---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: controller-alerts
  namespace: {{ .Values.namespaces.olmv1.name }}
spec:
  groups:
    - name: controller-panic
      rules:
        - alert: reconciler-panic
          annotations:
            description: controller of pod {{`{{ $labels.pod }}`}} experienced panic(s); count={{`{{ $value }}`}}
          expr: controller_runtime_reconcile_panics_total{} > 0
        - alert: webhook-panic
          annotations:
            description: controller webhook of pod {{`{{ $labels.pod }}`}} experienced panic(s); count={{`{{ $value }}`}}
          expr: controller_runtime_webhook_panics_total{} > 0
    - name: resource-usage
      rules:
        - alert: oom-events
          annotations:
            description: container {{`{{ $labels.container }}`}} of pod {{`{{ $labels.pod }}`}} experienced OOM event(s); count={{`{{ $value }}`}}
          expr: container_oom_events_total > 0
        # Memory growth alerts - thresholds calibrated based on baseline memory profiling
        # See MEMORY_ANALYSIS.md for details on normal operational memory patterns
        - alert: operator-controller-memory-growth
          annotations:
            description: 'operator-controller pod memory usage growing at a high rate for 5 minutes: {{`{{ $value | humanize }}`}}B/sec'
          # Threshold: 200kB/sec (baseline shows 132.4kB/sec episodic growth during e2e tests is normal)
          expr: deriv(sum(container_memory_working_set_bytes{pod=~"operator-controller.*",container="manager"})[5m:]) > 200_000
          for: 5m
          keep_firing_for: 1d
        - alert: catalogd-memory-growth
          annotations:
            description: 'catalogd pod memory usage growing at a high rate for 5 minutes: {{`{{ $value | humanize }}`}}B/sec'
          # Threshold: 200kB/sec (aligned with operator-controller for consistency)
          expr: deriv(sum(container_memory_working_set_bytes{pod=~"catalogd.*",container="manager"})[5m:]) > 200_000
          for: 5m
          keep_firing_for: 1d
        # Memory usage alerts - thresholds calibrated for test/development environments
        # Production deployments may need different thresholds based on workload
        - alert: operator-controller-memory-usage
          annotations:
            description: 'operator-controller pod using high memory resources for the last 5 minutes: {{`{{ $value | humanize }}`}}B'
          # Threshold: 150MB (baseline shows 107.9MB peak is normal, stabilizes at 78-88MB)
          expr: sum(container_memory_working_set_bytes{pod=~"operator-controller.*",container="manager"}) > 150_000_000
          for: 5m
          keep_firing_for: 1d
        - alert: catalogd-memory-usage
          annotations:
            description: 'catalogd pod using high memory resources for the last 5 minutes: {{`{{ $value | humanize }}`}}B'
          # Threshold: 75MB (baseline shows 16.9MB peak, well under threshold)
          expr: sum(container_memory_working_set_bytes{pod=~"catalogd.*",container="manager"}) > 75_000_000
          for: 5m
          keep_firing_for: 1d
        - alert: operator-controller-cpu-usage
          annotations:
            description: 'operator-controller using high cpu resource for 5 minutes: {{`{{ $value | printf "%.2f" }}`}}%'
          expr: rate(container_cpu_usage_seconds_total{pod=~"operator-controller.*",container="manager"}[5m]) * 100 > 20
          for: 5m
          keep_firing_for: 1d
        - alert: catalogd-cpu-usage
          annotations:
            description: 'catalogd using high cpu resources for 5 minutes: {{`{{ $value | printf "%.2f" }}`}}%'
          expr: rate(container_cpu_usage_seconds_total{pod=~"catalogd.*",container="manager"}[5m]) * 100 > 20
          for: 5m
          keep_firing_for: 1d
        - alert: operator-controller-api-call-rate
          annotations:
            description: 'operator-controller making excessive API calls for 5 minutes: {{`{{ $value | printf "%.2f" }}`}}/sec'
          expr: sum(rate(rest_client_requests_total{job=~"operator-controller-service"}[5m])) > 10
          for: 5m
          keep_firing_for: 1d
        - alert: catalogd-api-call-rate
          annotations:
            description: 'catalogd making excessive API calls for 5 minutes: {{`{{ $value | printf "%.2f" }}`}}/sec'
          expr: sum(rate(rest_client_requests_total{job=~"catalogd-service"}[5m])) > 5
          for: 5m
          keep_firing_for: 1d
