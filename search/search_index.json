{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Operator Lifecycle Manager","text":"<p>The Operator Lifecycle Manager (OLM) is an open-source project under the Cloud Native Computing Foundation (CNCF), designed to simplify and centralize the management of Kubernetes cluster extensions. OLM streamlines the process of installing, running, and updating these extensions, making it easier, safer, and more reproducible for cluster and platform administrators alike.</p> <p>Originally, OLM was focused on managing a specific type of extension known as Operators, which are powerful tools that automate the management of complex Kubernetes applications. At its core, an Operator is made up of controllers that automate the lifecycle of applications, paired with:</p> <ul> <li>One or more Kubernetes API extensions.</li> <li>One or more CustomResourceDefinitions (CRDs), allowing administrators to define custom resources.</li> </ul> <p>The purpose of OLM is to manage the lifecycle of these extensions\u2014from their packaging and distribution to installation, updates, and eventual removal\u2014helping administrators ensure stability and security across their clusters.</p> <p>In its first release (OLM v0), the project introduced several important concepts and features aimed at improving the lifecycle management of Kubernetes applications:</p> <ul> <li>Dependency Model: Enables extensions to focus on their primary function by delegating non-essential tasks to other dependencies.</li> <li>Constraint Model: Allows developers to define compatibility constraints such as conflicting extensions or minimum required Kubernetes versions.</li> <li>Namespace-Based Multi-Tenancy: Provides a multi-tenancy model to manage multiple extensions without the need for namespace-scoped CRDs.</li> <li>Packaging Model: Distributes extensions through catalogs, allowing users to browse and install extensions, often with access to the full version history.</li> </ul> <p>Thanks to these innovations, OLM has played a significant role in popularizing Operators throughout the Kubernetes ecosystem. A prime example of its impact is OperatorHub.io, a widely-used platform with over 300 Operators from various vendors, providing users with a central location to discover and install Operators.</p>"},{"location":"#why-build-olm-v1","title":"Why Build OLM v1?","text":"<p>After five years of real-world use, OLM has become an essential part of managing Kubernetes Operators. However, over time, the community has gathered valuable insights, uncovering both the strengths and limitations of OLM v0. These findings have led to a comprehensive redesign and the creation of OLM v1, with several key improvements over the initial version:</p> <ul> <li>Simpler API and Mental Model: Streamlined APIs and a more intuitive design, making it easier to understand and work with.</li> <li>Greater Flexibility: Less rigid automation, allowing for more customization and broader use cases.</li> <li>Beyond Operators: Support for a wider range of Kubernetes applications, not limited to Operators.</li> <li>Security by Default: Enhanced security features out-of-the-box, reducing vulnerabilities.</li> <li>Helm Chart and GitOps Support: Expanded support for popular Kubernetes tools like Helm and GitOps, broadening the range of integration options.</li> </ul> <p>For more details on the evolution of OLM and the roadmap for v1, explore the following resources:</p> <ul> <li>Multi-Tenancy Challenges, Lessons Learned, and Design Shifts</li> <li>OLM v1 Roadmap</li> </ul>"},{"location":"#can-i-migrate-from-olmv0-to-olmv1","title":"Can I Migrate from OLMv0 to OLMv1?","text":"<p>There is currently no concrete migration strategy due to the conceptual differences between OLMv0 and OLMv1. OLMv1, as of writing, supports a subset of the existing content supported by OLMv0. For more information regarding the current limitations of OLMv1, see limitations.</p> <p>If your current usage of OLMv0 is compatible with the limitations and expectations of OLMv1, you may be able to manually transition to using OLMv1 following the standard workflows we have documented.</p>"},{"location":"api-reference/catalogd-webserver/","title":"Catalogd web server","text":"<p>Catalogd, the OLM v1 component for making catalog contents available on cluster, includes a web server that serves catalog contents to clients via an HTTP(S) endpoint.</p> <p>The endpoint to retrieve this information can be composed from the <code>.status.urls.base</code> of a <code>ClusterCatalog</code> resource with the selected access API path. As an example, to access the full FBC via the v1 API endpoint (indicated by path <code>api/v1/all</code>) where <code>.status.urls.base</code> is</p> <pre><code>    urls:\n        base: https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio\n</code></pre> <p>the URL to access the service would be <code>https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio/api/v1/all</code></p> <p>Note</p> <p>The values of the <code>.status.urls</code> field in a <code>ClusterCatalog</code> resource are arbitrary string values and can change at any time. While there are no guarantees on the exact value of this field, it will always contain catalog-specific API endpoints for use by clients to make a request from within the cluster.</p>"},{"location":"api-reference/catalogd-webserver/#interacting-with-the-server","title":"Interacting With the Server","text":""},{"location":"api-reference/catalogd-webserver/#supported-http-methods","title":"Supported HTTP Methods","text":"<p>The HTTP request methods supported by the catalogd web server are:</p> <ul> <li>GET</li> <li>HEAD</li> </ul>"},{"location":"api-reference/catalogd-webserver/#response-format","title":"Response Format","text":"<p>Responses are encoded as a JSON Lines stream of File-Based Catalog (FBC) Meta objects delimited by newlines.</p> Example JSON-encoded FBC snippet <pre><code>{\n    \"schema\": \"olm.package\",\n    \"name\": \"cockroachdb\",\n    \"defaultChannel\": \"stable-v6.x\",\n}\n{\n    \"schema\": \"olm.channel\",\n    \"name\": \"stable-v6.x\",\n    \"package\": \"cockroachdb\",\n    \"entries\": [\n        {\n            \"name\": \"cockroachdb.v6.0.0\",\n            \"skipRange\": \"&lt;6.0.0\"\n        }\n    ]\n}\n{\n    \"schema\": \"olm.bundle\",\n    \"name\": \"cockroachdb.v6.0.0\",\n    \"package\": \"cockroachdb\",\n    \"image\": \"quay.io/openshift-community-operators/cockroachdb@sha256:d3016b1507515fc7712f9c47fd9082baf9ccb070aaab58ed0ef6e5abdedde8ba\",\n    \"properties\": [\n        {\n            \"type\": \"olm.package\",\n            \"value\": {\n                \"packageName\": \"cockroachdb\",\n                \"version\": \"6.0.0\"\n            }\n        },\n    ],\n}\n</code></pre> <p>Corresponding JSON lines response: <pre><code>{\"schema\":\"olm.package\",\"name\":\"cockroachdb\",\"defaultChannel\":\"stable-v6.x\"}\n{\"schema\":\"olm.channel\",\"name\":\"stable-v6.x\",\"package\":\"cockroachdb\",\"entries\":[{\"name\":\"cockroachdb.v6.0.0\",\"skipRange\":\"&lt;6.0.0\"}]}\n{\"schema\":\"olm.bundle\",\"name\":\"cockroachdb.v6.0.0\",\"package\":\"cockroachdb\",\"image\":\"quay.io/openshift-community-operators/cockroachdb@sha256:d3016b1507515fc7712f9c47fd9082baf9ccb070aaab58ed0ef6e5abdedde8ba\",\"properties\":[{\"type\":\"olm.package\",\"value\":{\"packageName\":\"cockroachdb\",\"version\":\"6.0.0\"}}]}\n</code></pre></p>"},{"location":"api-reference/catalogd-webserver/#compression-support","title":"Compression Support","text":"<p>The <code>catalogd</code> web server supports gzip compression of responses, which can significantly reduce associated network traffic.  In order to signal that the client handles compressed responses, the client must include <code>Accept-Encoding: gzip</code> as a header in the HTTP request.</p> <p>The web server will include a <code>Content-Encoding: gzip</code> header in compressed responses.</p> <p>Note</p> <p>Only catalogs whose uncompressed response body would result in a response size greater than 1400 bytes will be compressed.</p>"},{"location":"api-reference/catalogd-webserver/#cache-header-support","title":"Cache Header Support","text":"<p>For clients interested in caching the information returned from the <code>catalogd</code> web server, the <code>Last-Modified</code> header is set on responses and the <code>If-Modified-Since</code> header is supported for requests.</p>"},{"location":"api-reference/olmv1-api-reference/","title":"API Reference","text":""},{"location":"api-reference/olmv1-api-reference/#packages","title":"Packages","text":"<ul> <li>olm.operatorframework.io/v1</li> </ul>"},{"location":"api-reference/olmv1-api-reference/#olmoperatorframeworkiov1","title":"olm.operatorframework.io/v1","text":"<p>Package v1 contains API Schema definitions for the olm v1 API group</p>"},{"location":"api-reference/olmv1-api-reference/#resource-types","title":"Resource Types","text":"<ul> <li>ClusterCatalog</li> <li>ClusterCatalogList</li> <li>ClusterExtension</li> <li>ClusterExtensionList</li> </ul>"},{"location":"api-reference/olmv1-api-reference/#availabilitymode","title":"AvailabilityMode","text":"<p>Underlying type: string</p> <p>AvailabilityMode defines the availability of the catalog</p> <p>Appears in: - ClusterCatalogSpec</p> Field Description <code>Available</code> <code>Unavailable</code>"},{"location":"api-reference/olmv1-api-reference/#bundlemetadata","title":"BundleMetadata","text":"<p>BundleMetadata is a representation of the identifying attributes of a bundle.</p> <p>Appears in: - ClusterExtensionInstallStatus</p> Field Description Default Validation <code>name</code> string name is required and follows the DNS subdomain standard as defined in [RFC 1123].It must contain only lowercase alphanumeric characters, hyphens (-) or periods (.),start and end with an alphanumeric character, and be no longer than 253 characters. Required: {}  <code>version</code> string version is required and references the version that this bundle represents.It follows the semantic versioning standard as defined in https://semver.org/. Required: {}"},{"location":"api-reference/olmv1-api-reference/#crdupgradesafetyenforcement","title":"CRDUpgradeSafetyEnforcement","text":"<p>Underlying type: string</p> <p>Appears in: - CRDUpgradeSafetyPreflightConfig</p> Field Description <code>None</code> None will not perform CRD upgrade safety checks. <code>Strict</code> Strict will enforce the CRD upgrade safety check and block the upgrade if the CRD would not pass the check."},{"location":"api-reference/olmv1-api-reference/#crdupgradesafetypreflightconfig","title":"CRDUpgradeSafetyPreflightConfig","text":"<p>CRDUpgradeSafetyPreflightConfig is the configuration for CRD upgrade safety preflight check.</p> <p>Appears in: - PreflightConfig</p> Field Description Default Validation <code>enforcement</code> CRDUpgradeSafetyEnforcement enforcement is required and configures the state of the CRD Upgrade Safety pre-flight check.Allowed values are \"None\" or \"Strict\". The default value is \"Strict\".When set to \"None\", the CRD Upgrade Safety pre-flight check is skipped during an upgrade operation.Use this option with caution as unintended consequences such as data loss can occur.When set to \"Strict\", the CRD Upgrade Safety pre-flight check runs during an upgrade operation. Enum: [None Strict] Required: {}"},{"location":"api-reference/olmv1-api-reference/#catalogfilter","title":"CatalogFilter","text":"<p>CatalogFilter defines the attributes used to identify and filter content from a catalog.</p> <p>Appears in: - SourceConfig</p> Field Description Default Validation <code>packageName</code> string packageName specifies the name of the package to be installed and is used to filterthe content from catalogs.It is required, immutable, and follows the DNS subdomain standard as defined in [RFC 1123].It must contain only lowercase alphanumeric characters, hyphens (-) or periods (.),start and end with an alphanumeric character, and be no longer than 253 characters.Some examples of valid values are:  - some-package  - 123-package  - 1-package-2  - somepackageSome examples of invalid values are:  - -some-package  - some-package-  - thisisareallylongpackagenamethatisgreaterthanthemaximumlength  - some.package[RFC 1123]: https://tools.ietf.org/html/rfc1123 MaxLength: 253 Required: {}  <code>version</code> string version is an optional semver constraint (a specific version or range of versions).When unspecified, the latest version available is installed.Acceptable version ranges are no longer than 64 characters.Version ranges are composed of comma- or space-delimited values and one or more comparison operators,known as comparison strings.You can add additional comparison strings using the OR operator (||).# Range ComparisonsTo specify a version range, you can use a comparison string like \"&gt;=3.0,&lt;3.6\". When specifying a range, automatic updates will occur within thatrange. The example comparison string means \"install any version greater thanor equal to 3.0.0 but less than 3.6.0.\". It also states intent that if anyupgrades are available within the version range after initial installation,those upgrades should be automatically performed.# Pinned VersionsTo specify an exact version to install you can use a version range that\"pins\" to a specific version. When pinning to a specific version, noautomatic updates will occur. An example of a pinned version range is\"0.6.0\", which means \"only install version 0.6.0 and neverupgrade from this version\".# Basic Comparison OperatorsThe basic comparison operators and their meanings are:  - \"=\", equal (not aliased to an operator)  - \"!=\", not equal  - \"&lt;\", less than  - \"&gt;\", greater than  - \"&gt;=\", greater than OR equal to  - \"&lt;=\", less than OR equal to# Wildcard ComparisonsYou can use the \"x\", \"X\", and \"\" characters as wildcard characters in allcomparison operations. Some examples of using the wildcard characters:  - \"1.2.x\", \"1.2.X\", and \"1.2.\" is equivalent to \"&gt;=1.2.0, &lt; 1.3.0\"  - \"&gt;= 1.2.x\", \"&gt;= 1.2.X\", and \"&gt;= 1.2.\" is equivalent to \"&gt;= 1.2.0\"  - \"&lt;= 2.x\", \"&lt;= 2.X\", and \"&lt;= 2.\" is equivalent to \"&lt; 3\"  - \"x\", \"X\", and \"*\" is equivalent to \"&gt;= 0.0.0\"# Patch Release ComparisonsWhen you want to specify a minor version up to the next major version youcan use the \"~\" character to perform patch comparisons. Some examples:  - \"~1.2.3\" is equivalent to \"&gt;=1.2.3, &lt;1.3.0\"  - \"~1\" and \"~1.x\" is equivalent to \"&gt;=1, &lt;2\"  - \"~2.3\" is equivalent to \"&gt;=2.3, &lt;2.4\"  - \"~1.2.x\" is equivalent to \"&gt;=1.2.0, &lt;1.3.0\"# Major Release ComparisonsYou can use the \"^\" character to make major release comparisons after astable 1.0.0 version is published. If there is no stable version published, // minor versions define the stability level. Some examples:  - \"^1.2.3\" is equivalent to \"&gt;=1.2.3, &lt;2.0.0\"  - \"^1.2.x\" is equivalent to \"&gt;=1.2.0, &lt;2.0.0\"  - \"^2.3\" is equivalent to \"&gt;=2.3, &lt;3\"  - \"^2.x\" is equivalent to \"&gt;=2.0.0, &lt;3\"  - \"^0.2.3\" is equivalent to \"&gt;=0.2.3, &lt;0.3.0\"  - \"^0.2\" is equivalent to \"&gt;=0.2.0, &lt;0.3.0\"  - \"^0.0.3\" is equvalent to \"&gt;=0.0.3, &lt;0.0.4\"  - \"^0.0\" is equivalent to \"&gt;=0.0.0, &lt;0.1.0\"  - \"^0\" is equivalent to \"&gt;=0.0.0, &lt;1.0.0\"# OR ComparisonsYou can use the \"||\" character to represent an OR operation in the versionrange. Some examples:  - \"&gt;=1.2.3, &lt;2.0.0 || &gt;3.0.0\"  - \"^0 || ^3 || ^5\"For more information on semver, please see https://semver.org/ MaxLength: 64 Optional: {}  <code>channels</code> string array channels is optional and specifies a set of channels belonging to the packagespecified in the packageName field.A channel is a package-author-defined stream of updates for an extension.Each channel in the list must follow the DNS subdomain standard as defined in [RFC 1123].It must contain only lowercase alphanumeric characters, hyphens (-) or periods (.),start and end with an alphanumeric character, and be no longer than 253 characters.You can specify no more than 256 channels.When specified, it constrains the set of installable bundles and the automated upgrade path.This constraint is an AND operation with the version field. For example:  - Given channel is set to \"foo\"  - Given version is set to \"&gt;=1.0.0, &lt;1.5.0\"  - Only bundles that exist in channel \"foo\" AND satisfy the version range comparison are considered installable  - Automatic upgrades are constrained to upgrade edges defined by the selected channelWhen unspecified, upgrade edges across all channels are used to identify valid automatic upgrade paths.Some examples of valid values are:  - 1.1.x  - alpha  - stable  - stable-v1  - v1-stable  - dev-preview  - preview  - communitySome examples of invalid values are:  - -some-channel  - some-channel-  - thisisareallylongchannelnamethatisgreaterthanthemaximumlength  - original_40  - --default-channel[RFC 1123]: https://tools.ietf.org/html/rfc1123 MaxItems: 256 items:MaxLength: 253 items:XValidation: {self.matches(\"^a-z0-9?(\\.a-z0-9?)*$\") channels entries must be valid DNS1123 subdomains    } Optional: {}  <code>selector</code> LabelSelector selector is optional and filters the set of ClusterCatalogs used in the bundle selection process.When unspecified, all ClusterCatalogs are used in the bundle selection process. Optional: {}  <code>upgradeConstraintPolicy</code> UpgradeConstraintPolicy upgradeConstraintPolicy is optional and controls whether the upgrade paths defined in the catalogare enforced for the package referenced in the packageName field.Allowed values are \"CatalogProvided\", \"SelfCertified\", or omitted.When set to \"CatalogProvided\", automatic upgrades only occur when upgrade constraints specified by the packageauthor are met.When set to \"SelfCertified\", the upgrade constraints specified by the package author are ignored.This allows upgrades and downgrades to any version of the package.This is considered a dangerous operation as it can lead to unknown and potentially disastrous outcomes,such as data loss.Use this option only if you have independently verified the changes.When omitted, the default value is \"CatalogProvided\". CatalogProvided Enum: [CatalogProvided SelfCertified] Optional: {}"},{"location":"api-reference/olmv1-api-reference/#catalogsource","title":"CatalogSource","text":"<p>CatalogSource is a discriminated union of possible sources for a Catalog. CatalogSource contains the sourcing information for a Catalog</p> <p>Appears in: - ClusterCatalogSpec</p> Field Description Default Validation <code>type</code> SourceType type is a required field that specifies the type of source for the catalog.The only allowed value is \"Image\".When set to \"Image\", the ClusterCatalog content is sourced from an OCI image.When using an image source, the image field must be set and must be the only field defined for this type. Enum: [Image] Required: {}  <code>image</code> ImageSource image configures how catalog contents are sourced from an OCI image.It is required when type is Image, and forbidden otherwise. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clustercatalog","title":"ClusterCatalog","text":"<p>ClusterCatalog makes File-Based Catalog (FBC) data available to your cluster. For more information on FBC, see https://olm.operatorframework.io/docs/reference/file-based-catalogs/#docs</p> <p>Appears in: - ClusterCatalogList</p> Field Description Default Validation <code>apiVersion</code> string <code>olm.operatorframework.io/v1</code> <code>kind</code> string <code>ClusterCatalog</code> <code>kind</code> string Kind is a string value representing the REST resource this object represents.Servers may infer this from the endpoint the client submits requests to.Cannot be updated.In CamelCase.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds Optional: {}  <code>apiVersion</code> string APIVersion defines the versioned schema of this representation of an object.Servers should convert recognized schemas to the latest internal value, andmay reject unrecognized values.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources Optional: {}  <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> ClusterCatalogSpec spec is a required field that defines the desired state of the ClusterCatalog.The controller ensures that the catalog is unpacked and served over the catalog content HTTP server. Required: {}  <code>status</code> ClusterCatalogStatus status contains the following information about the state of the ClusterCatalog:  - Whether the catalog contents are being served via the catalog content HTTP server  - Whether the ClusterCatalog is progressing to a new state  - A reference to the source from which the catalog contents were retrieved Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clustercataloglist","title":"ClusterCatalogList","text":"<p>ClusterCatalogList contains a list of ClusterCatalog</p> Field Description Default Validation <code>apiVersion</code> string <code>olm.operatorframework.io/v1</code> <code>kind</code> string <code>ClusterCatalogList</code> <code>kind</code> string Kind is a string value representing the REST resource this object represents.Servers may infer this from the endpoint the client submits requests to.Cannot be updated.In CamelCase.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds Optional: {}  <code>apiVersion</code> string APIVersion defines the versioned schema of this representation of an object.Servers should convert recognized schemas to the latest internal value, andmay reject unrecognized values.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources Optional: {}  <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> ClusterCatalog array items is a list of ClusterCatalogs.items is required. Required: {}"},{"location":"api-reference/olmv1-api-reference/#clustercatalogspec","title":"ClusterCatalogSpec","text":"<p>ClusterCatalogSpec defines the desired state of ClusterCatalog</p> <p>Appears in: - ClusterCatalog</p> Field Description Default Validation <code>source</code> CatalogSource source is a required field that defines the source of a catalog.A catalog contains information on content that can be installed on a cluster.The catalog source makes catalog contents discoverable and usable by other on-cluster components.These components can present the content in a GUI dashboard or install content from the catalog on the cluster.The catalog source must contain catalog metadata in the File-Based Catalog (FBC) format.For more information on FBC, see https://olm.operatorframework.io/docs/reference/file-based-catalogs/#docs.Below is a minimal example of a ClusterCatalogSpec that sources a catalog from an image: source:   type: Image   image:     ref: quay.io/operatorhubio/catalog:latest Required: {}  <code>priority</code> integer priority is an optional field that defines a priority for this ClusterCatalog.Clients use the ClusterCatalog priority as a tie-breaker between ClusterCatalogs that meet their requirements.Higher numbers mean higher priority.Clients decide how to handle scenarios where multiple ClusterCatalogs with the same priority meet their requirements.Clients should prompt users for additional input to break the tie.When omitted, the default priority is 0.Use negative numbers to specify a priority lower than the default.Use positive numbers to specify a priority higher than the default.The lowest possible value is -2147483648.The highest possible value is 2147483647. 0 Maximum: 2.147483647e+09 Minimum: -2.147483648e+09 Optional: {}  <code>availabilityMode</code> AvailabilityMode availabilityMode is an optional field that defines how the ClusterCatalog is made available to clients on the cluster.Allowed values are \"Available\", \"Unavailable\", or omitted.When omitted, the default value is \"Available\".When set to \"Available\", the catalog contents are unpacked and served over the catalog content HTTP server.Clients should consider this ClusterCatalog and its contents as usable.When set to \"Unavailable\", the catalog contents are no longer served over the catalog content HTTP server.Treat this the same as if the ClusterCatalog does not exist.Use \"Unavailable\" when you want to keep the ClusterCatalog but treat it as if it doesn't exist. Available Enum: [Unavailable Available] Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clustercatalogstatus","title":"ClusterCatalogStatus","text":"<p>ClusterCatalogStatus defines the observed state of ClusterCatalog</p> <p>Appears in: - ClusterCatalog</p> Field Description Default Validation <code>conditions</code> Condition array conditions represents the current state of this ClusterCatalog.The current condition types are Serving and Progressing.The Serving condition represents whether the catalog contents are being served via the HTTP(S) web server:  - When status is True and reason is Available, the catalog contents are being served.  - When status is False and reason is Unavailable, the catalog contents are not being served because the contents are not yet available.  - When status is False and reason is UserSpecifiedUnavailable, the catalog contents are not being served because the catalog has been intentionally marked as unavailable.The Progressing condition represents whether the ClusterCatalog is progressing or is ready to progress towards a new state:  - When status is True and reason is Retrying, an error occurred that may be resolved on subsequent reconciliation attempts.  - When status is True and reason is Succeeded, the ClusterCatalog has successfully progressed to a new state and is ready to continue progressing.  - When status is False and reason is Blocked, an error occurred that requires manual intervention for recovery.If the system initially fetched contents and polling identifies updates, both conditions can be active simultaneously:  - The Serving condition remains True with reason Available because the previous contents are still served via the HTTP(S) web server.  - The Progressing condition is True with reason Retrying because the system is working to serve the new version. Optional: {}  <code>resolvedSource</code> ResolvedCatalogSource resolvedSource contains information about the resolved source based on the source type. Optional: {}  <code>urls</code> ClusterCatalogURLs urls contains the URLs that can be used to access the catalog. Optional: {}  <code>lastUnpacked</code> Time lastUnpacked represents the last time the catalog contents were extracted from their source format.For example, when using an Image source, the OCI image is pulled and image layers are written to a file-system backed cache.This extraction from the source format is called \"unpacking\". Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clustercatalogurls","title":"ClusterCatalogURLs","text":"<p>ClusterCatalogURLs contains the URLs that can be used to access the catalog.</p> <p>Appears in: - ClusterCatalogStatus</p> Field Description Default Validation <code>base</code> string base is a cluster-internal URL that provides endpoints for accessing the catalog content.Clients should append the path for the endpoint they want to access.Currently, only a single endpoint is served and is accessible at the path /api/v1.The endpoints served for the v1 API are:  - /all - this endpoint returns the entire catalog contents in the FBC formatNew endpoints may be added as needs evolve. MaxLength: 525 Required: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextension","title":"ClusterExtension","text":"<p>ClusterExtension is the Schema for the clusterextensions API</p> <p>Appears in: - ClusterExtensionList</p> Field Description Default Validation <code>apiVersion</code> string <code>olm.operatorframework.io/v1</code> <code>kind</code> string <code>ClusterExtension</code> <code>kind</code> string Kind is a string value representing the REST resource this object represents.Servers may infer this from the endpoint the client submits requests to.Cannot be updated.In CamelCase.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds Optional: {}  <code>apiVersion</code> string APIVersion defines the versioned schema of this representation of an object.Servers should convert recognized schemas to the latest internal value, andmay reject unrecognized values.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources Optional: {}  <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. Optional: {}  <code>spec</code> ClusterExtensionSpec spec is an optional field that defines the desired state of the ClusterExtension. Optional: {}  <code>status</code> ClusterExtensionStatus status is an optional field that defines the observed state of the ClusterExtension. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensionconfig","title":"ClusterExtensionConfig","text":"<p>ClusterExtensionConfig is a discriminated union which selects the source configuration values to be merged into the ClusterExtension's rendered manifests.</p> <p>Appears in: - ClusterExtensionSpec</p> Field Description Default Validation <code>configType</code> ClusterExtensionConfigType configType is required and specifies the type of configuration source.The only allowed value is \"Inline\".When set to \"Inline\", the cluster extension configuration is defined inline within the ClusterExtension resource. Enum: [Inline] Required: {}  <code>inline</code> JSON inline contains JSON or YAML values specified directly in the ClusterExtension.It is used to specify arbitrary configuration values for the ClusterExtension.It must be set if configType is 'Inline' and must be a valid JSON/YAML object containing at least one property.The configuration values are validated at runtime against a JSON schema provided by the bundle. MinProperties: 1 Type: object Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensionconfigtype","title":"ClusterExtensionConfigType","text":"<p>Underlying type: string</p> <p>Appears in: - ClusterExtensionConfig</p> Field Description <code>Inline</code>"},{"location":"api-reference/olmv1-api-reference/#clusterextensioninstallconfig","title":"ClusterExtensionInstallConfig","text":"<p>ClusterExtensionInstallConfig is a union which selects the clusterExtension installation config. ClusterExtensionInstallConfig requires the namespace and serviceAccount which should be used for the installation of packages.</p> <p>Appears in: - ClusterExtensionSpec</p> Field Description Default Validation <code>preflight</code> PreflightConfig preflight is optional and configures the checks that run before installation or upgradeof the content for the package specified in the packageName field.When specified, it replaces the default preflight configuration for install/upgrade actions.When not specified, the default configuration is used. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensioninstallstatus","title":"ClusterExtensionInstallStatus","text":"<p>ClusterExtensionInstallStatus is a representation of the status of the identified bundle.</p> <p>Appears in: - ClusterExtensionStatus</p> Field Description Default Validation <code>bundle</code> BundleMetadata bundle is required and represents the identifying attributes of a bundle.A \"bundle\" is a versioned set of content that represents the resources that need to be appliedto a cluster to install a package. Required: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensionlist","title":"ClusterExtensionList","text":"<p>ClusterExtensionList contains a list of ClusterExtension</p> Field Description Default Validation <code>apiVersion</code> string <code>olm.operatorframework.io/v1</code> <code>kind</code> string <code>ClusterExtensionList</code> <code>kind</code> string Kind is a string value representing the REST resource this object represents.Servers may infer this from the endpoint the client submits requests to.Cannot be updated.In CamelCase.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds Optional: {}  <code>apiVersion</code> string APIVersion defines the versioned schema of this representation of an object.Servers should convert recognized schemas to the latest internal value, andmay reject unrecognized values.More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources Optional: {}  <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. Optional: {}  <code>items</code> ClusterExtension array items is a required list of ClusterExtension objects. Required: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensionspec","title":"ClusterExtensionSpec","text":"<p>ClusterExtensionSpec defines the desired state of ClusterExtension</p> <p>Appears in: - ClusterExtension</p> Field Description Default Validation <code>namespace</code> string namespace specifies a Kubernetes namespace.This is the namespace where the provided ServiceAccount must exist.It also designates the default namespace where namespace-scoped resources for the extension are applied to the cluster.Some extensions may contain namespace-scoped resources to be applied in other namespaces.This namespace must exist.The namespace field is required, immutable, and follows the DNS label standard as defined in [RFC 1123].It must contain only lowercase alphanumeric characters or hyphens (-), start and end with an alphanumeric character,and be no longer than 63 characters.[RFC 1123]: https://tools.ietf.org/html/rfc1123 MaxLength: 63 Required: {}  <code>serviceAccount</code> ServiceAccountReference serviceAccount specifies a ServiceAccount used to perform all interactions with the clusterthat are required to manage the extension.The ServiceAccount must be configured with the necessary permissions to perform these interactions.The ServiceAccount must exist in the namespace referenced in the spec.The serviceAccount field is required. Required: {}  <code>source</code> SourceConfig source is required and selects the installation source of content for this ClusterExtension.Set the sourceType field to perform the selection.Catalog is currently the only implemented sourceType.Setting sourceType to \"Catalog\" requires the catalog field to also be defined.Below is a minimal example of a source definition (in yaml):source:  sourceType: Catalog  catalog:    packageName: example-package Required: {}  <code>install</code> ClusterExtensionInstallConfig install is optional and configures installation options for the ClusterExtension,such as the pre-flight check configuration. Optional: {}  <code>config</code> ClusterExtensionConfig config is optional and specifies bundle-specific configuration.Configuration is bundle-specific and a bundle may provide a configuration schema.When not specified, the default configuration of the resolved bundle is used.config is validated against a configuration schema provided by the resolved bundle. If the bundle does not providea configuration schema the bundle is deemed to not be configurable. More information on howto configure bundles can be found in the OLM documentation associated with your current OLM version. Optional: {}  <code>progressDeadlineMinutes</code> integer progressDeadlineMinutes is an optional field that defines the maximum periodof time in minutes after which an installation should be considered failed andrequire manual intervention. This functionality is disabled when no valueis provided. The minimum period is 10 minutes, and the maximum is 720 minutes (12 hours). Maximum: 720 Minimum: 10 Optional: {}"},{"location":"api-reference/olmv1-api-reference/#clusterextensionstatus","title":"ClusterExtensionStatus","text":"<p>ClusterExtensionStatus defines the observed state of a ClusterExtension.</p> <p>Appears in: - ClusterExtension</p> Field Description Default Validation <code>conditions</code> Condition array conditions represents the current state of the ClusterExtension.The set of condition types which apply to all spec.source variations are Installed and Progressing.The Installed condition represents whether the bundle has been installed for this ClusterExtension:  - When Installed is True and the Reason is Succeeded, the bundle has been successfully installed.  - When Installed is False and the Reason is Failed, the bundle has failed to install.The Progressing condition represents whether or not the ClusterExtension is advancing towards a new state.When Progressing is True and the Reason is Succeeded, the ClusterExtension is making progress towards a new state.When Progressing is True and the Reason is Retrying, the ClusterExtension has encountered an error that could be resolved on subsequent reconciliation attempts.When Progressing is False and the Reason is Blocked, the ClusterExtension has encountered an error that requires manual intervention for recovery.When Progressing is True and Reason is RollingOut, the ClusterExtension has one or more ClusterExtensionRevisions in active roll out.When the ClusterExtension is sourced from a catalog, it surfaces deprecation conditions based on catalog metadata.These are indications from a package owner to guide users away from a particular package, channel, or bundle:  - BundleDeprecated is True if the installed bundle is marked deprecated, False if not deprecated, or Unknown if no bundle is installed yet or if catalog data is unavailable.  - ChannelDeprecated is True if any requested channel is marked deprecated, False if not deprecated, or Unknown if catalog data is unavailable.  - PackageDeprecated is True if the requested package is marked deprecated, False if not deprecated, or Unknown if catalog data is unavailable.  - Deprecated is a rollup condition that is True when any deprecation exists, False when none exist, or Unknown when catalog data is unavailable. Optional: {}  <code>install</code> ClusterExtensionInstallStatus install is a representation of the current installation status for this ClusterExtension. Optional: {}  <code>activeRevisions</code> RevisionStatus array activeRevisions holds a list of currently active (non-archived) ClusterExtensionRevisions,including both installed and rolling out revisions. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#imagesource","title":"ImageSource","text":"<p>ImageSource enables users to define the information required for sourcing a Catalog from an OCI image</p> <p>If we see that there is a possibly valid digest-based image reference AND pollIntervalMinutes is specified, reject the resource since there is no use in polling a digest-based image reference.</p> <p>Appears in: - CatalogSource</p> Field Description Default Validation <code>ref</code> string ref is a required field that defines the reference to a container image containing catalog contents.It cannot be more than 1000 characters.A reference has 3 parts: the domain, name, and identifier.The domain is typically the registry where an image is located.It must be alphanumeric characters (lowercase and uppercase) separated by the \".\" character.Hyphenation is allowed, but the domain must start and end with alphanumeric characters.Specifying a port to use is also allowed by adding the \":\" character followed by numeric values.The port must be the last value in the domain.Some examples of valid domain values are \"registry.mydomain.io\", \"quay.io\", \"my-registry.io:8080\".The name is typically the repository in the registry where an image is located.It must contain lowercase alphanumeric characters separated only by the \".\", \"\", \"__\", \"-\" characters.Multiple names can be concatenated with the \"/\" character.The domain and name are combined using the \"/\" character.Some examples of valid name values are \"operatorhubio/catalog\", \"catalog\", \"my-catalog.prod\".An example of the domain and name parts of a reference being combined is \"quay.io/operatorhubio/catalog\".The identifier is typically the tag or digest for an image reference and is present at the end of the reference.It starts with a separator character used to distinguish the end of the name and beginning of the identifier.For a digest-based reference, the \"@\" character is the separator.For a tag-based reference, the \":\" character is the separator.An identifier is required in the reference.Digest-based references must contain an algorithm reference immediately after the \"@\" separator.The algorithm reference must be followed by the \":\" character and an encoded string.The algorithm must start with an uppercase or lowercase alpha character followed by alphanumeric characters and may contain the \"-\", \"\", \"+\", and \".\" characters.Some examples of valid algorithm values are \"sha256\", \"sha256+b64u\", \"multihash+base58\".The encoded string following the algorithm must be hex digits (a-f, A-F, 0-9) and must be a minimum of 32 characters.Tag-based references must begin with a word character (alphanumeric + \"_\") followed by word characters or \".\", and \"-\" characters.The tag must not be longer than 127 characters.An example of a valid digest-based image reference is \"quay.io/operatorhubio/catalog@sha256:200d4ddb2a73594b91358fe6397424e975205bfbe44614f5846033cad64b3f05\"An example of a valid tag-based image reference is \"quay.io/operatorhubio/catalog:latest\" MaxLength: 1000 Required: {}  <code>pollIntervalMinutes</code> integer pollIntervalMinutes is an optional field that sets the interval, in minutes, at which the image source is polled for new content.You cannot specify pollIntervalMinutes when ref is a digest-based reference.When omitted, the image is not polled for new content. Minimum: 1 Optional: {}"},{"location":"api-reference/olmv1-api-reference/#preflightconfig","title":"PreflightConfig","text":"<p>PreflightConfig holds the configuration for the preflight checks.  If used, at least one preflight check must be non-nil.</p> <p>Appears in: - ClusterExtensionInstallConfig</p> Field Description Default Validation <code>crdUpgradeSafety</code> CRDUpgradeSafetyPreflightConfig crdUpgradeSafety configures the CRD Upgrade Safety pre-flight checks that runbefore upgrades of installed content.The CRD Upgrade Safety pre-flight check safeguards from unintended consequences of upgrading a CRD,such as data loss."},{"location":"api-reference/olmv1-api-reference/#resolvedcatalogsource","title":"ResolvedCatalogSource","text":"<p>ResolvedCatalogSource is a discriminated union of resolution information for a Catalog. ResolvedCatalogSource contains the information about a sourced Catalog</p> <p>Appears in: - ClusterCatalogStatus</p> Field Description Default Validation <code>type</code> SourceType type is a required field that specifies the type of source for the catalog.The only allowed value is \"Image\".When set to \"Image\", information about the resolved image source is set in the image field. Enum: [Image] Required: {}  <code>image</code> ResolvedImageSource image contains resolution information for a catalog sourced from an image.It must be set when type is Image, and forbidden otherwise."},{"location":"api-reference/olmv1-api-reference/#resolvedimagesource","title":"ResolvedImageSource","text":"<p>ResolvedImageSource provides information about the resolved source of a Catalog sourced from an image.</p> <p>Appears in: - ResolvedCatalogSource</p> Field Description Default Validation <code>ref</code> string ref contains the resolved image digest-based reference.The digest format allows you to use other tooling to fetch the exact OCI manifeststhat were used to extract the catalog contents. MaxLength: 1000 Required: {}"},{"location":"api-reference/olmv1-api-reference/#revisionstatus","title":"RevisionStatus","text":"<p>RevisionStatus defines the observed state of a ClusterExtensionRevision.</p> <p>Appears in: - ClusterExtensionStatus</p> Field Description Default Validation <code>name</code> string name of the ClusterExtensionRevision resource <code>conditions</code> Condition array conditions optionally expose Progressing and Available condition of the revision,in case when it is not yet marked as successfully installed (condition Succeeded is not set to True).Given that a ClusterExtension should remain available during upgrades, an observer may use these conditionsto get more insights about reasons for its current state. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#serviceaccountreference","title":"ServiceAccountReference","text":"<p>ServiceAccountReference identifies the serviceAccount used fo install a ClusterExtension.</p> <p>Appears in: - ClusterExtensionSpec</p> Field Description Default Validation <code>name</code> string name is a required, immutable reference to the name of the ServiceAccount used for installationand management of the content for the package specified in the packageName field.This ServiceAccount must exist in the installNamespace.The name field follows the DNS subdomain standard as defined in [RFC 1123].It must contain only lowercase alphanumeric characters, hyphens (-) or periods (.),start and end with an alphanumeric character, and be no longer than 253 characters.Some examples of valid values are:  - some-serviceaccount  - 123-serviceaccount  - 1-serviceaccount-2  - someserviceaccount  - some.serviceaccountSome examples of invalid values are:  - -some-serviceaccount  - some-serviceaccount-[RFC 1123]: https://tools.ietf.org/html/rfc1123 MaxLength: 253 Required: {}"},{"location":"api-reference/olmv1-api-reference/#sourceconfig","title":"SourceConfig","text":"<p>SourceConfig is a discriminated union which selects the installation source.</p> <p>Appears in: - ClusterExtensionSpec</p> Field Description Default Validation <code>sourceType</code> string sourceType is required and specifies the type of install source.The only allowed value is \"Catalog\".When set to \"Catalog\", information for determining the appropriate bundle of content to installis fetched from ClusterCatalog resources on the cluster.When using the Catalog sourceType, the catalog field must also be set. Enum: [Catalog] Required: {}  <code>catalog</code> CatalogFilter catalog configures how information is sourced from a catalog.It is required when sourceType is \"Catalog\", and forbidden otherwise. Optional: {}"},{"location":"api-reference/olmv1-api-reference/#sourcetype","title":"SourceType","text":"<p>Underlying type: string</p> <p>SourceType defines the type of source used for catalogs.</p> <p>Appears in: - CatalogSource - ResolvedCatalogSource</p> Field Description <code>Image</code>"},{"location":"api-reference/olmv1-api-reference/#upgradeconstraintpolicy","title":"UpgradeConstraintPolicy","text":"<p>Underlying type: string</p> <p>Appears in: - CatalogFilter</p> Field Description <code>CatalogProvided</code> The extension will only upgrade if the new version satisfiesthe upgrade constraints set by the package author. <code>SelfCertified</code> Unsafe option which allows an extension to beupgraded or downgraded to any available version of the package andignore the upgrade path designed by package authors.This assumes that users independently verify the outcome of the changes.Use with caution as this can lead to unknown and potentiallydisastrous results such as data loss."},{"location":"concepts/controlling-catalog-selection/","title":"How A ClusterExtension Is Resolved From Various Catalogs","text":""},{"location":"concepts/controlling-catalog-selection/#overview","title":"Overview","text":"<p>Here you will find guidance on how catalog selection affects which bundle is actually resolved for a given package name. These features allow you to control which catalogs are used when resolving and installing operator bundles via <code>ClusterExtension</code>. You can:</p> <ul> <li>Select specific catalogs by name or labels.</li> <li>Set priorities for catalogs to resolve ambiguities.</li> <li>Handle scenarios where multiple bundles match your criteria.</li> </ul>"},{"location":"concepts/controlling-catalog-selection/#usage-examples","title":"Usage Examples","text":""},{"location":"concepts/controlling-catalog-selection/#selecting-catalogs-by-name","title":"Selecting Catalogs by Name","text":"<p>To select a specific catalog by name, you can use the <code>matchLabels</code> field in your <code>ClusterExtension</code> resource.</p>"},{"location":"concepts/controlling-catalog-selection/#example","title":"Example","text":"<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      selector:\n        matchLabels:\n          olm.operatorframework.io/metadata.name: operatorhubio\n</code></pre> <p>In this example, only the catalog named <code>operatorhubio</code> will be considered when resolving <code>argocd-operator</code>.</p>"},{"location":"concepts/controlling-catalog-selection/#selecting-catalogs-by-labels","title":"Selecting Catalogs by Labels","text":"<p>If you have catalogs labeled with specific metadata, you can select them using <code>matchLabels</code> or <code>matchExpressions</code>.</p>"},{"location":"concepts/controlling-catalog-selection/#using-matchlabels","title":"Using <code>matchLabels</code>","text":"<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      selector:\n        matchLabels:\n          example.com/support: \"true\"\n</code></pre> <p>This selects catalogs labeled with <code>example.com/support: \"true\"</code>.</p>"},{"location":"concepts/controlling-catalog-selection/#using-matchexpressions","title":"Using <code>matchExpressions</code>","text":"<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      selector:\n        matchExpressions:\n          - key: example.com/support\n            operator: In\n            values:\n              - \"gold\"\n              - \"platinum\"\n</code></pre> <p>This selects catalogs where the label <code>example.com/support</code> has the value <code>gold</code> or <code>platinum</code>.</p>"},{"location":"concepts/controlling-catalog-selection/#excluding-catalogs","title":"Excluding Catalogs","text":"<p>You can exclude catalogs by using the <code>NotIn</code> or <code>DoesNotExist</code> operators in <code>matchExpressions</code>.</p>"},{"location":"concepts/controlling-catalog-selection/#example-exclude-specific-catalogs","title":"Example: Exclude Specific Catalogs","text":"<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      selector:\n        matchExpressions:\n          - key: olm.operatorframework.io/metadata.name\n            operator: NotIn\n            values:\n              - unwanted-catalog\n</code></pre> <p>This excludes the catalog named <code>unwanted-catalog</code> from consideration.</p>"},{"location":"concepts/controlling-catalog-selection/#example-exclude-catalogs-with-a-specific-label","title":"Example: Exclude Catalogs with a Specific Label","text":"<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      selector:\n        matchExpressions:\n          - key: example.com/support\n            operator: DoesNotExist\n</code></pre> <p>This selects catalogs that do not have the <code>example.com/support</code> label.</p>"},{"location":"concepts/controlling-catalog-selection/#setting-catalog-priority","title":"Setting Catalog Priority","text":"<p>When multiple catalogs provide the same package, you can set priorities to resolve ambiguities. Higher priority catalogs are preferred.</p>"},{"location":"concepts/controlling-catalog-selection/#defining-catalog-priority","title":"Defining Catalog Priority","text":"<p>In your <code>ClusterCatalog</code> resource, set the <code>priority</code> field:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: high-priority-catalog\nspec:\n  priority: 1000\n  source:\n    type: Image\n    image:\n      ref: quay.io/example/high-priority-content-management:latest\n</code></pre> <p>Catalogs have a default priority of <code>0</code>. The priority can be any 32-bit integer. Catalogs with higher priority values are preferred during bundle resolution.</p>"},{"location":"concepts/controlling-catalog-selection/#how-priority-resolves-ambiguity","title":"How Priority Resolves Ambiguity","text":"<p>When multiple bundles match your criteria:</p> <ol> <li>Bundles from catalogs with higher priority are selected.</li> <li>If multiple bundles are from catalogs with the same highest priority, and there is still ambiguity, an error is generated.</li> <li>Deprecated bundles are deprioritized. If non-deprecated bundles are available, deprecated ones are ignored.</li> </ol>"},{"location":"concepts/controlling-catalog-selection/#handling-ambiguity-errors","title":"Handling Ambiguity Errors","text":"<p>If the system cannot resolve to a single bundle due to ambiguity, it will generate an error. You can resolve this by:</p> <ul> <li>Refining your catalog selection criteria.</li> <li>Adjusting catalog priorities.</li> <li>Ensuring that only one bundle matches your package name and version requirements.</li> </ul>"},{"location":"concepts/controlling-catalog-selection/#end-to-end-example","title":"End to End Example","text":"<ol> <li> <p>Create or Update <code>ClusterCatalogs</code> with Appropriate Labels and Priority</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: catalog-a\n  labels:\n    example.com/support: \"true\"\nspec:\n  priority: 1000\n  source:\n    type: Image\n    image:\n      ref: quay.io/example/content-management-a:latest\n</code></pre> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: catalog-b\n  labels:\n    example.com/support: \"false\"\nspec:\n  priority: 500\n  source:\n    type: Image\n    image:\n      ref: quay.io/example/content-management-b:latest\n</code></pre> <p>Note</p> <p>An <code>olm.operatorframework.io/metadata.name</code> label will be added automatically to ClusterCatalogs when applied</p> </li> <li> <p>Create a <code>ClusterExtension</code> with Catalog Selection</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: install-my-operator\nspec:\n  namespace: my-operator-ns\n  serviceAccount:\n    name: my-operator-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: my-operator\n      selector:\n        matchLabels:\n          example.com/support: \"true\"\n</code></pre> </li> <li> <p>Apply the Resources</p> <pre><code>kubectl apply -f content-management-a.yaml\nkubectl apply -f content-management-b.yaml\nkubectl apply -f install-my-operator.yaml\n</code></pre> </li> <li> <p>Verify the Installation</p> <p>Check the status of the <code>ClusterExtension</code>:</p> <pre><code>kubectl get clusterextension install-my-operator -o yaml\n</code></pre> <p>The status should indicate that the bundle was resolved from <code>catalog-a</code> due to the higher priority and matching label.</p> </li> </ol>"},{"location":"concepts/controlling-catalog-selection/#important-notes","title":"Important Notes","text":"<ul> <li>Default Behavior: If you do not specify any catalog selection criteria, the system may select any available catalog that provides the requested package, and the choice is undefined.</li> <li>Logical AND of Selectors: When using both <code>matchLabels</code> and <code>matchExpressions</code>, catalogs must satisfy all criteria.</li> <li>Deprecation Status: Non-deprecated bundles are preferred over deprecated ones during resolution.</li> <li>Error Messages: The system will update the <code>.status.conditions</code> of the <code>ClusterExtension</code> with meaningful messages if resolution fails due to ambiguity or no catalogs being selected.</li> </ul>"},{"location":"concepts/controlling-catalog-selection/#references","title":"References","text":"<ul> <li>Minimal Controls for Selecting Catalogs to Resolve From</li> <li>RFC: Minimal Catalog Selection - Labels</li> <li>RFC: Minimal Catalog Selection - Priority</li> <li>General Concept - Working with Labels &amp; Selectors</li> </ul>"},{"location":"concepts/crd-upgrade-safety/","title":"Custom Resource Definition Upgrade Safety","text":"<p>When you update a Custom Resource Definition (CRD), OLM runs a CRD Upgrade Safety preflight check to ensure backwards compatibility with previous versions of that CRD. The CRD update must pass the validation checks before the change is allowed to progress on a cluster.</p>"},{"location":"concepts/crd-upgrade-safety/#prohibited-crd-upgrade-changes","title":"Prohibited CRD Upgrade Changes","text":"<p>The following changes to an existing CRD will be caught by the CRD Upgrade Safety preflight check and prevent the upgrade:</p> <ul> <li>The scope changes from Cluster to Namespace or from Namespace to Cluster</li> <li>An existing stored version of the CRD is removed</li> <li>A new required field is added to an existing version of the CRD</li> <li>An existing field is removed from an existing version of the CRD</li> <li>An existing field type is changed in an existing version of the CRD</li> <li>A new default value is added to a field that did not previously have a default value</li> <li>The default value of a field is changed</li> <li>An existing default value of a field is removed</li> <li>New enum restrictions are added to an existing field which did not previously have enum restrictions</li> <li>Existing enum values from an existing field are removed</li> <li>The minimum value of an existing field is increased in an existing version</li> <li>The maximum value of an existing field is decreased in an existing version</li> <li>Minimum or maximum field constraints are added to a field that did not previously have constraints</li> </ul> <p>Note</p> <p>The rules for changes to minimum and maximum values apply to <code>minimum</code>, <code>minLength</code>, <code>minProperties</code>, <code>minItems</code>, <code>maximum</code>, <code>maxLength</code>, <code>maxProperties</code>, and <code>maxItems</code> constraints.</p> <p>If the CRD Upgrade Safety preflight check encounters one of the disallowed upgrade changes, it will log an error for each disallowed change detected in the CRD upgrade.</p> <p>Tip</p> <p>In cases where a change to the CRD does not fall into one of the disallowed change categories but is also unable to be properly detected as allowed, the CRD Upgrade Safety preflight check will prevent the upgrade and log an error for an \"unknown change.\"</p> <p>If you identify any preflight checks that should be implemented to prevent issues during CRD upgrades, please create a new issue.</p>"},{"location":"concepts/crd-upgrade-safety/#allowed-crd-upgrade-changes","title":"Allowed CRD Upgrade Changes","text":"<p>The following changes to an existing CRD are safe for backwards compatibility and will not cause the CRD Upgrade Safety preflight check to halt the upgrade:</p> <ul> <li>Adding new enum values to the list of allowed enum values in a field</li> <li>An existing required field is changed to optional in an existing version</li> <li>The minimum value of an existing field is decreased in an existing version</li> <li>The maximum value of an existing field is increased in an existing version</li> <li>A new version of the CRD is added with no modifications to existing versions</li> </ul>"},{"location":"concepts/crd-upgrade-safety/#disabling-crd-upgrade-safety","title":"Disabling CRD Upgrade Safety","text":"<p>The CRD Upgrade Safety preflight check can be entirely disabled by adding the <code>.spec.install.preflight.crdUpgradeSafety.enforcement</code> field with a value of <code>None</code> to the <code>ClusterExtension</code> of the CRD.</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.6.0\n  install:\n    preflight:\n      crdUpgradeSafety:\n        enforcement: None\n</code></pre> <p>You cannot disable individual field validators. If you disable the CRD Upgrade Safety preflight check, all field validators are disabled.</p> <p>Warning</p> <p>Disabling the CRD Upgrade Safety preflight check could break backwards compatibility with stored versions of the CRD and cause other unintended consequences on the cluster.</p>"},{"location":"concepts/crd-upgrade-safety/#examples-of-unsafe-crd-changes","title":"Examples of Unsafe CRD Changes","text":"<p>Take the following CRD as our starting version:</p> <pre><code>---\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  annotations:\n    controller-gen.kubebuilder.io/version: v0.13.0\n  name: example.test.example.com\nspec:\n  group: test.example.com\n  names:\n    kind: Sample\n    listKind: SampleList\n    plural: samples\n    singular: sample\n  scope: Namespaced\n  versions:\n  - name: v1alpha1\n    schema:\n      openAPIV3Schema:\n        properties:\n          apiVersion:\n            type: string\n          kind:\n            type: string\n          metadata:\n            type: object\n          spec:\n            type: object\n          status:\n            type: object\n          pollInterval:\n            type: string\n        type: object\n    served: true\n    storage: true\n    subresources:\n      status: {}\n</code></pre> <p>The following examples will demonstrate specific changes to sections of the example CRD that would be caught by the CRD Upgrade Safety preflight check.</p>"},{"location":"concepts/crd-upgrade-safety/#changing-scope","title":"Changing Scope","text":"<p>In this example, <code>scope</code> has been changed from <code>Namespaced</code> to <code>Cluster</code>.</p> Example <pre><code>spec:\n  group: test.example.com\n  names:\n    kind: Sample\n    listKind: SampleList\n    plural: samples\n    singular: sample\n  scope: Cluster\n  versions:\n  - name: v1alpha1\n</code></pre> Error output <pre><code>validating upgrade for CRD \"test.example.com\" failed: CustomResourceDefinition test.example.com failed upgrade safety validation. \"NoScopeChange\" validation failed: scope changed from \"Namespaced\" to \"Cluster\"\n</code></pre>"},{"location":"concepts/crd-upgrade-safety/#removing-a-stored-version","title":"Removing a stored version","text":"<p>In this example, the existing stored version, <code>v1alpha1</code>, has been removed:</p> Example <pre><code>  versions:\n  - name: v1alpha2\n    schema:\n      openAPIV3Schema:\n        properties:\n          apiVersion:\n            type: string\n          kind:\n            type: string\n          metadata:\n            type: object\n          spec:\n            type: object\n          status:\n            type: object\n          pollInterval:\n            type: string\n        type: object\n</code></pre> Error output <pre><code>validating upgrade for CRD \"test.example.com\" failed: CustomResourceDefinition test.example.com failed upgrade safety validation. \"NoStoredVersionRemoved\" validation failed: stored version \"v1alpha1\" removed\n</code></pre>"},{"location":"concepts/crd-upgrade-safety/#removing-an-existing-field","title":"Removing an existing field","text":"<p>In this example, the <code>pollInterval</code> field has been removed from <code>v1alpha1</code>:</p> Example <pre><code>  versions:\n  - name: v1alpha1\n    schema:\n      openAPIV3Schema:\n        properties:\n          apiVersion:\n            type: string\n          kind:\n            type: string\n          metadata:\n            type: object\n          spec:\n            type: object\n          status:\n            type: object\n        type: object\n</code></pre> Error output <pre><code>validating upgrade for CRD \"test.example.com\" failed: CustomResourceDefinition test.example.com failed upgrade safety validation. \"NoExistingFieldRemoved\" validation failed: crd/test.example.com version/v1alpha1 field/^.spec.pollInterval may not be removed\n</code></pre>"},{"location":"concepts/crd-upgrade-safety/#adding-a-required-field","title":"Adding a required field","text":"<p>In this example, <code>pollInterval</code> has been changed to a required field:</p> Example <pre><code>  versions:\n  - name: v1alpha2\n    schema:\n      openAPIV3Schema:\n        properties:\n          apiVersion:\n            type: string\n          kind:\n            type: string\n          metadata:\n            type: object\n          spec:\n            type: object\n          status:\n            type: object\n          pollInterval:\n            type: string\n        type: object\n        required:\n        - pollInterval\n</code></pre> Error output <pre><code>validating upgrade for CRD \"test.example.com\" failed: CustomResourceDefinition test.example.com failed upgrade safety validation. \"ChangeValidator\" validation failed: version \"v1alpha1\", field \"^\": new required fields added: [pollInterval]\n</code></pre>"},{"location":"concepts/permission-model/","title":"Permission model","text":""},{"location":"concepts/permission-model/#olmv1-permission-model","title":"OLMv1 Permission Model","text":"<p>Here we aim to describe the OLMv1 permission model. OLMv1 itself does not have cluster-wide admin permissions. Therefore, each cluster extension must specify a service account with sufficient permissions to install and manage it. While this service account is distinct from any service account defined in the bundle, it will need sufficient privileges to create and assign the required RBAC. Therefore, the cluster extension service account's privileges would be a superset of the privileges required by the service account in the bundle.</p> <p>To understand the permission model, lets see the scope of the the service accounts associated with ClusterExtension deployment:</p>"},{"location":"concepts/permission-model/#service-account-associated-with-the-clusterextension-cr","title":"Service Account associated with the ClusterExtension CR","text":"<p>1) The ClusterExtension CR defines a service account to deploy and manage the ClusterExtension lifecycle and can be derived using the document. It is specified in the ClusterExtension yaml while deploying a ClusterExtension. 2) The purpose of the service account specified in the ClusterExtension spec is to manage the cluster extension lifecycle. Its permissions are the cumulative of the permissions required for managing the cluster extension lifecycle and any RBAC that maybe included in the extension bundle. 3) Since the extension bundle contains its own RBAC, it means the ClusterExtension service account requires either: - the same set of permissions that are defined in the RBAC that it is trying to create. - bind/escalate verbs for RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#privilege-escalation-prevention-and-bootstrapping</p>"},{"location":"concepts/permission-model/#service-accounts-part-of-the-extension-bundle","title":"Service Account/(s) part of the Extension Bundle","text":"<p>1) The contents of the extension bundle may contain more service accounts and RBAC. 2) The OLMv1 operator-controller creates the service account/(s) defined as part of the extension bundle with the required RBAC for the controller business logic.</p>"},{"location":"concepts/permission-model/#example","title":"Example:","text":"<p>Lets consider deployment of the ArgoCD operator. The ClusterExtension ClusterResource specifies a service account as part of its spec, usually denoted as the ClusterExtension installer service account.  The ArgoCD operator specifies the <code>argocd-operator-controller-manager</code> service account with necessary RBAC for the bundle resources and OLMv1 creates it as part of this extension bundle deployment.</p> <p>The extension bundle CSV contains the permissions and cluster permissions allow the operator to manage and run the controller logic. These permissions are assigned to the <code>argocd-operator-controller-manager</code> service account when the operator bundle is deployed.</p> <p>OLM v1 will assign all the RBAC specified in the extension bundle to the above service account. The ClusterExtension installer service account will need all the RBAC specified for the <code>argocd-operator-controller-manager</code> and additional RBAC for deploying the ClusterExtension.</p> <p>Note: The ClusterExtension permissions are not propogated to the deployment. The ClusterExtension service account and the bundle's service accounts have different purposes and naming conflicts between the two service accounts can lead to failure of ClusterExtension deployment.</p>"},{"location":"concepts/single-owner-objects/","title":"OLM Ownership Enforcement for <code>ClusterExtensions</code>","text":"<p>In OLM, a Kubernetes resource can only be owned by a single <code>ClusterExtension</code> at a time. This ensures that resources within a Kubernetes cluster are managed consistently and prevents conflicts between multiple <code>ClusterExtensions</code> attempting to control the same resource.</p>"},{"location":"concepts/single-owner-objects/#key-concept-single-ownership","title":"Key Concept: Single Ownership","text":"<p>The core principle enforced by OLM is that each resource can only have one <code>ClusterExtension</code> as its owner. This prevents overlapping or conflicting management by multiple <code>ClusterExtensions</code>, ensuring that each resource is uniquely associated with only one operator bundle.</p>"},{"location":"concepts/single-owner-objects/#implications-of-single-ownership","title":"Implications of Single Ownership","text":""},{"location":"concepts/single-owner-objects/#1-operator-bundles-that-provide-a-crd-can-only-be-installed-once","title":"1. Operator Bundles That Provide a CRD Can Only Be Installed Once","text":"<p>Operator bundles provide <code>CustomResourceDefinitions</code> (CRDs), which are part of a <code>ClusterExtension</code>. This means a bundle can only be installed once in a cluster. Attempting to install another bundle that provides the same CRDs will result in a failure, as each custom resource can have only one <code>ClusterExtension</code> as its owner.</p>"},{"location":"concepts/single-owner-objects/#2-clusterextensions-cannot-share-objects","title":"2. <code>ClusterExtensions</code> Cannot Share Objects","text":"<p>OLM's single-owner policy means that <code>ClusterExtensions</code> cannot share ownership of any resources. If one <code>ClusterExtension</code> manages a specific resource (e.g., a <code>Deployment</code>, <code>CustomResourceDefinition</code>, or <code>Service</code>), another <code>ClusterExtension</code> cannot claim ownership of the same resource. Any attempt to do so will be blocked by the system.</p>"},{"location":"concepts/single-owner-objects/#error-messages","title":"Error Messages","text":"<p>When a conflict occurs due to multiple <code>ClusterExtensions</code> attempting to manage the same resource, <code>operator-controller</code> will return a clear error message, indicating the ownership conflict.</p> <ul> <li>Example Error:   <pre><code>CustomResourceDefinition 'logfilemetricexporters.logging.kubernetes.io' already exists in namespace 'kubernetes-logging' and cannot be managed by operator-controller\n</code></pre></li> </ul> <p>This error message signals that the resource is already being managed by another <code>ClusterExtension</code> and cannot be reassigned or \"shared.\"</p>"},{"location":"concepts/single-owner-objects/#what-this-means-for-you","title":"What This Means for You","text":"<ul> <li>Uniqueness of Operator Bundles: Ensure that operator bundles providing the same CRDs are not installed more than once. This can prevent potential installation failures due to ownership conflicts.</li> <li>Avoid Resource Sharing: If you need different <code>ClusterExtensions</code> to interact with similar resources, ensure they are managing separate resources. <code>ClusterExtensions</code> cannot jointly manage the same resource due to the single-owner enforcement.</li> </ul>"},{"location":"concepts/upgrade-support/","title":"Upgrade support","text":"<p>This document explains how OLM v1 handles upgrades.</p> <p>OLM v1 introduces a simplified UX for package authors and package admins to implicitly define upgrade edges via Semantic Versioning.</p> <p>It also introduces an API to enable independently verified upgrades and downgrades.</p>"},{"location":"concepts/upgrade-support/#upgrade-constraint-semantics","title":"Upgrade constraint semantics","text":"<p>When determining upgrade edges, also known as upgrade paths or upgrade constraints, for an installed cluster extension, Operator Lifecycle Manager (OLM) v1 supports legacy OLM semantics by default. This support follows the behavior from legacy OLM, including <code>replaces</code>, <code>skips</code>, and <code>skipRange</code> directives, with a few noted differences.</p> <p>By supporting legacy OLM semantics, OLM v1 honors the upgrade graph from catalogs accurately.</p> <p>If there are multiple possible successors, OLM v1 behavior differs in the following ways:</p> <ul> <li>In legacy OLM, the successor closest to the channel head is chosen.</li> <li>In OLM v1, the successor with the highest semantic version (semver) is chosen.</li> </ul> <p>Consider the following set of file-based catalog (FBC) channel entries:</p> <pre><code># ...\n- name: example.v3.0.0\n  skips: [\"example.v2.0.0\"]\n- name: example.v2.0.0\n  skipRange: \"&gt;=1.0.0 &lt;2.0.0\"\n</code></pre> <p>If <code>1.0.0</code> is installed, OLM v1 behavior differs in the following ways:</p> <ul> <li>Legacy OLM does not detect an upgrade edge to <code>v2.0.0</code> because <code>v2.0.0</code> is skipped and not on the <code>replaces</code> chain.</li> <li>OLM v1 detects the upgrade edge because OLM v1 does not have a concept of a <code>replaces</code> chain. OLM v1 finds all entries that have a <code>replace</code>, <code>skip</code>, or <code>skipRange</code> value that covers the currently installed version.</li> </ul> <p>You can change the default behavior of the upgrade constraints by setting the <code>upgradeConstraintPolicy</code> parameter in your cluster extension's custom resource (CR).</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: &lt;extension_name&gt;\nspec:\n  namespace: &lt;namespace&gt;\n  serviceAccount:\n    name: &lt;service_account&gt;\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: &lt;package_name&gt;\n      version: \"&lt;version_or_version_range&gt;\"\n      upgradeConstraintPolicy: SelfCertified\n</code></pre> <p>Setting the <code>upgradeConstraintPolicy</code> to:</p> <code>SelfCertified</code> Does not limit the next version to the set of successors, and instead allows for any downgrade, sidegrade, or upgrade. <code>CatalogProvided</code> Only allows the next version to come from the successors list. This is the default value. If the <code>upgradeConstraintPolicy</code> parameter is not defined in an extension's CR, then the policy is set to <code>CatalogProvided</code> by default."},{"location":"concepts/upgrade-support/#upgrades","title":"Upgrades","text":"<p>OLM supports Semver to provide a simplified way for package authors to define compatible upgrades. According to the Semver standard, releases within a major version (e.g. <code>&gt;=1.0.0 &lt;2.0.0</code>) must be compatible. As a result, package authors can publish a new package version following the Semver specification, and OLM assumes compatibility. Package authors do not have to explicitly define upgrade edges in the catalog.</p> <p>Note</p> <p>Currently, OLM 1.0 does not support automatic upgrades to the next major version. You must manually verify and perform major version upgrades. For more information about major version upgrades, see Manually verified upgrades and downgrades.</p>"},{"location":"concepts/upgrade-support/#upgrades-within-the-major-version-zero","title":"Upgrades within the major version zero","text":"<p>According to the Semver specification, a major version zero release is for initial development. It is assumed that breaking changes might be introduced at any time. As a result, the following special conditions apply to upgrades within a major version zero release:</p> <ul> <li>You cannot automatically upgrade from one patch version to another when both major and minor versions are <code>0</code>. For example, automatic upgrades within the following version range are not allowed: <code>&gt;= 0.0.1 &lt;0.1.0</code>.</li> <li>You cannot automatically upgrade from one minor version to another minor version within the major version zero. For example, no upgrades from <code>0.1.0</code> to <code>0.2.0</code>. However, you can upgrade from patch versions. For example, upgrades are possible in ranges <code>&gt;= 0.1.0 &lt;0.2.0</code>, <code>&gt;= 0.2.0 &lt;0.3.0</code>, <code>&gt;= 0.3.0 &lt;0.4.0</code>, and so on.</li> </ul> <p>You must verify and perform upgrades manually in cases where automatic upgrades are blocked.</p>"},{"location":"concepts/upgrade-support/#manually-verified-upgrades-and-downgrades","title":"Manually verified upgrades and downgrades","text":"<p>Warning</p> <p>If you want to force an upgrade manually, you must thoroughly verify the outcome before applying any changes to production workloads. Failure to test and verify the upgrade might lead to catastrophic consequences such as data loss.</p> <p>As a package admin, if you must upgrade or downgrade to version that might be incompatible with the currently installed version, you can set the <code>.spec.source.catalog.upgradeConstraintPolicy</code> field to <code>SelfCertified</code> on the relevant <code>ClusterExtension</code> resource.</p> <p>If you set the field to <code>SelfCertified</code>, no upgrade constraints are set on the package. As a result, you can change the version to any version available in the catalogs for a given package.</p> <p>Example <code>ClusterExtension</code> with <code>.spec.source.catalog.upgradeConstraintPolicy</code> field set to <code>SelfCertified</code>:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: extension-sample\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.6.0\n      upgradeConstraintPolicy: SelfCertified\n</code></pre>"},{"location":"concepts/version-ranges/","title":"Extension version ranges","text":"<p>This document explains how to specify a version range to install or update an extension with OLM 1.0.</p> <p>You define a version range in a ClusterExtension's custom resource (CR) file.</p>"},{"location":"concepts/version-ranges/#specifying-a-version-range-in-the-cr","title":"Specifying a version range in the CR","text":"<p>If you specify a version range in the ClusterExtension's CR, OLM 1.0 installs or updates the latest version of the extension that can be resolved within the version range. The resolved version is the latest version of the extension that satisfies the dependencies and constraints of the extension and the environment. Extension updates within the specified range are automatically installed if they can be resolved successfully. Updates are not installed if they are outside of the specified range or if they cannot be resolved successfully.</p>"},{"location":"concepts/version-ranges/#comparisons","title":"Comparisons","text":"<p>You define a version range by adding a comparison string to the <code>spec.version</code> field. A comparison string is composed of a list of comma or space separated values and one or more comparison operators. You can add an additional comparison string by including an OR (<code>||</code>) operator between the strings.</p>"},{"location":"concepts/version-ranges/#basic-comparisons","title":"Basic comparisons","text":"Operator Definition <code>=</code> equal (not aliased to an operator) <code>!=</code> not equal <code>&gt;</code> greater than <code>&lt;</code> less than <code>&gt;=</code> greater than or equal to <code>&lt;=</code> less than or equal to"},{"location":"concepts/version-ranges/#range-comparisons","title":"Range comparisons","text":"<p>To specify a version range, use a range comparison similar to the following example:</p> <pre><code>version: \"&gt;=3.0, &lt;3.6\"\n</code></pre>"},{"location":"concepts/version-ranges/#wildcards-in-comparisons","title":"Wildcards in comparisons","text":"<p>You can use the <code>x</code>, <code>X</code>, and <code>*</code> characters as wildcard characters in all comparison operations. If you use a wildcard character with the <code>=</code> operator, you define a patch level comparision. This is equivalent to making a tilde range comparison.</p> <p>Example comparisons with wildcard characters</p> Comparison Equivalent <code>1.2.x</code> <code>&gt;= 1.2.0, &lt; 1.3.0</code> <code>&gt;= 1.2.x</code> <code>&gt;= 1.2.0</code> <code>&lt;= 2.x</code> <code>&lt; 3</code> <code>*</code> <code>&gt;= 0.0.0</code>"},{"location":"concepts/version-ranges/#patch-release-or-tilde-range-comparison","title":"Patch release or tilde (<code>~</code>) range comparison","text":"<p>You can use the tilde (<code>~</code>) operator to make patch release comparisons. This is useful when you want to specify a minor version up to the next major version.</p> <p>Example patch release comparisons</p> Comparison Equivalent <code>~1.2.3</code> <code>&gt;= 1.2.3, &lt; 1.3.0</code> <code>~1</code> <code>&gt;= 1, &lt;2</code> <code>~2.3</code> <code>&gt;= 2.3, &lt; 2.4</code> <code>~1.2.x</code> <code>&gt;= 1.2.0, &lt; 1.3.0</code> <code>~1.x</code> <code>&gt;= 1, &lt; 2</code>"},{"location":"concepts/version-ranges/#major-release-or-caret-range-comparisons","title":"Major release or caret (<code>^</code>) range comparisons","text":"<p>You can use the caret (<code>^</code>) operator to make major release comparisons after a stable, <code>1.0.0</code>, version is published. If you make a major release comparison before a stable version is published, minor versions define the API stability level.</p> <p>Example major release comparisons</p> Comparison Equivalent <code>^1.2.3</code> <code>&gt;= 1.2.3, &lt; 2.0.0``&gt;= 1.2.3, &lt; 2.0.0</code> <code>^1.2.x</code> <code>&gt;= 1.2.0, &lt; 2.0.0</code> <code>^2.3</code> <code>&gt;= 2.3, &lt; 3</code> <code>^2.x</code> <code>&gt;= 2.0.0, &lt; 3</code> <code>^0.2.3</code> <code>&gt;=0.2.3 &lt;0.3.0</code> <code>^0.2</code> <code>&gt;=0.2.0 &lt;0.3.0</code> <code>^0.0.3</code> <code>&gt;=0.0.3 &lt;0.0.4</code> <code>^0.0</code> <code>&gt;=0.0.0 &lt;0.1.0</code> <code>^0</code> <code>&gt;=0.0.0 &lt;1.0.0</code>"},{"location":"contribute/contributing/","title":"How to Contribute","text":"<p>Operator Controller is an Apache 2.0 licensed project and accepts contributions via GitHub pull requests (PRs).</p>"},{"location":"contribute/contributing/#certificate-of-origin","title":"Certificate of Origin","text":"<p>By contributing to this project you agree to the Developer Certificate of Origin (DCO). This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution. See the DCO file for details.</p>"},{"location":"contribute/contributing/#overview","title":"Overview","text":"<p>Thank you for your interest in contributing to the Operator-Controller.</p> <p>As you may or may not know, the Operator-Controller project aims to deliver the user experience described in the Operator Lifecycle Manager (OLM) V1 Product Requirements Document (PRD). The design requirements captured in the OLM V1 PRD were born from customer and community feedback based on the experience they had with the released version of OLM V0.</p> <p>The user experience captured in the OLM V1 PRD introduces many requirements that are best satisfied by a microservices architecture. The OLM V1 experience currently relies on two components:</p> <ul> <li>Operator-Controller, which is the top level component allowing users to specify operators they'd like to install.</li> <li>Catalogd, which hosts operator content and helps users discover installable content.</li> </ul>"},{"location":"contribute/contributing/#how-do-we-collaborate","title":"How do we collaborate","text":"<p>\"We need to accept that random issues and pull requests will show up\" - Joe L.</p> <p>Before diving into our process for coordinating community efforts, I think it's important to set the expectation that Open Source development can be messy. Any effort to introduce a formal workflow for project contributions will almost certainly be circumvented by new community users. Rather than pestering users to subscribe to a project-specific process, we strive to make it as simple as possible to provide valuable feedback. With that in mind, changes to the project will almost certainly follow this process:</p> <ol> <li>The community engages in discussion in the #olm-dev slack channel.</li> <li>The community creates GitHub Issues, GitHub Discussions, or pull requests in the appropriate repos based on (1) to continue the discussion.</li> <li>The community utilizes the Working Group Meeting to talk about items from (1) and (2) as well as anything else that comes to mind.</li> </ol> <p>The workflow defined above implies that the community is always ready for discussion and that ongoing work can be found in the GitHub repository as GitHub Issues, GitHub Discussions, or pull requests, and that milestone planning is async, happening as part of (1), (2), and (3).</p> <p>Please keep this workflow in mind as you read through the document.</p>"},{"location":"contribute/contributing/#how-to-build-and-deploy-locally","title":"How to Build and Deploy Locally","text":"<p>After creating a fork and cloning the project locally, you can follow the steps below to test your changes:</p> <ol> <li> <p>Create the cluster:</p> <pre><code>kind create cluster -n operator-controller\n</code></pre> </li> <li> <p>Build your changes:</p> <pre><code>make build docker-build\n</code></pre> </li> <li> <p>Load the image locally and Deploy to Kind</p> <pre><code>make kind-load kind-deploy\n</code></pre> </li> </ol>"},{"location":"contribute/contributing/#how-to-debug-controller-tests-using-envtest","title":"How to debug controller tests using ENVTEST","text":"<p>ENVTEST requires k8s binaries to be downloaded to run the tests. To download the necessary binaries, follow the steps below:</p> <pre><code>make envtest-k8s-bins\n</code></pre> <p>Note that the binaries are downloaded to the <code>bin/envtest-binaries</code> directory.</p> <pre><code>$ tree\n.\n\u251c\u2500\u2500 envtest-binaries\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 k8s\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 1.31.0-darwin-arm64\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 etcd\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 kube-apiserver\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 kubectl\n</code></pre> <p>Now, you can debug them with your IDE:</p> <p></p>"},{"location":"contribute/contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>Email: operator-framework-olm-dev</li> <li>Slack: #olm-dev</li> <li>Google Group: olm-gg</li> <li>Weekly in Person Working Group Meeting: olm-wg</li> </ul>"},{"location":"contribute/contributing/#how-are-milestones-designed","title":"How are Milestones Designed?","text":"<p>It's unreasonable to attempt to consider all of the design requirements laid out in the OLM V1 PRD from the onset of the project. Instead, the community attempts to design Milestones with the following principles:</p> <ul> <li>Milestones are tightly scoped units of work, ideally lasting one to three weeks.</li> <li>Milestones are derived from the OLM V1 PRD.</li> <li>Milestones are \"demo driven\", meaning that a set of acceptance criteria is defined upfront and the milestone is done as soon as some member of the community can run the demo.</li> <li>Edge cases found during development are captured in issues and assigned to the GA Milestone, which contains a list of issues that block the release of operator-controller v1.0.0 .</li> </ul> <p>This \"demo driven\" development model will allow us to collect user experience and regularly course correct based on user feedback. Subsequent milestone may revert features or change the user experience based on community feedback.</p> <p>The project maintainer will create a GitHub Discussion for the upcoming milestone once we've finalized the current milestone. Please feel encouraged to contribute suggestions for the milestone in the discussion.</p>"},{"location":"contribute/contributing/#where-are-operator-controller-milestones","title":"Where are Operator Controller Milestones?","text":"<p>Ongoing or previous Operator-Controller milestones can always be found in the milestone section of our GitHub Repo.</p>"},{"location":"contribute/contributing/#how-are-subproject-issues-tracked","title":"How are Subproject Issues Tracked?","text":"<p>As discussed earlier, the operator-controller adheres to a microservice architecture, where multiple projects contribute to the overall experience. As such, when designing an operator-controller milestone, the community may need to file an issue against Catalogd. Unfortunately, the operator-controller milestone cannot contain issues from one of its subprojects. As such, we've introduced the concept of a \"Dependency Issue\", described below:</p> <p>Dependency Issues: An issue tracked in a milestone that \"points\" to an issue in another project with a URL.</p>"},{"location":"contribute/contributing/#submitting-issues","title":"Submitting Issues","text":"<p>Unsure where to submit an issue?</p> <ul> <li>Operator-Controller, which contains both components, is the project allowing users to specify operators they'd like to install.</li> </ul>"},{"location":"contribute/contributing/#submitting-pull-requests","title":"Submitting Pull Requests","text":""},{"location":"contribute/contributing/#code-review","title":"Code Review","text":"<p>Contributing PRs with a reasonable title and description can go a long way with helping the PR through the review process.</p> <p>When opening PRs that are in a rough draft or WIP state, prefix the PR description with <code>WIP: ...</code> or create a draft PR. This can help save reviewer's time by communicating the state of a PR ahead of time. Draft/WIP PRs can be a good way to get early feedback from reviewers on the implementation, focusing less on smaller details, and more on the general approach of changes.</p> <p>When contributing changes that require a new dependency, check whether it's feasible to directly vendor that code without introducing a new dependency.</p> <p>Currently, PRs require at least one approval from an operator-controller maintainer in order to get merged.</p>"},{"location":"contribute/contributing/#code-style","title":"Code style","text":"<p>The coding style suggested by the Golang community is used throughout the operator-controller project:</p> <ul> <li>CodeReviewComments</li> <li>EffectiveGo</li> </ul> <p>In addition to the linked style documentation, operator-controller formats Golang packages using the <code>golangci-lint</code> tool. Before submitting a PR, please run <code>make lint</code> locally and commit the results. This will help expedite the review process, focusing less on style conflicts, and more on the design and implementation details.</p> <p>Please follow this style to make the operator-controller project easier to review, maintain and develop.</p>"},{"location":"contribute/contributing/#go-version","title":"Go version","text":"<p>Our goal is to minimize disruption by requiring the lowest possible Go language version. This means avoiding updaties to the go version specified in the project's <code>go.mod</code> file (and other locations).</p> <p>There is a GitHub PR CI job named <code>go-verdiff</code> that will inform a PR author if the Go language version has been updated. It is not a required test, but failures should prompt authors and reviewers to have a discussion with the community about the Go language version change. </p> <p>There may be ways to avoid a Go language version change by using not-the-most-recent versions of dependencies. We do acknowledge that CVE fixes might require a specific dependency version that may have updated to a newer version of the Go language.</p>"},{"location":"contribute/contributing/#documentation","title":"Documentation","text":"<p>If the contribution changes the existing APIs or user interface it must include sufficient documentation to explain the new or updated features.</p> <p>The Operator Controller documentation is primarily housed at the root-level README.</p>"},{"location":"contribute/developer/","title":"Developing OLM v1","text":""},{"location":"contribute/developer/#getting-started","title":"Getting Started","text":"<p>The following <code>make run</code> starts a KIND cluster for you to get a local cluster for testing, see the manual install steps below for how to run against a remote cluster.</p> <p>Note</p> <p>You will need a container runtime environment like Docker to run Kind. Kind also has experimental support for Podman.</p> <p>If you are on MacOS, see Special Setup for MacOS.</p>"},{"location":"contribute/developer/#quickstart-installation","title":"Quickstart Installation","text":"<p>First, you need to install the CRDs and the operator-controller into a new KIND cluster. You can do this by running:</p> <pre><code>make run\n</code></pre> <p>This will build a local container image of the operator-controller, create a new KIND cluster and then deploy onto that cluster. This will also deploy the catalogd and cert-manager dependencies.</p>"},{"location":"contribute/developer/#to-install-any-given-release","title":"To Install Any Given Release","text":"<p>Warning</p> <p>Operator-Controller depends on cert-manager. Running the following command may affect an existing installation of cert-manager and cause cluster instability.</p> <p>The latest version of Operator Controller can be installed with the following command:</p> <pre><code>curl -L -s https://github.com/operator-framework/operator-controller/releases/latest/download/install.sh | bash -s\n</code></pre>"},{"location":"contribute/developer/#manual-step-by-step-installation","title":"Manual Step-by-Step Installation","text":"<ol> <li> <p>Install Instances of Custom Resources:</p> <pre><code>kubectl apply -f config/samples/\n</code></pre> </li> <li> <p>Build and push your image to the location specified by <code>IMG</code>:</p> <pre><code>make docker-build docker-push IMG=&lt;some-registry&gt;/operator-controller:tag\n</code></pre> </li> <li> <p>Deploy the controller to the cluster with the image specified by <code>IMG</code>:</p> <pre><code>make deploy IMG=&lt;some-registry&gt;/operator-controller:tag\n</code></pre> </li> </ol>"},{"location":"contribute/developer/#modifying-the-api-definitions","title":"Modifying the API definitions","text":"<p>If you are editing the API definitions, generate the manifests such as CRs or CRDs using:</p> <pre><code>make manifests\n</code></pre> <p>Note</p> <p>Run <code>make help</code> for more information on all potential <code>make</code> targets.</p>"},{"location":"contribute/developer/#rapid-iterative-development-with-tilt","title":"Rapid Iterative Development with Tilt","text":"<p>If you are developing against the combined ecosystem of catalogd + operator-controller, you will want to take advantage of <code>tilt</code>:</p> <p>Tilt is a tool that enables rapid iterative development of containerized workloads.</p> <p>Here is an example workflow without Tilt for modifying some source code and testing those changes in a cluster:</p> <ol> <li>Modify the source code.</li> <li>Build the container image.</li> <li>Either push the image to a registry or load it into your kind cluster.</li> <li>Deploy all the appropriate Kubernetes manifests for your application.</li> </ol> <p>This process can take minutes, depending on how long each step takes.</p> <p>Here is the same workflow with Tilt:</p> <ol> <li>Run <code>tilt up</code></li> <li>Modify the source code</li> <li>Wait for Tilt to update the container with your changes</li> </ol> <p>This ends up taking a fraction of the time, sometimes on the order of a few seconds!</p>"},{"location":"contribute/developer/#installing-tilt","title":"Installing Tilt","text":"<p>Follow Tilt's instructions for installation.</p>"},{"location":"contribute/developer/#installing-catalogd","title":"Installing catalogd","text":"<p>operator-controller requires catalogd. When you give a <code>tilt up</code> invocation, catalogd will be started along with operator-controller.</p>"},{"location":"contribute/developer/#starting-tilt","title":"Starting Tilt","text":"<p>This is typically as short as:</p> <pre><code>tilt up\n</code></pre> <p>Note</p> <p>If you are using Podman, at least as of v4.5.1, you need to do this:</p> <pre><code>DOCKER_BUILDKIT=0 tilt up\n</code></pre> <p>Otherwise, you'll see an error when Tilt tries to build your image that looks similar to:</p> <pre><code>Build Failed: ImageBuild: stat /var/tmp/libpod_builder2384046170/build/Dockerfile: no such file or directory\n</code></pre> <p>When Tilt starts, you'll see something like this in your terminal:</p> <pre><code>Tilt started on http://localhost:10350/\nv0.33.1, built 2023-06-28\n\n(space) to open the browser\n(s) to stream logs (--stream=true)\n(t) to open legacy terminal mode (--legacy=true)\n(ctrl-c) to exit\n</code></pre> <p>At the end of the installation process, the command output will prompt you to press the space bar to open the web UI, which provides a useful overview of all the installed components.</p> <p>Shortly after starting, Tilt processes the <code>Tiltfile</code>, resulting in:</p> <ul> <li>Building the go binaries</li> <li>Building the images</li> <li>Loading the images into kind</li> <li>Running kustomize and applying everything except the Deployments that reference the images above</li> <li>Modifying the Deployments to use the just-built images</li> <li>Creating the Deployments</li> </ul>"},{"location":"contribute/developer/#using-the-claude-local-development-environment-sub-agent","title":"Using the Claude local development environment sub-agent","text":"<p>The repository contains a configuration for a Claude sub-agent that can help walk you through the process of setting up your local development environment. If you are using Claude, simply ask it for assistance in setting up the local development environment and it should suggest using the local development environment specialist sub-agent. For example:</p> <pre><code>&gt; Can you help me set up a local dev environment?\n\n\u25cf I'll help you set up the local development environment for this OLM v1 project. Since this project has a specialized sub-agent for\n  local development setup, I'll use that to guide you through the complete process.\n\n---\n\n&gt; I need help setting up a local dev env\n\n\u25cf I'll help you set up a local development environment for the operator-controller project. Since this involves setting up a complete\n  development environment with multiple components, I'll use the specialized OLM development environment agent to guide you through the\n  process.\n</code></pre> <p>The sub-agent is designed to assist with: - Checking for all the necessary tooling and installing missing binaries - Helping with OS-specific configuration - Running and monitoring the kind cluster and Tilt server</p> <p>As with all LLM-based tooling, always use good judgement and verify its suggestions. This is not intended as a substitute for the concrete instructions in the rest of the project documentation.</p>"},{"location":"contribute/developer/#special-setup-for-macos","title":"Special Setup for MacOS","text":"<p>Some additional setup is necessary on Macintosh computers to install and configure compatible tooling.</p>"},{"location":"contribute/developer/#install-homebrew-and-tools","title":"Install Homebrew and tools","text":"<p>Follow the instructions to install Homebrew, and then execute the following command to install the required tools:</p> <pre><code>brew install bash gnu-tar gsed coreutils\n</code></pre>"},{"location":"contribute/developer/#configure-your-shell","title":"Configure your shell","text":"<p>To configure your shell, either add this to your bash or zsh profile (e.g., in $HOME/.bashrc or $HOME/.zshrc), or run the following command in the terminal:</p> <pre><code>for bindir in `find $(brew --prefix)/opt -type d -follow -name gnubin -print -maxdepth 3`\ndo\n  export PATH=$bindir:$PATH\ndone\n</code></pre>"},{"location":"contribute/developer/#making-code-changes","title":"Making code changes","text":"<p>Any time you change any of the files listed in the <code>deps</code> section in the <code>&lt;binary name&gt;_binary</code> <code>local_resource</code>, Tilt automatically rebuilds the go binary. As soon as the binary is rebuilt, Tilt pushes it (and only it) into the appropriate running container, and then restarts the process.</p>"},{"location":"contribute/developer/#contributing","title":"Contributing","text":"<p>Refer to CONTRIBUTING.md for more information.</p>"},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/","title":"Catalogd web server","text":"<p>Catalogd, the OLM v1 component for making catalog contents available on cluster, includes a web server that serves catalog contents to clients via HTTP(S) endpoints.</p> <p>The endpoints to retrieve information about installable clusterextentions can be composed from the <code>.status.urls.base</code> of a <code>ClusterCatalog</code> resource with the selected access API path.</p> <p>Currently, there are two API endpoints: </p> <ol> <li><code>api/v1/all</code> endpoint that provides access to the FBC metadata in entirety. </li> </ol> <p>As an example, to access the full FBC via the v1 API endpoint (indicated by path <code>api/v1/all</code>) where <code>.status.urls.base</code> is</p> <pre><code>    urls:\n        base: https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio\n</code></pre> <p>the URL to access the service would be <code>https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio/api/v1/all</code></p> <ol> <li><code>api/v1/metas</code> endpoint that allows clients to retrieve filtered portions of the FBC. </li> </ol> <p>The metas endpoint accepts parameters which are one of the sub-types of the <code>Meta</code> definition, following the pattern <code>/api/v1/metas?&lt;parameter&gt;[&amp;&lt;parameter&gt;...]</code>.</p> <p>As an example, to access only the package schema blobs of the FBC via the <code>api/v1/metas</code> endpoint where <code>.status.urls.base</code> is</p> <pre><code>    urls:\n        base: https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio\n</code></pre> <p>the URL to access the service would be <code>https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio/api/v1/metas?schema=olm.package</code></p> <p>For more examples of valid queries that can be made to the <code>api/v1/metas</code> service endpoint, please see Catalog Queries.</p> <p>Note</p> <p>The values of the <code>.status.urls</code> field in a <code>ClusterCatalog</code> resource are arbitrary string values and can change at any time. While there are no guarantees on the exact value of this field, it will always contain catalog-specific API endpoints for use by clients to make a request from within the cluster.</p>"},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/#interacting-with-the-server","title":"Interacting With the Server","text":""},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/#supported-http-methods","title":"Supported HTTP Methods","text":"<p>The HTTP request methods supported by the catalogd web server are:</p> <ul> <li>GET</li> <li>HEAD</li> </ul>"},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/#response-format","title":"Response Format","text":"<p>Responses are encoded as a JSON Lines stream of File-Based Catalog (FBC) Meta objects delimited by newlines.</p> Example JSON-encoded FBC snippet <pre><code>{\n    \"schema\": \"olm.package\",\n    \"name\": \"cockroachdb\",\n    \"defaultChannel\": \"stable-v6.x\",\n}\n{\n    \"schema\": \"olm.channel\",\n    \"name\": \"stable-v6.x\",\n    \"package\": \"cockroachdb\",\n    \"entries\": [\n        {\n            \"name\": \"cockroachdb.v6.0.0\",\n            \"skipRange\": \"&lt;6.0.0\"\n        }\n    ]\n}\n{\n    \"schema\": \"olm.bundle\",\n    \"name\": \"cockroachdb.v6.0.0\",\n    \"package\": \"cockroachdb\",\n    \"image\": \"quay.io/openshift-community-operators/cockroachdb@sha256:d3016b1507515fc7712f9c47fd9082baf9ccb070aaab58ed0ef6e5abdedde8ba\",\n    \"properties\": [\n        {\n            \"type\": \"olm.package\",\n            \"value\": {\n                \"packageName\": \"cockroachdb\",\n                \"version\": \"6.0.0\"\n            }\n        },\n    ],\n}\n</code></pre> <p>Corresponding JSON lines response: <pre><code>{\"schema\":\"olm.package\",\"name\":\"cockroachdb\",\"defaultChannel\":\"stable-v6.x\"}\n{\"schema\":\"olm.channel\",\"name\":\"stable-v6.x\",\"package\":\"cockroachdb\",\"entries\":[{\"name\":\"cockroachdb.v6.0.0\",\"skipRange\":\"&lt;6.0.0\"}]}\n{\"schema\":\"olm.bundle\",\"name\":\"cockroachdb.v6.0.0\",\"package\":\"cockroachdb\",\"image\":\"quay.io/openshift-community-operators/cockroachdb@sha256:d3016b1507515fc7712f9c47fd9082baf9ccb070aaab58ed0ef6e5abdedde8ba\",\"properties\":[{\"type\":\"olm.package\",\"value\":{\"packageName\":\"cockroachdb\",\"version\":\"6.0.0\"}}]}\n</code></pre></p>"},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/#compression-support","title":"Compression Support","text":"<p>The <code>catalogd</code> web server supports gzip compression of responses, which can significantly reduce associated network traffic.  In order to signal that the client handles compressed responses, the client must include <code>Accept-Encoding: gzip</code> as a header in the HTTP request.</p> <p>The web server will include a <code>Content-Encoding: gzip</code> header in compressed responses.</p> <p>Note</p> <p>Only catalogs whose uncompressed response body would result in a response size greater than 1400 bytes will be compressed.</p>"},{"location":"draft/api-reference/catalogd-webserver-metas-endpoint/#cache-header-support","title":"Cache Header Support","text":"<p>For clients interested in caching the information returned from the <code>catalogd</code> web server, the <code>Last-Modified</code> header is set on responses and the <code>If-Modified-Since</code> header is supported for requests.</p>"},{"location":"draft/api-reference/network-policies/","title":"NetworkPolicy in OLMv1","text":""},{"location":"draft/api-reference/network-policies/#overview","title":"Overview","text":"<p>OLMv1 uses Kubernetes NetworkPolicy to secure communication between components, restricting network traffic to only what's necessary for proper functionality. </p> <ul> <li>The catalogd NetworkPolicy is implemented here.</li> <li>The operator-controller is implemented here.</li> </ul> <p>This document explains the details of <code>NetworkPolicy</code> implementation for the core components.</p>"},{"location":"draft/api-reference/network-policies/#implementation-overview","title":"Implementation Overview","text":"<p>NetworkPolicy is implemented for both catalogd and operator-controller components to:</p> <ul> <li>Restrict incoming (ingress) traffic to only required ports and services</li> <li>Control outgoing (egress) traffic patterns</li> </ul> <p>Each component has a dedicated NetworkPolicy that applies to its respective pod through label selectors:</p> <ul> <li>For catalogd: <code>app.kubernetes.io/name=catalogd</code></li> <li>For operator-controller: <code>app.kubernetes.io/name=operator-controller</code></li> </ul>"},{"location":"draft/api-reference/network-policies/#catalogd-networkpolicy","title":"Catalogd NetworkPolicy","text":"<ul> <li> <p>Ingress Rules Catalogd exposes three services, and its NetworkPolicy allows ingress traffic to the following TCP ports:</p> </li> <li> <p>7443: Metrics server for Prometheus metrics</p> </li> <li>8443: Catalogd HTTPS server for catalog metadata API</li> <li>9443: Webhook server for Mutating Admission Webhook implementation</li> </ul> <p>All other ingress traffic to the catalogd pod is blocked.</p> <ul> <li> <p>Egress Rules Catalogd needs to communicate with:</p> </li> <li> <p>The Kubernetes API server</p> </li> <li>Image registries specified in ClusterCatalog objects</li> </ul> <p>Currently, all egress traffic from catalogd is allowed, to support communication with arbitrary image registries that aren't known at install time.</p>"},{"location":"draft/api-reference/network-policies/#operator-controller-networkpolicy","title":"Operator-Controller NetworkPolicy","text":"<ul> <li> <p>Ingress Rules Operator-controller exposes one service, and its NetworkPolicy allows ingress traffic to:</p> </li> <li> <p>8443: Metrics server for Prometheus metrics</p> </li> </ul> <p>All other ingress traffic to the operator-controller pod is blocked.</p> <ul> <li> <p>Egress Rules Operator-controller needs to communicate with:</p> </li> <li> <p>The Kubernetes API server</p> </li> <li>Catalogd's HTTPS server (on port 8443)</li> <li>Image registries specified in bundle metadata</li> </ul> <p>Currently, all egress traffic from operator-controller is allowed to support communication with arbitrary image registries that aren't known at install time.</p>"},{"location":"draft/api-reference/network-policies/#security-considerations","title":"Security Considerations","text":"<p>The current implementation focuses on securing ingress traffic while allowing all egress traffic. This approach:</p> <ul> <li>Prevents unauthorized incoming connections</li> <li>Allows communication with arbitrary image registries</li> <li>Establishes a foundation for future refinements to egress rules</li> </ul> <p>While allowing all egress does present some security risks, this implementation provides significant security improvements over having no network policies at all.</p>"},{"location":"draft/api-reference/network-policies/#troubleshooting-network-issues","title":"Troubleshooting Network Issues","text":"<p>If you encounter network connectivity issues after deploying OLMv1, consider the following:</p> <ul> <li>Verify NetworkPolicy support: Ensure your cluster has a CNI plugin that supports NetworkPolicy. If your Kubernetes cluster is using a Container Network Interface (CNI) plugin that doesn't support NetworkPolicy, then the NetworkPolicy resources you create will be completely ignored and have no effect whatsoever on traffic flow.</li> <li>Check pod labels: Confirm that catalogd and operator-controller pods have the correct labels for NetworkPolicy selection:</li> </ul> <p><pre><code># Verify catalogd pod labels\nkubectl get pods -n olmv1-system --selector=apps.kubernetes.io/name=catalogd\n\n# Verify operator-controller pod labels\nkubectl get pods -n olmv1-system --selector=apps.kubernetes.io/name=operator-controller\n\n# Compare with actual pod names\nkubectl get pods -n olmv1-system | grep -E 'catalogd|operator-controller'\n</code></pre> * Inspect logs: Check component logs for connection errors</p> <p>For more comprehensive information on NetworkPolicy, see: </p> <ul> <li>How NetworkPolicy is implemented with network plugins via the Container Network Interface (CNI)</li> <li>Installing Network Policy Providers documentation.</li> </ul>"},{"location":"draft/howto/catalog-queries-metas-endpoint/","title":"Catalog queries","text":"<p>After you add a catalog of extensions to your cluster, you must port forward your catalog as a service. Then you can query the catalog by using <code>curl</code> commands and the <code>jq</code> CLI tool to find extensions to install.</p>"},{"location":"draft/howto/catalog-queries-metas-endpoint/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have added a ClusterCatalog of extensions, such as OperatorHub.io, to your cluster.</li> <li>You have installed the <code>jq</code> CLI tool.</li> </ul> <p>Note</p> <p>By default, Catalogd is installed with TLS enabled for the catalog webserver. The following examples will show this default behavior, but for simplicity's sake will ignore TLS verification in the curl commands using the <code>-k</code> flag.</p> <p>Note</p> <p>While using the <code>/api/v1/metas</code> endpoint shown in the below examples, it is important to note that the metas endpoint accepts parameters which are one of the sub-types of the <code>Meta</code> definition, following the pattern <code>/api/v1/metas?&lt;parameter&gt;[&amp;&lt;parameter&gt;...]</code>. e.g. <code>schema=&lt;schema_name&gt;&amp;package=&lt;package_name&gt;</code>, <code>schema=&lt;schema_name&gt;&amp;name=&lt;name&gt;</code>, and <code>package=&lt;package_name&gt;&amp;name=&lt;name&gt;</code> are all valid parameter combinations. However <code>schema=&lt;schema_name&gt;&amp;version=&lt;version_string&gt;</code> is not a valid parameter combination, since version is not a first class FBC meta field. </p> <p>You also need to port forward the catalog server service:</p> <pre><code>kubectl -n olmv1-system port-forward svc/catalogd-service 8443:443\n</code></pre> <p>Now you can use the <code>curl</code> command with <code>jq</code> to query catalogs that are installed on your cluster.</p>"},{"location":"draft/howto/catalog-queries-metas-endpoint/#package-queries","title":"Package queries","text":"<ul> <li> <p>Available packages in a catalog:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.package'\n</code></pre></p> </li> <li> <p>Packages that support <code>AllNamespaces</code> install mode and do not use webhooks:     <pre><code>jq -cs '[.[] | select(.schema == \"olm.bundle\" and (.properties[] | select(.type == \"olm.csv.metadata\").value.installModes[] | select(.type == \"AllNamespaces\" and .supported == true)) and .spec.webhookdefinitions == null) | .package] | unique[]'\n</code></pre></p> </li> <li> <p>Package metadata:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.package&amp;name=&lt;package_name&gt;'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Blobs that belong to a package (that are not schema=olm.package):     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?package=&lt;package_name&gt;'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> </ul> <p>Note: the <code>olm.package</code> schema blob does not have the <code>package</code> field set. In other words, to get all the blobs that belong to a package, along with the olm.package blob for that package, a combination of both of the above queries need to be used. </p>"},{"location":"draft/howto/catalog-queries-metas-endpoint/#channel-queries","title":"Channel queries","text":"<ul> <li> <p>Channels in a package:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.channel&amp;package=&lt;package_name&gt;'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Versions in a channel:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.channel&amp;package=zoperator&amp;name=alpha' | jq -s '.[] | .entries | .[] | .name'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. <code>&lt;channel_name&gt;</code> Name of the channel for a given package. </li> </ul>"},{"location":"draft/howto/catalog-queries-metas-endpoint/#bundle-queries","title":"Bundle queries","text":"<ul> <li> <p>Bundles in a package:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.bundle&amp;package=&lt;package_name&gt;'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Bundle dependencies and available APIs:     <pre><code>curl -k 'https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.bundle&amp;name=&lt;bundle_name&gt;' | jq -s '.[] | .properties[] | select(.type==\"olm.gvk\")'\n</code></pre></p> <code>&lt;bundle_name&gt;</code> Name of the bundle for a given package. </li> </ul>"},{"location":"draft/howto/configure-bundles/","title":"Configure bundles","text":""},{"location":"draft/howto/configure-bundles/#description","title":"Description","text":"<p>Note</p> <p>This feature is still in <code>alpha</code> and the <code>SingleOwnNamespaceInstallSupport</code> feature-gate must be enabled to make use of it. See the instructions below on how to enable it.</p>"},{"location":"draft/howto/configure-bundles/#configuring-olm-v1-extensions-migration-and-reference","title":"Configuring OLM v1 Extensions: Migration and Reference","text":"<p>In OLM v1, the way extensions are configured has changed significantly to improve flexibility and consistency. This guide explains the architectural shift from OLM v0, how to inspect bundles for supported configurations, and how to correctly configure <code>registry+v1</code> (legacy) bundles using the new <code>ClusterExtension</code> API.</p>"},{"location":"draft/howto/configure-bundles/#olm-v0-vs-olm-v1-the-configuration-shift","title":"OLM v0 vs. OLM v1: The Configuration Shift","text":"<p>In OLM v0, configuration was split across multiple resources and concepts. \"Install Modes\" (defining which namespaces an Operator watches) were handled by the <code>OperatorGroup</code> resource, while operand configuration (environment variables, resource limits) was handled via the <code>Subscription</code> resource.</p> <p>In OLM v1, these concepts are unified under the ClusterExtension resource.</p> Feature OLM v0 Approach OLM v1 Approach Namespace Scope Defined by OperatorGroup. You had to pre-create an OperatorGroup to tell the Operator where to watch. Defined by Configuration. You provide a <code>watchNamespace</code> value directly in the <code>ClusterExtension</code> YAML. User Settings <code>Subscription.spec.config</code> (e.g., env, resources). <code>ClusterExtension.spec.config.inline</code> (arbitrary JSON/YAML defined by the bundle author). Multi-Tenancy \"Install Modes\" allowed multiple instances of an operator to exist. \"Install Modes\" are treated as bundle configuration. You install the extension once, and configure it to watch specific areas."},{"location":"draft/howto/configure-bundles/#the-watchnamespace-configuration","title":"The <code>watchNamespace</code> Configuration","text":"<p>For existing <code>registry+v1</code> bundles (standard OLM bundles), OLM v1 automatically generates a configuration schema based on the bundle's capabilities. The primary configuration field available is <code>watchNamespace</code>.</p> <ul> <li>OLM v0: You selected <code>SingleNamespace</code> mode by creating an <code>OperatorGroup</code> that targeted a specific namespace.</li> <li>OLM v1: You set <code>watchNamespace: \"my-target-namespace\"</code> inside the <code>ClusterExtension</code> config.</li> </ul>"},{"location":"draft/howto/configure-bundles/#step-1-identifying-bundle-capabilities","title":"Step 1: Identifying Bundle Capabilities","text":"<p>Before configuring a bundle, you must understand which Install Modes it supports. OLM v1 does not allow you to force a configuration that the bundle author has not explicitly supported.</p> <p>You can inspect a bundle image using the <code>opm</code> CLI tool and <code>jq</code> to parse the output.</p> <p>Prerequisites: * <code>opm</code> CLI installed. * <code>jq</code> installed.</p> <p>Command:</p> <p>Run the following command, replacing <code>&lt;bundle-image&gt;</code> with your target image (e.g., <code>quay.io/example/my-operator-bundle:v1.0.0</code>).</p> <pre><code>opm render &lt;bundle-image&gt; -o json | \\\njq 'select(.schema == \"olm.bundle\") | .properties[] | select(.type == \"olm.csv\") | .value.spec.installModes'\n</code></pre> <p>Example Output:</p> <pre><code>[\n  {\n    \"type\": \"OwnNamespace\",\n    \"supported\": true\n  },\n  {\n    \"type\": \"SingleNamespace\",\n    \"supported\": true\n  },\n  {\n    \"type\": \"MultiNamespace\",\n    \"supported\": false\n  },\n  {\n    \"type\": \"AllNamespaces\",\n    \"supported\": false\n  }\n]\n</code></pre> <p>By analyzing which modes are marked <code>true</code>, you can determine how to configure the <code>ClusterExtension</code> in the next step.</p>"},{"location":"draft/howto/configure-bundles/#step-2-capability-matrix-configuration-guide","title":"Step 2: Capability Matrix &amp; Configuration Guide","text":"<p>Use the output from Step 1 to locate your bundle's capabilities in the matrix below. This determines if you must provide configuration, if it is optional, and what values are valid.</p>"},{"location":"draft/howto/configure-bundles/#legend","title":"Legend","text":"<ul> <li>Install Namespace: The namespace where the Operator logic (Pod) runs (defined in <code>ClusterExtension.spec.namespace</code>).</li> <li>Watch Namespace: The namespace the Operator monitors for Custom Resources (defined in <code>spec.config.inline.watchNamespace</code>).</li> </ul>"},{"location":"draft/howto/configure-bundles/#configuration-matrix","title":"Configuration Matrix","text":"Capabilities Detected (from <code>opm</code>) <code>watchNamespace</code> Field Status Valid Values / Constraints OwnNamespace ONLY Required Must be exactly the same as the Install Namespace. SingleNamespace ONLY Required Must be different from the Install Namespace. OwnNamespace AND SingleNamespace Required Can be any namespace (either the install namespace or a different one). AllNamespaces (regardless of others) Optional If omitted: defaults to Cluster-wide watch.If provided: can be any specific namespace (limits scope)."},{"location":"draft/howto/configure-bundles/#common-configuration-scenarios","title":"Common Configuration Scenarios","text":""},{"location":"draft/howto/configure-bundles/#scenario-a-the-legacy-ownnamespace-operator","title":"Scenario A: The Legacy \"OwnNamespace\" Operator","text":"<ul> <li>Capability: Only supports <code>OwnNamespace</code>.</li> <li>Requirement: The operator is hardcoded to watch its own namespace.</li> <li>Config: You must explicitly set <code>watchNamespace</code> to match the installation namespace.</li> </ul> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: my-operator\nspec:\n  namespace: my-operator-ns      # &lt;--- Install Namespace\n  serviceAccount:\n    name: my-sa\n  config:\n    configType: Inline\n    inline:\n      watchNamespace: my-operator-ns # &lt;--- MUST match Install Namespace\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: my-package\n</code></pre>"},{"location":"draft/howto/configure-bundles/#scenario-b-the-singlenamespace-operator","title":"Scenario B: The \"SingleNamespace\" Operator","text":"<ul> <li>Capability: Supports <code>SingleNamespace</code> (but not <code>OwnNamespace</code>).</li> <li>Requirement: The operator runs in one namespace (e.g., <code>ops-system</code>) but watches workloads in another (e.g., <code>dev-team-a</code>).</li> <li>Config: You must set <code>watchNamespace</code> to the target workload namespace.</li> </ul> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: monitor-operator\nspec:\n  namespace: ops-system          # &lt;--- Install Namespace\n  serviceAccount:\n    name: monitor-operator-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: monitor-operator\n  config:\n    configType: Inline\n    inline:\n      watchNamespace: dev-team-a     # &lt;--- MUST differ from Install Namespace\n</code></pre>"},{"location":"draft/howto/configure-bundles/#scenario-c-the-modern-allnamespaces-operator","title":"Scenario C: The Modern \"AllNamespaces\" Operator","text":"<ul> <li>Capability: Only supports <code>AllNamespaces</code>.</li> </ul> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: global-operator\nspec:\n  namespace: operators\n  # No config provided = Operator watches the entire cluster (AllNamespaces)\n  serviceAccount:\n    name: global-operator-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: global-operator\n</code></pre>"},{"location":"draft/howto/configure-bundles/#troubleshooting-configuration-errors","title":"Troubleshooting Configuration Errors","text":"<p>OLM v1 validates your configuration against the bundle's schema before installation proceeds. If your configuration is invalid, the <code>ClusterExtension</code> will report a <code>Progressing</code> condition with an error message.</p> Error Message Example Cause Solution <code>required field \"watchNamespace\" is missing</code> The bundle does not support <code>AllNamespaces</code> default mode. Add the <code>inline</code> block and specify a <code>watchNamespace</code>. <code>invalid value \"X\": watchNamespace must be \"Y\" (the namespace where the operator is installed) because this operator only supports OwnNamespace install mode</code> You tried to set a different watch namespace for an <code>OwnNamespace</code>-only bundle. Change <code>watchNamespace</code> to match <code>spec.namespace</code>. <code>invalid value \"X\": watchNamespace must be different from \"Y\" (the install namespace) because this operator uses SingleNamespace install mode to watch a different namespace</code> You tried to set the watch namespace to the install namespace for a <code>SingleNamespace</code>-only bundle. Change <code>watchNamespace</code> to a different target namespace. <code>unknown field \"foo\"</code> You added extra fields to the inline config. Remove fields other than <code>watchNamespace</code> (unless the bundle author explicitly documents extra schema support)."},{"location":"draft/howto/consuming-metrics/","title":"Consuming Metrics","text":"<p>Warning</p> <p>Metrics endpoints and ports are available as an alpha release and are subject to change in future versions. The following procedure is provided as an example for testing purposes. Do not depend on alpha features in production clusters.</p> <p>In OLM v1, you can use the provided metrics with tools such as the Prometheus Operator. By default, Operator Controller and catalogd export metrics to the <code>/metrics</code> endpoint of each service.</p> <p>You must grant the necessary permissions to access the metrics by using role-based access control (RBAC) polices. You will also need to create a <code>NetworkPolicy</code> to allow egress traffic from your scraper pod, as the OLM namespace by default allows only <code>catalogd</code> and <code>operator-controller</code> to send and receive traffic. Because the metrics are exposed over HTTPS by default, you need valid certificates to use the metrics with services such as Prometheus. The following sections cover enabling metrics, validating access, and provide a reference of a <code>ServiceMonitor</code> to illustrate how you might integrate the metrics with the Prometheus Operator or other third-part solutions.</p>"},{"location":"draft/howto/consuming-metrics/#enabling-metrics-for-the-operator-controller","title":"Enabling metrics for the Operator Controller","text":"<ol> <li>To enable access to the Operator controller metrics, create a <code>ClusterRoleBinding</code> resource by running the following command:</li> </ol> <pre><code>kubectl create clusterrolebinding operator-controller-metrics-binding \\\n   --clusterrole=operator-controller-metrics-reader \\\n   --serviceaccount=olmv1-system:operator-controller-controller-manager\n</code></pre> <ol> <li>Next, create a <code>NetworkPolicy</code> to allow the scraper pods to send their scrape requests:</li> </ol> <pre><code>kubectl apply -f - &lt;&lt; EOF\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: scraper-policy\n  namespace: olmv1-system\nspec:\n  podSelector:\n    matchLabels:\n      metrics: scraper\n  policyTypes:\n    - Egress\n  egress:\n    - {}  # Allows all egress traffic for metrics requests\nEOF\n</code></pre>"},{"location":"draft/howto/consuming-metrics/#validating-access-manually","title":"Validating Access Manually","text":"<ol> <li>Generate a token for the service account and extract the required certificates:</li> </ol> <pre><code>TOKEN=$(kubectl create token operator-controller-controller-manager -n olmv1-system)\necho $TOKEN\n</code></pre> <ol> <li>Apply the following YAML to deploy a pod in a namespace to consume the metrics:</li> </ol> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curl-metrics\n  namespace: olmv1-system\n  labels:\n    metrics: scraper\nspec:\n  serviceAccountName: operator-controller-controller-manager\n  containers:\n  - name: curl\n    image: curlimages/curl:latest\n    command:\n    - sh\n    - -c\n    - sleep 3600\n    securityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n      runAsUser: 1000\n      runAsGroup: 1000\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n    volumeMounts:\n    - mountPath: /tmp/cert\n      name: olm-cert\n      readOnly: true\n  volumes:\n  - name: olm-cert\n    secret:\n      secretName: olmv1-cert\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    seccompProfile:\n        type: RuntimeDefault\n  restartPolicy: Never\nEOF\n</code></pre> <ol> <li>Run the following command using the <code>TOKEN</code> value obtained above to check the metrics:</li> </ol> <pre><code>kubectl exec -it curl-metrics -n olmv1-system -- \\\ncurl -v -k -H \"Authorization: Bearer ${TOKEN}\" \\\nhttps://operator-controller-service.olmv1-system.svc.cluster.local:8443/metrics\n</code></pre> <ol> <li>Run the following command to validate the certificates and token:</li> </ol> <pre><code>kubectl exec -it curl-metrics -n olmv1-system -- \\\ncurl -v --cacert /tmp/cert/ca.crt --cert /tmp/cert/tls.crt --key /tmp/cert/tls.key \\\n-H \"Authorization: Bearer ${TOKEN}\" \\\nhttps://operator-controller-service.olmv1-system.svc.cluster.local:8443/metrics\n</code></pre>"},{"location":"draft/howto/consuming-metrics/#enabling-metrics-for-the-operator-catalogd","title":"Enabling metrics for the Operator CatalogD","text":"<ol> <li>To enable access to the CatalogD metrics, create a <code>ClusterRoleBinding</code> for the CatalogD service account:</li> </ol> <pre><code>kubectl create clusterrolebinding catalogd-metrics-binding \\\n   --clusterrole=catalogd-metrics-reader \\\n   --serviceaccount=olmv1-system:catalogd-controller-manager\n</code></pre>"},{"location":"draft/howto/consuming-metrics/#validating-access-manually_1","title":"Validating Access Manually","text":"<ol> <li>Generate a token and get the required certificates:</li> </ol> <pre><code>TOKEN=$(kubectl create token catalogd-controller-manager -n olmv1-system)\necho $TOKEN\n</code></pre> <ol> <li>Run the following command to obtain the name of the secret which store the certificates:</li> </ol> <pre><code>OLM_SECRET=$(kubectl get secret -n olmv1-system -o jsonpath=\"{.items[*].metadata.name}\" | tr ' ' '\\n' | grep '^catalogd-service-cert')\necho $OLM_SECRET\n</code></pre> <ol> <li>Apply the following YAML to deploy a pod in a namespace to consume the metrics:</li> </ol> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curl-metrics-catalogd\n  namespace: olmv1-system\n  labels:\n    metrics: scraper\nspec:\n  serviceAccountName: catalogd-controller-manager\n  containers:\n  - name: curl\n    image: curlimages/curl:latest\n    command:\n    - sh\n    - -c\n    - sleep 3600\n    securityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n      runAsUser: 1000\n      runAsGroup: 1000\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n    volumeMounts:\n    - mountPath: /tmp/cert\n      name: catalogd-cert\n      readOnly: true\n  volumes:\n  - name: catalogd-cert\n    secret:\n      secretName: $OLM_SECRET\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    seccompProfile:\n        type: RuntimeDefault\n  restartPolicy: Never\nEOF\n</code></pre> <ol> <li>Run the following command using the <code>TOKEN</code> value obtained above to check the metrics:</li> </ol> <pre><code>kubectl exec -it curl-metrics -n olmv1-system -- \\\ncurl -v -k -H \"Authorization: Bearer ${TOKEN}\" \\\nhttps://catalogd-service.olmv1-system.svc.cluster.local:7443/metrics\n</code></pre> <ol> <li>Run the following command to validate the certificates and token: <pre><code>kubectl exec -it curl-metrics -n olmv1-system -- \\\ncurl -v --cacert /tmp/cert/ca.crt --cert /tmp/cert/tls.crt --key /tmp/cert/tls.key \\\n-H \"Authorization: Bearer ${TOKEN}\" \\\nhttps://catalogd-service.olmv1-system.svc.cluster.local:7443/metrics\n</code></pre></li> </ol>"},{"location":"draft/howto/consuming-metrics/#integrating-the-metrics-endpoints-with-third-party-solutions","title":"Integrating the metrics endpoints with third-party solutions","text":"<p>In many cases, you must provide the certificates and the <code>ServiceName</code> resources to integrate metrics endpoints with third-party solutions. The following example illustrates how to create a <code>ServiceMonitor</code> resource to scrape metrics for the Prometheus Operator in OLM v1.</p> <p>Note</p> <p>The following manifests are provided as a reference mainly to let you know how to configure the certificates. The following procedure is not a complete guide to configuring the Prometheus Operator or how to integrate within. To integrate with Prometheus Operator you might need to adjust your configuration settings, such as the <code>serviceMonitorSelector</code> resource, and the namespace where you apply the <code>ServiceMonitor</code> resource to ensure that metrics are properly scraped.</p> <p>Example for Operator-Controller</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    apps.kubernetes.io/name: operator-controller\n  name: controller-manager-metrics-monitor\n  namespace: olmv1-system\nspec:\n  endpoints:\n    - path: /metrics\n      port: https\n      scheme: https\n      bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token\n      tlsConfig:\n        insecureSkipVerify: false \n        serverName: operator-controller-service.olmv1-system.svc\n        ca:\n          secret:\n            name: olmv1-cert\n            key: ca.crt\n        cert:\n          secret:\n            name: olmv1-cert\n            key: tls.crt\n        keySecret:\n          name: olmv1-cert\n          key: tls.key\n  selector:\n    matchLabels:\n      apps.kubernetes.io/name: operator-controller\nEOF\n</code></pre> <p>Example for CatalogD</p> <pre><code>OLM_SECRET=$(kubectl get secret -n olmv1-system -o jsonpath=\"{.items[*].metadata.name}\" | tr ' ' '\\n' | grep '^catalogd-service-cert')\necho $OLM_SECRET\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    apps.kubernetes.io/name: catalogd\n  name: catalogd-metrics-monitor\n  namespace: olmv1-system\nspec:\n  endpoints:\n    - path: /metrics\n      port: metrics\n      scheme: https\n      bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token\n      tlsConfig:\n        serverName: catalogd-service.olmv1-system.svc\n        insecureSkipVerify: false\n        ca:\n          secret:\n            name: $OLM_SECRET\n            key: ca.crt\n        cert:\n          secret:\n            name: $OLM_SECRET\n            key: tls.crt\n        keySecret:\n          name: $OLM_SECRET\n          key: tls.key\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: catalogd\nEOF\n</code></pre>"},{"location":"draft/howto/enable-helm-chart-support/","title":"How to Enable Helm Chart Support Feature Gate","text":""},{"location":"draft/howto/enable-helm-chart-support/#description","title":"Description","text":"<p>This document outlines the steps to enable the Helm Chart support feature gate in the OLMv1 and subsequently deploy a Helm Chart to a Kubernetes cluster. It involves patching the <code>operator-controller-controller-manager</code> deployment to enable the <code>HelmChartSupport</code> feature, setting up a network policy for the registry, deploying an OCI registry, and finally creating a ClusterExtension to deploy the metrics server helm chart.</p> <p>The feature allows developers and end-users to deploy Helm charts from OCI registries through the <code>ClusterExtension</code> API.</p>"},{"location":"draft/howto/enable-helm-chart-support/#demos","title":"Demos","text":""},{"location":"draft/howto/enable-helm-chart-support/#enabling-the-feature-gate","title":"Enabling the Feature Gate","text":"<p>To enable the Helm Chart support feature gate, you need to patch the <code>operator-controller-controller-manager</code> deployment in the <code>olmv1-system</code> namespace. This will add the <code>--feature-gates=HelmChartSupport=true</code> argument to the manager container.</p> <ol> <li> <p>Create a patch file:</p> <pre><code>$ kubectl patch deployment -n olmv1-system operator-controller-controller-manager --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/args/-\", \"value\": \"--feature-gates=HelmChartSupport=true\"}]'\n</code></pre> </li> <li> <p>Wait for the controller manager pods to be ready:</p> <pre><code>$ kubectl -n olmv1-system wait --for condition=ready pods -l apps.kubernetes.io/name=operator-controller\n</code></pre> </li> </ol> <p>Once the above wait condition is met, the <code>HelmChartSupport</code> feature gate should be enabled in operator controller.</p>"},{"location":"draft/howto/enable-helm-chart-support/#deploy-an-oci-chart-registry-for-testing","title":"Deploy an OCI Chart registry for testing","text":"<p>With the operator-controller pod running with the <code>HelmChartSupport</code> feature gate enabled, you would need access to a Helm charts  hosted in an OCI registry. For this demo, the instructions will walk you through steps to deploy a registry in the <code>olmv1-system</code> project.</p> <p>In addition to the OCI registry, you will need a ClusterCatalog in the Kubernetes cluster which will reference Helm charts in the OCI registry.</p> <ol> <li> <p>Configure network policy for the registry:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl -n olmv1-system apply -f -\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: registry\nspec:\n  egress:\n  - {}\n  ingress:\n  - ports:\n    - port: 8443\n      protocol: TCP\n  podSelector:\n    matchLabels:\n      app: registry\n  policyTypes:\n  - Ingress\n  - Egress\nEOF\n</code></pre> </li> <li> <p>Create certificates for the OCI registry:</p> </li> </ol> <pre><code>$ cat &lt;&lt; EOF | kubectl -n olmv1-system apply -f -\n---\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: registry-cert\n  namespace: olmv1-system\nspec:\n  dnsNames:\n    - registry.olmv1-system.svc\n    - registry.olmv1-system.svc.cluster.local\n  issuerRef:\n    group: cert-manager.io\n    kind: ClusterIssuer\n    name: olmv1-ca\n  privateKey:\n    algorithm: RSA\n    encoding: PKCS1\n    size: 2048\n  secretName: registry-cert\nstatus: {}\nEOF\n</code></pre> <ol> <li> <p>Deploy an OCI registry:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl -n olmv1-system apply -f -\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: registry\n  name: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: registry\n  strategy: {}\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: registry\n    spec:\n      containers:\n        - name: registry\n          image: docker.io/library/registry:3.0.0\n          env:\n            - name: REGISTRY_HTTP_ADDR\n              value: \"0.0.0.0:8443\"\n            - name: REGISTRY_HTTP_TLS_CERTIFICATE\n              value: \"/certs/tls.crt\"\n            - name: REGISTRY_HTTP_TLS_KEY\n              value: \"/certs/tls.key\"\n            - name: OTEL_TRACES_EXPORTER\n              value: \"none\"\n          ports:\n            - name: registry\n              protocol: TCP\n              containerPort: 8443\n          securityContext:\n            runAsUser: 999\n            allowPrivilegeEscalation: false\n            runAsNonRoot: true\n            seccompProfile:\n              type: \"RuntimeDefault\"\n            capabilities:\n              drop:\n                - ALL\n          volumeMounts:\n            - name: blobs\n              mountPath: /var/lib/registry/docker\n            - name: certs\n              mountPath: /certs\n          resources: {}\n      volumes:\n        - name: blobs\n          emptyDir: {}\n        - name: certs\n          secret:\n            secretName: registry-cert\nstatus: {}\nEOF\n</code></pre> </li> <li> <p>Expose the registry container:</p> </li> </ol> <pre><code>$ cat &lt;&lt; EOF | kubectl -n olmv1-system apply -f -\n---\napiVersion: v1\nkind: Service\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: registry\n  name: registry\n  namespace: olmv1-system\nspec:\n  ports:\n    - port: 443\n      protocol: TCP\n      targetPort: 8443\n  selector:\n    app: registry\nstatus:\n  loadBalancer: {}\nEOF\n</code></pre> <ol> <li> <p>Wait for the registry pod to be in a Running phase:</p> <pre><code>$ kubectl -n olmv1-system wait --for=jsonpath='{.status.phase}'=Running pod -l app=registry\n</code></pre> </li> <li> <p>Deploy the cluster catalog:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: metrics-server-operators\n  namespace: olmv1-system\nspec:\n  priority: -100\n  source:\n    image:\n      pollIntervalMinutes: 5\n      ref: quay.io/eochieng/metrics-server-catalog:latest\n    type: Image\nEOF\n</code></pre> </li> <li> <p>Upload charts to the registry:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  creationTimestamp: null\n  name: chart-uploader\nspec:\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - image: quay.io/eochieng/uploader:latest\n        name: chart-uploader\n        resources: {}\n      restartPolicy: Never\nstatus: {}\nEOF\n</code></pre> </li> <li> <p>Deploy metrics server RBAC and metrics server:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  creationTimestamp: null\n  name: metrics-server-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  creationTimestamp: null\n  name: metrics-server-installer\n  namespace: metrics-server-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  creationTimestamp: null\n  name: metrics-server-crb\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: metrics-server-cr\nsubjects:\n- kind: ServiceAccount\n  name: metrics-server-installer\n  namespace: metrics-server-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  creationTimestamp: null\n  name: metrics-server-cr\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - serviceaccounts\n  verbs:\n  - create\n  - delete\n  - list\n  - watch\n  - get\n  - patch\n  - update\n- apiGroups:\n  - rbac.authorization.k8s.io\n  resources:\n  - clusterroles\n  - clusterrolebindings\n  - rolebindings\n  verbs:\n  - create\n  - delete\n  - list\n  - watch\n  - get\n  - patch\n  - update\n- apiGroups:\n  - \"\"\n  resources:\n  - services\n  - secrets\n  verbs:\n  - get\n  - list\n  - watch\n  - create\n  - delete\n  - patch\n  - update\n- apiGroups:\n  - apps\n  resources:\n  - deployments\n  - deployments/finalizers\n  verbs:\n  - get\n  - list\n  - watch\n  - create\n  - delete\n  - patch\n  - update\n- apiGroups:\n  - apiregistration.k8s.io\n  resources:\n  - apiservices\n  verbs:\n  - get\n  - list\n  - watch\n  - create\n  - delete\n  - patch\n  - update\n- apiGroups:\n  - olm.operatorframework.io\n  resources:\n  - clusterextensions\n  - clusterextensions/finalizers\n  verbs:\n  - get\n  - list\n  - watch\n  - create\n  - delete\n  - update\n  - patch\n- apiGroups:\n  - metrics.k8s.io\n  resources:\n  - nodes\n  - pods\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - configmaps\n  - namespaces\n  - nodes\n  - pods\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes/metrics\n  verbs:\n  - get\n- apiGroups:\n  - authentication.k8s.io\n  resources:\n  - tokenreviews\n  verbs:\n  - create\n- apiGroups:\n  - authorization.k8s.io\n  resources:\n  - subjectaccessreviews\n  verbs:\n  - create\nEOF\n</code></pre> </li> <li> <p>Deploy metrics server cluster extension:</p> <pre><code>$ cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: metrics-server\n  namespace: metrics-server-system\nspec:\n  namespace: metrics-server-system\n  serviceAccount:\n    name: metrics-server-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: metrics-server\n      version: 3.12.0\nEOF\n</code></pre> </li> <li> <p>Confirm the Helm chart has been deployed:</p> </li> </ol> <pre><code>$ kubectl get clusterextensions metrics-server\nNAME             INSTALLED BUNDLE         VERSION   INSTALLED   PROGRESSING   AGE\nmetrics-server   metrics-server.v3.12.0   3.12.0    True        True          4m40s\n</code></pre>"},{"location":"draft/howto/enable-webhook-support/","title":"Enable webhook support","text":""},{"location":"draft/howto/enable-webhook-support/#installation-of-bundles-containing-webhooks","title":"Installation of Bundles containing Webhooks","text":"<p>Note</p> <p>OLMv1 supports the installation of bundles containing webhooks by default. By default, OLM v1 uses the community Cert Manager package for admission webhook via the feature-gate flag <code>WebhookProviderCertManager</code>. To use the OpenShift Service CA provider, set the <code>--feature-gates=WebhookProviderOpenshiftServiceCA=true</code> flag at startup.</p> <p>Admission webhooks are part of the Kubernetes suite of Dynamic Admission Control plugins. Webhooks run as services called by the kube-apiservice in due course of processing a resource related request. They can be used to validate resources, ensure reasonable default values, are set, or aid in the migration to new CustomResourceDefinition schema. The communication with the webhook service is secured by TLS. In OLMv1, the TLS certificate is managed by a  certificate provider. Currently, two certificate providers are supported: CertManager and Openshift-ServiceCA. The certificate provider to use given by the feature-gate:</p> <ul> <li><code>WebhookProviderCertManager</code> for CertManager</li> <li><code>WebhookProviderOpenshiftServiceCA</code> for Openshift-ServiceCA</li> </ul> <p>As CertManager is already installed with OLMv1, we suggest using <code>WebhookProviderCertManager</code>.</p>"},{"location":"draft/howto/enable-webhook-support/#run-olm-v1-with-webhook-support","title":"Run OLM v1 with Webhook Support","text":"<p>```terminal title=Start the controller with webhook support make run <pre><code>Then,\n\n```terminal title=Wait for rollout to complete\nkubectl rollout status -n olmv1-system deployment/operator-controller-controller-manager \n</code></pre></p>"},{"location":"draft/howto/enable-webhook-support/#notes-on-the-generated-certificate","title":"Notes on the generated certificate","text":""},{"location":"draft/howto/enable-webhook-support/#certmanager","title":"CertManager","text":"<p>The generated certificate maintains a high-level of parity with the certificate generated by OLMv0: - Self-signed - Two validity period, rotating 24h before expiry - Valid for the webhook service's DNSNames:   - .   - ..svc   - ..svc.cluster.local"},{"location":"draft/howto/enable-webhook-support/#openshift-serviceca","title":"Openshift-ServiceCA","text":"<p>Generation and rotation are completely governed by Openshift-ServiceCA</p>"},{"location":"draft/howto/enable-webhook-support/#how-does-it-work","title":"How does it work?","text":"<p>There's no change in the installation flow. Just install a bundle containing webhooks as you would any other.</p>"},{"location":"draft/howto/enable-webhook-support/#demo","title":"Demo","text":"<p>Note</p> <p>As there is no difference in usage or experience between the CertManager and Openshift-ServiceCA variants, only the cert-manager variant is demoed.</p> <p></p>"},{"location":"draft/howto/profiling_with_pprof/","title":"Profiling with Pprof","text":"<p>Warning</p> <p>Pprof bind port flag are available as an alpha release and are subject to change in future versions.</p> <p>Pprof is a useful tool for analyzing memory and CPU usage profiles. However, it is not recommended to enable it by default in production environments. While it is great for troubleshooting, keeping it enabled can introduce performance concerns and potential information leaks.</p> <p>Both components allow you to enable pprof by specifying the port it should bind to using the <code>pprof-bind-address</code> flag. However, you must ensure that each component uses a unique port\u2014using the same port for multiple components is not allowed. Additionally, you need to export the corresponding port in the service configuration for each component.</p> <p>The following steps are examples to demonstrate the required changes to enable Pprof for Operator-Controller and CatalogD.</p>"},{"location":"draft/howto/profiling_with_pprof/#enabling-pprof-for-gathering-the-data","title":"Enabling Pprof for gathering the data","text":""},{"location":"draft/howto/profiling_with_pprof/#for-operator-controller","title":"For Operator-Controller","text":"<ol> <li>Run the following command to patch the Deployment and add the <code>--pprof-bind-address=:8082</code> flag:</li> </ol> <pre><code>kubectl patch deployment $(kubectl get deployments -n olmv1-system -l apps.kubernetes.io/name=operator-controller -o jsonpath='{.items[0].metadata.name}') \\\n-n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/template/spec/containers/0/args/-\",\n    \"value\": \"--pprof-bind-address=:8082\"\n  }\n]'\n</code></pre> <ol> <li>Once Pprof is enabled, you need to export port <code>8082</code> in the Service to make it accessible:</li> </ol> <pre><code>kubectl patch service operator-controller-service -n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/ports/-\",\n    \"value\": {\n      \"name\": \"pprof\",\n      \"port\": 8082,\n      \"targetPort\": 8082,\n      \"protocol\": \"TCP\"\n    }\n  }\n]'\n</code></pre> <ol> <li>Create the Pod with <code>curl</code> to allow to generate the report:</li> </ol> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curl-oper-con-pprof\n  namespace: olmv1-system\nspec:\n  serviceAccountName: operator-controller-controller-manager\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: curl\n    image: curlimages/curl:latest\n    command:\n    - sh\n    - -c\n    - sleep 3600\n    securityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: false\n      runAsUser: 1000\n      runAsGroup: 1000\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n    volumeMounts:\n    - mountPath: /tmp\n      name: tmp-volume\n  restartPolicy: Never\n  volumes:\n  - name: tmp-volume\n    emptyDir: {}\nEOF\n</code></pre> <ol> <li>Run the following command to generate the token for authentication:</li> </ol> <pre><code>TOKEN=$(kubectl create token operator-controller-controller-manager -n olmv1-system)\necho $TOKEN\n</code></pre> <ol> <li>Run the following command to generate the report in the Pod:</li> </ol> <pre><code>kubectl exec -it curl-oper-con-pprof -n olmv1-system -- sh -c \\\n\"curl -s -k -H \\\"Authorization: Bearer $TOKEN\\\" \\\nhttp://operator-controller-service.olmv1-system.svc.cluster.local:8082/debug/pprof/profile &gt; /tmp/operator-controller-profile.pprof\"\n</code></pre> <ol> <li>Now, we can verify that the report was successfully created:</li> </ol> <pre><code>kubectl exec -it curl-oper-con-pprof -n olmv1-system -- ls -lh /tmp/\n</code></pre> <ol> <li>Then, we can copy the result for your local environment:</li> </ol> <pre><code>kubectl cp olmv1-system/curl-oper-con-pprof:/tmp/operator-controller-profile.pprof ./operator-controller-profile.pprof\ntar: removing leading '/' from member names\n</code></pre> <ol> <li>By last, we can use pprof to analyse the result:</li> </ol> <pre><code>go tool pprof -http=:8080 ./operator-controller-profile.pprof\n</code></pre>"},{"location":"draft/howto/profiling_with_pprof/#for-the-catalogd","title":"For the CatalogD","text":"<ol> <li>Run the following command to patch the Deployment and add the <code>--pprof-bind-address=:8083</code> flag:</li> </ol> <pre><code>kubectl patch deployment $(kubectl get deployments -n olmv1-system -l apps.kubernetes.io/name=catalogd -o jsonpath='{.items[0].metadata.name}') \\\n-n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/template/spec/containers/0/args/-\",\n    \"value\": \"--pprof-bind-address=:8083\"\n  }\n]'\n</code></pre> <ol> <li>Once Pprof is enabled, you need to export port <code>8083</code> in the <code>Service</code> to make it accessible:</li> </ol> <pre><code>kubectl patch service $(kubectl get service -n olmv1-system -l app.kubernetes.io/part-of=olm,app.kubernetes.io/name=catalogd -o jsonpath='{.items[0].metadata.name}') \\\n-n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/ports/-\",\n    \"value\": {\n      \"name\": \"pprof\",\n      \"port\": 8083,\n      \"targetPort\": 8083,\n      \"protocol\": \"TCP\"\n    }\n  }\n]'\n</code></pre> <ol> <li>Create the Pod with <code>curl</code> to allow to generate the report:</li> </ol> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curl-catalogd-pprof\n  namespace: olmv1-system\nspec:\n  serviceAccountName: catalogd-controller-manager\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: curl\n    image: curlimages/curl:latest\n    command:\n    - sh\n    - -c\n    - sleep 3600\n    securityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: false\n      runAsUser: 1000\n      runAsGroup: 1000\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n    volumeMounts:\n    - mountPath: /tmp\n      name: tmp-volume\n  restartPolicy: Never\n  volumes:\n  - name: tmp-volume\n    emptyDir: {}\nEOF\n</code></pre> <ol> <li>Run the following command to generate the token for authentication:</li> </ol> <pre><code>TOKEN=$(kubectl create token catalogd-controller-manager -n olmv1-system)\necho $TOKEN\n</code></pre> <ol> <li>Run the following command to generate the report in the Pod:</li> </ol> <pre><code>kubectl exec -it curl-catalogd-pprof -n olmv1-system -- sh -c \\\n\"curl -s -k -H \\\"Authorization: Bearer $TOKEN\\\" \\\nhttp://catalogd-service.olmv1-system.svc.cluster.local:8083/debug/pprof/profile &gt; /tmp/catalogd-profile.pprof\"\n</code></pre> <ol> <li>Now, we can verify that the report was successfully created:</li> </ol> <pre><code>kubectl exec -it curl-catalogd-pprof -n olmv1-system -- ls -lh /tmp/\n</code></pre> <ol> <li>Then, we can copy the result for your local environment:</li> </ol> <pre><code>kubectl cp olmv1-system/curl-catalogd-pprof:/tmp/catalogd-profile.pprof ./catalogd-profile.pprof\n</code></pre> <ol> <li>By last, we can use pprof to analyse the result:</li> </ol> <pre><code>go tool pprof -http=:8080 ./catalogd-profile.pprof\n</code></pre>"},{"location":"draft/howto/profiling_with_pprof/#disabling-pprof-after-gathering-the-data","title":"Disabling pprof after gathering the data","text":""},{"location":"draft/howto/profiling_with_pprof/#for-operator-controller_1","title":"For Operator-Controller","text":"<ol> <li>Run the following command to bind to <code>--pprof-bind-address</code> the value <code>0</code> in order to disable the endpoint.</li> </ol> <pre><code>kubectl patch deployment $(kubectl get deployments -n olmv1-system -l apps.kubernetes.io/name=operator-controller -o jsonpath='{.items[0].metadata.name}') \\\n-n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"replace\",\n    \"path\": \"/spec/template/spec/containers/0/args\",\n    \"value\": [\"--pprof-bind-address=0\"]\n  }\n]'\n</code></pre> <ol> <li>Try to generate the report as done previously. The connection should now be refused:</li> </ol> <pre><code>kubectl exec -it curl-pprof -n olmv1-system -- sh -c \\\n\"curl -s -k -H \\\"Authorization: Bearer $TOKEN\\\" \\\nhttp://operator-controller-service.olmv1-system.svc.cluster.local:8082/debug/pprof/profile &gt; /tmp/operator-controller-profile.pprof\"\n</code></pre> <p>NOTE: if you wish you can delete the service port added to allow use pprof and re-start the deployment <code>kubectl rollout restart deployment -n olmv1-system operator-controller-controller-manager</code></p> <ol> <li>We can remove the Pod created to generate the report:</li> </ol> <pre><code>kubectl delete pod curl-oper-con-pprof -n olmv1-system\n</code></pre>"},{"location":"draft/howto/profiling_with_pprof/#for-catalogd","title":"For CatalogD","text":"<ol> <li> <p>Run the following command to bind to <code>--pprof-bind-address</code> the value <code>0</code> in order to disable the endpoint. <pre><code>kubectl patch deployment $(kubectl get deployments -n olmv1-system -l apps.kubernetes.io/name=catalogd -o jsonpath='{.items[0].metadata.name}') \\\n-n olmv1-system --type='json' -p='[\n  {\n    \"op\": \"replace\",\n    \"path\": \"/spec/template/spec/containers/0/args\",\n    \"value\": [\"--pprof-bind-address=0\"]\n  }\n]'\n</code></pre></p> </li> <li> <p>To ensure we can try to generate the report as done above. Note that the connection should be refused:</p> </li> </ol> <pre><code>kubectl exec -it curl-pprof -n olmv1-system -- sh -c \\\n\"curl -s -k -H \\\"Authorization: Bearer $TOKEN\\\" \\\nhttp://catalogd-service.olmv1-system.svc.cluster.local:8083/debug/pprof/profile &gt; /tmp/catalogd-profile.pprof\"\n</code></pre> <p>NOTE: if you wish you can delete the service port added to allow use pprof and  re-start the deployment <code>kubectl rollout restart deployment -n olmv1-system catalogd-controller-manager</code></p> <ol> <li>We can remove the Pod created to generate the report:</li> </ol> <pre><code>kubectl delete pod curl-catalogd-pprof -n olmv1-system\n</code></pre>"},{"location":"draft/howto/rbac-permissions-checking/","title":"How To Get Your Cluster Extension RBAC Right \u2014 Working with the Preflight Permissions Check","text":"<p>Cluster Extensions in Operator Lifecycle Manager (OLM) v1 are installed and managed via a service account that you (the cluster admin) provide. Unlike OLM v0, OLM v1 itself doesn\u2019t have cluster-admin privileges to grant Operators the access they need\u00a0\u2013 you must ensure the service account has all necessary Role-Based Access Control (RBAC) permissions. If the service account is missing permissions, the extension\u2019s installation will fail or hang. To address this, the operator-controller now performs a preflight permissions check before installing an extension. This check identifies any missing RBAC permissions up front and surfaces them to you so that you can fix the issues.</p>"},{"location":"draft/howto/rbac-permissions-checking/#understanding-the-preflight-permissions-check","title":"Understanding the Preflight Permissions Check","text":"<p>When you create a <code>ClusterExtension</code> Custom Resource (CR) to install an Operator extension, the operator-controller will do a dry-run of the installation and verify that the specified service account can perform all the actions required by that extension. This includes creating all the Kubernetes objects in the bundle (Deployments, Services, CRDs, etc.), as well as creating any RBAC roles or bindings that the extension\u2019s bundle defines.</p> <p>If any required permission is missing, the preflight check will fail fast before attempting the real installation. Instead of proceeding, the operator-controller records which permissions are missing. You\u2019ll find this information in two places:</p> <ul> <li>ClusterExtension Status Conditions: The <code>ClusterExtension</code> CR will have a condition (such as Progressing or Installing) with a message describing the missing permissions. The condition\u2019s reason may be set to \u201cRetrying\u201d (meaning the controller will periodically retry the install) and the message will start with \u201cpre-authorization failed: \u2026\u201d.</li> <li>Operator-Controller Logs: The same message is also logged by the operator-controller pod. If you have access to the operator-controller\u2019s logs (in namespace <code>olm-controller</code> on OpenShift), you can see the detailed RBAC errors there as well.</li> </ul>"},{"location":"draft/howto/rbac-permissions-checking/#interpreting-the-preflight-check-output","title":"Interpreting the Preflight Check Output","text":"<p>The preflight check\u2019s output enumerates the RBAC rules that the service account is missing. Each missing permission is listed in a structured format. For example, a message might say:</p> <pre><code>service account requires the following permissions to manage cluster extension:\n Namespace:\"\" APIGroups:[] Resources:[services] Verbs:[list,watch]\n Namespace:\"pipelines\" APIGroups:[] Resources:[secrets] Verbs:[get]\n</code></pre> <p>Let\u2019s break down how to read this output:</p> <ul> <li><code>Namespace:\"\"</code> \u2013 An empty namespace in quotes means the permission is needed at the cluster scope (not limited to a single namespace). In the example above, <code>Namespace:\"\"</code> for Services indicates the service account needs the ability to list/watch Services cluster-wide.</li> <li><code>APIGroups:[]</code> \u2013 An empty API group (<code>[]</code>) means the core API group (no group). For instance, core resources like Services, Secrets, ConfigMaps have <code>APIGroups:[]</code>. If the resource is part of a named API group (e.g. <code>apps</code>, <code>apiextensions.k8s.io</code>), that group would be listed here.</li> <li><code>Resources:[...]</code> \u2013 The resource type that\u2019s missing permissions. e.g. <code>services</code>, <code>secrets</code>, <code>customresourcedefinitions</code>.</li> <li><code>Verbs:[...]</code> \u2013 The specific actions (verbs) that the service account is not allowed to do for that resource. Multiple verbs listed together means none of those verbs are permitted (and are all required).</li> </ul> <p>A few special cases to note:</p> <ul> <li>Privilege Escalation Cases: If the extension\u2019s bundle includes the creation of a Role or ClusterRole, the service account needs to have at least the permissions it is trying to grant. If not, the preflight check will report those verbs as missing to prevent privilege escalation.</li> <li>Missing Role References (Resolution Errors): If an Operator\u2019s bundle references an existing ClusterRole or Role that is not found, the preflight check will report an \u201cauthorization evaluation error\u201d listing the missing role.</li> </ul>"},{"location":"draft/howto/rbac-permissions-checking/#resolving-common-rbac-permission-errors","title":"Resolving Common RBAC Permission Errors","text":"<p>Once you understand what each missing permission is, the fix is usually straightforward: grant the service account those permissions. Here are common scenarios and how to address them:</p> <ul> <li>Missing resource permissions (verbs): Update or create a (Cluster)Role and RoleBinding/ClusterRoleBinding to grant the missing verbs on the resources in the specified namespaces or at cluster scope.</li> <li>Privilege escalation missing permissions: Treat these missing verbs as required for the installer as well, granting the service account those rights so it can create the roles it needs.</li> <li>Missing roles/clusterroles: Ensure any referenced roles exist by creating them or adjusting the extension\u2019s expectations.</li> </ul>"},{"location":"draft/howto/rbac-permissions-checking/#demo-scenario-openshift","title":"Demo Scenario (OpenShift)","text":"<p>Below is an example demo you can run on OpenShift to see the preflight check in action:</p> <ol> <li>Create a minimal ServiceAccount and ClusterRole that lacks key permissions (e.g., missing list/watch on Services and create on CRDs).</li> <li>Apply a ClusterExtension pointing to the Pipelines Operator package, specifying the above service account.</li> <li>Describe the ClusterExtension (<code>oc describe clusterextension pipelines-operator</code>) to see the preflight \u201cpre-authorization failed\u201d errors listing missing permissions.</li> <li>Update the ClusterRole to include the missing verbs.</li> <li>Reapply the role and observe the ClusterExtension status clear and the operator proceed with installation.</li> </ol> <p>By following this guide and using the preflight output, you can iteratively grant exactly the permissions needed\u2014no more, no less\u2014ensuring your cluster extensions install reliably and securely.</p>"},{"location":"draft/howto/single-ownnamespace-install/","title":"Single ownnamespace install","text":""},{"location":"draft/howto/single-ownnamespace-install/#description","title":"Description","text":"<p>Note</p> <p>The <code>SingleOwnNamespaceInstallSupport</code> feature-gate is enabled by default. Use this guide to configure bundles that need Single or Own namespace install modes.</p> <p>A component of OLMv0's multi-tenancy feature is its support of four installModes: for operator installation:</p> <ul> <li>OwnNamespace: If supported, the operator can be configured to watch for events in the namespace it is deployed in.</li> <li>SingleNamespace: If supported, the operator can be configured to watch for events in a single namespace that the operator is not deployed in.</li> <li>MultiNamespace: If supported, the operator can be configured to watch for events in more than one namespace.</li> <li>AllNamespaces: If supported, the operator can be configured to watch for events in all namespaces.</li> </ul> <p>OLMv1 will not attempt multi-tenancy (see design decisions document) and will think of operators as globally installed, i.e. in OLMv0 parlance, as installed in AllNamespaces mode. However, there are operators that were intended only for the SingleNamespace and OwnNamespace install modes. In order to make these operators installable in v1 while they transition to the new model, v1 is adding support for these two new installModes. It should be noted that, in line with v1's no multi-tenancy policy, users will not be able to install the same operator multiple times, and that in future iterations of the registry bundle format will not include installModes.</p>"},{"location":"draft/howto/single-ownnamespace-install/#demos","title":"Demos","text":""},{"location":"draft/howto/single-ownnamespace-install/#singlenamespace-install","title":"SingleNamespace Install","text":""},{"location":"draft/howto/single-ownnamespace-install/#ownnamespace-install","title":"OwnNamespace Install","text":""},{"location":"draft/howto/single-ownnamespace-install/#configuring-the-clusterextension","title":"Configuring the <code>ClusterExtension</code>","text":"<p>A <code>ClusterExtension</code> can be configured to install bundle in <code>Single-</code> or <code>OwnNamespace</code> mode through the <code>.spec.config.inline.watchNamespace</code> property which may or may not be present or required depending on the bundle's install mode support, if the bundle:</p> <ul> <li>only supports AllNamespaces mode =&gt; <code>watchNamespace</code> is not a configuration</li> <li>supports AllNamespaces and SingleNamespace and/or OwnNamespace =&gt; <code>watchNamespace</code> is optional</li> <li>bundle only supports SingleNamespace and/or OwnNamespace =&gt; <code>watchNamespace</code> is required</li> </ul> <p>The <code>watchNamespace</code> configuration can only be the install namespace if the bundle supports the OwnNamespace install mode, and it can only be any other namespace if the bundle supports the SingleNamespace install mode.</p> <p>Examples:</p> <p>Bundle only supports AllNamespaces: - <code>watchNamespace</code> is not a configuration - bundle will be installed in AllNamespaces mode</p> <p>Bundle only supports OwnNamespace: - <code>watchNamespace</code> is required - <code>watchNamespace</code> must be the install namespace - bundle will always be installed in OwnNamespace mode</p> <p>Bundle supports AllNamespace and OwnNamespace: - <code>watchNamespace</code> is optional - if <code>watchNamespace</code> = install namespace =&gt; bundle will be installed in OwnNamespace mode - if <code>watchNamespace</code> is null or not set =&gt; bundle will be installed in AllNamespaces mode - if <code>watchNamespace</code> != install namespace =&gt; error</p> <p>Bundle only supports SingleNamespace: - <code>watchNamespace</code> is required - <code>watchNamespace</code> must NOT be the install namespace - bundle will always be installed in SingleNamespace mode</p> <p>Bundle supports AllNamespaces, SingleNamespace, and OwnNamespace install modes: - <code>watchNamespace</code> can be optionally configured - if <code>watchNamespace</code> = install namespace =&gt; bundle will be installed in OwnNamespace mode - if <code>watchNamespace</code> != install namespace =&gt; bundle will be installed in SingleNamespace mode - if <code>watchNamespace</code> is null or not set =&gt; bundle will be installed in AllNamespaces mode</p>"},{"location":"draft/howto/single-ownnamespace-install/#examples","title":"Examples","text":"SingleNamespace install mode example<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  config:\n    inline:\n      watchNamespace: argocd-watch\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.2.1 # Update to version 0.2.1\n    EOF\n</code></pre> OwnNamespace install mode example<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  config:\n    inline:\n      watchNamespace: argocd\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.2.1 # Update to version 0.2.1\n    EOF\n</code></pre>"},{"location":"draft/howto/use-synthetic-permissions/","title":"Use synthetic permissions","text":""},{"location":"draft/howto/use-synthetic-permissions/#synthetic-user-permissions","title":"Synthetic User Permissions","text":"<p>Note</p> <p>This feature is still in alpha the <code>SyntheticPermissions</code> feature-gate must be enabled to make use of it. See the instructions below on how to enable it.</p> <p>Synthetic user permissions enables fine-grained configuration of ClusterExtension management client RBAC permissions. User can not only configure RBAC permissions governing the management across all ClusterExtensions, but also on a  case-by-case basis.</p>"},{"location":"draft/howto/use-synthetic-permissions/#run-olm-v1with-experimental-features-enabled","title":"Run OLM v1with Experimental Features Enabled","text":"<p>```terminal title=Enable Experimental Features in a New Kind Cluster make run-experimental <pre><code>```terminal title=Wait for rollout to complete\nkubectl rollout status -n olmv1-system deployment/operator-controller-controller-manager \n</code></pre></p>"},{"location":"draft/howto/use-synthetic-permissions/#how-does-it-work","title":"How does it work?","text":"<p>When managing a ClusterExtension, OLM will assume the identity of user \"olm:clusterextensions:\" and group \"olm:clusterextensions\" limiting Kubernetes API access scope to those defined for this user and group. These users and group do not exist beyond being defined in Cluster/RoleBinding(s) and can only be impersonated by clients with  <code>impersonate</code> verb permissions on the <code>users</code> and <code>groups</code> resources."},{"location":"draft/howto/use-synthetic-permissions/#demo","title":"Demo","text":""},{"location":"draft/howto/use-synthetic-permissions/#examples","title":"Examples:","text":""},{"location":"draft/howto/use-synthetic-permissions/#clusterextension-management-as-cluster-admin","title":"ClusterExtension management as cluster-admin","text":"<p>To enable ClusterExtensions management as cluster-admin, bind the <code>cluster-admin</code> cluster role to the <code>olm:clusterextensions</code> group:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n    name: clusterextensions-group-admin-binding\nroleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: ClusterRole\n    name: cluster-admin\nsubjects:\n- kind: Group\n  name: \"olm:clusterextensions\"\n</code></pre>"},{"location":"draft/howto/use-synthetic-permissions/#scoped-olmclusterextension-group-added-perms-on-specific-extensions","title":"Scoped olm:clusterextension group + Added perms on specific extensions","text":"<p>Give ClusterExtension management group broad permissions to manage ClusterExtensions denying potentially dangerous permissions such as being able to read cluster wide secrets:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: clusterextension-installer\nrules:\n  - apiGroups: [ olm.operatorframework.io ]\n    resources: [ clusterextensions/finalizers ]\n    verbs: [ update ]\n  - apiGroups: [ apiextensions.k8s.io ]\n    resources: [ customresourcedefinitions ]\n    verbs: [ create, list, watch, get, update, patch, delete ]\n  - apiGroups: [ rbac.authorization.k8s.io ]\n    resources: [ clusterroles, roles, clusterrolebindings, rolebindings ]\n    verbs: [ create, list, watch, get, update, patch, delete ]\n  - apiGroups: [\"\"]\n    resources: [configmaps, endpoints, events, pods, pod/logs, serviceaccounts, services, services/finalizers, namespaces, persistentvolumeclaims]\n    verbs: ['*']\n  - apiGroups: [apps]\n    resources: [ '*' ]\n    verbs: ['*']\n  - apiGroups: [ batch ]\n    resources: [ '*' ]\n    verbs: [ '*' ]\n  - apiGroups: [ networking.k8s.io ]\n    resources: [ '*' ]\n    verbs: [ '*' ]\n  - apiGroups: [authentication.k8s.io]\n    resources: [tokenreviews, subjectaccessreviews]\n    verbs: [create]\n</code></pre> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n    name: clusterextension-installer-binding\nroleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: ClusterRole\n    name: clusterextension-installer\nsubjects:\n- kind: Group\n  name: \"olm:clusterextensions\"\n</code></pre> <p>Give a specific ClusterExtension secrets access, maybe even on specific namespaces:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n    name: clusterextension-privileged\nrules:\n- apiGroups: [\"\"]\n  resources: [secrets]\n  verbs: ['*']\n</code></pre> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n    name: clusterextension-privileged-binding\n    namespace: &lt;some namespace&gt;\nroleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: ClusterRole\n    name: clusterextension-privileged\nsubjects:\n- kind: User\n  name: \"olm:clusterextensions:argocd-operator\"\n</code></pre> <p>Note: In this example the ClusterExtension user (or group) will still need to be updated to be able to manage the CRs coming from the argocd operator. Some look ahead and RBAC permission wrangling will still be required.</p>"},{"location":"draft/project/personas/","title":"OLM Personas","text":"<p>This document attempts to identify essential roles in the OLM lifecycle and associate the duties logically performed by each role. Though some roles can be (and even may typically be) performed by the same actor, they are logically distinct roles with different goals.</p> <p>OLM roles are broadly categorized here as Producers or Consumers, indicating whether that role typically is producing content for use in the ecosystem or is using (consuming) content.</p>"},{"location":"draft/project/personas/#consumers","title":"Consumers","text":""},{"location":"draft/project/personas/#cluster-admin","title":"Cluster Admin","text":"<p>Who is it?</p> <p>This role encompasses the basic full-permissions-required creation/maintenance of a cluster, and any non-OLM-ecosystem activities, such as creating, scaling, and upgrading a cluster.</p> <p>What does it do?</p> <ul> <li>Creates cluster</li> <li>Scales cluster</li> <li>Miscellaneous Cluster Administration</li> <li>Upgrades cluster</li> </ul>"},{"location":"draft/project/personas/#cluster-extension-admin","title":"Cluster Extension Admin","text":"<p>Who is it?</p> <p>This role encompasses privileged operations required for OLMv1 and associated operators to deploy workloads to the cluster. This role may exist as a set of activities executed by a cluster admin, but also may operate independently of that role, depending on the necessary privileges. Here <code>extension</code> represents any individual OLMv1 installable, including (but not limited to) <code>registry+v1</code> bundles.</p> <p>What does it do?</p> <ul> <li>Creates enabling infrastructure for extension lifecycle (service accounts, etc.)</li> <li>Installs extensions</li> <li>Upgrades extensions</li> <li>Removes extensions</li> <li>Browses extensions offered in installed <code>ClusterCatalogs</code></li> <li>Derives minimum privilege for installation</li> <li>filters visibility on installable extensions</li> <li>Verifies that extension health is detectable to desired sensors</li> </ul>"},{"location":"draft/project/personas/#cluster-catalog-admin","title":"Cluster Catalog Admin","text":"<p>Who is it?</p> <p>This role encompasses the control of <code>ClusterCatalogs</code> on the running cluster.  This role may exist as a set of activities executed by a cluster admin, but also may operate independently of that role, depending on the necessary privileges.  This role is a collaboration with Catalog Curators and may also interact with Catalog Manipulators</p> <p>What does it do?</p> <ul> <li>Adds/removes/updates catalogs</li> <li>Enables/disables catalogs</li> <li>Configures pull secrets necessary to access extensions from catalogs</li> </ul>"},{"location":"draft/project/personas/#cluster-monitors","title":"Cluster Monitors","text":"<p>Who is it?</p> <p>This role represents any actor which monitors the status of the cluster and installed workloads.  This may include - Platform status - Extension health - Diagnostic notifications</p>"},{"location":"draft/project/personas/#producers","title":"Producers","text":""},{"location":"draft/project/personas/#extension-author","title":"Extension Author","text":"<p>Who is it?</p> <p>This role encompasses folks who want to create an extension.  It interacts with other Producer roles by generating a catalog contribution to make extensions available on-cluster to Cluster Extension Admins. For example, a catalog contribution for a registry+v1 bundle is one/more bundle image and the upgrade graph expressed in FBC.</p> <p>What does it do? - Creates extension - Builds/releases extension - Validates extension - Adjusts upgrade graph - Publishes artifacts (i.e. images for registry+v1 bundle)</p>"},{"location":"draft/project/personas/#contribution-curator","title":"Contribution Curator","text":"<p>Who is it?</p> <p>This role is responsible for taking catalog contributions from Extension Authors, applying any changes necessary for publication, and supplying the resulting artifacts to the Catalog Curator. This role is frequently fulfilled by different developers than Extension Authors. </p> <p>What does it do? - Validates contributions - Publishes contributions to registry</p>"},{"location":"draft/project/personas/#catalog-curator","title":"Catalog Curator","text":"<p>Who is it?</p> <p>This role is responsible for publishing a catalog index image to be used by Consumers to make workloads available on-cluster.  Typically this role operates over multiple extensions, versions, and versioned releases of the final, published catalog. </p> <p>What does it do? - Aggregates contributions - Validates aggregate catalog - Publishes aggregate catalog</p>"},{"location":"draft/project/personas/#catalog-manipulator","title":"Catalog Manipulator","text":"<p>Who is it?</p> <p>This role is a general category for users who consume published catalogs and re-publish them in some way.  Possible use-cases include - Restricting available extension versions - Providing enclave services to disconnected environments - Reducing catalog size by restricting the number of included extensions</p> <p>What does it do? - Filters content - Defines content access mapping to new environments (if modified) - Provides catalog access in restricted environments</p>"},{"location":"draft/tutorials/explore-available-content-metas-endpoint/","title":"Explore Available Content","text":"<p>After you add a catalog of extensions to your cluster, you must port forward your catalog as a service. Then you can query the catalog by using <code>curl</code> commands and the <code>jq</code> CLI tool to find extensions to install.</p>"},{"location":"draft/tutorials/explore-available-content-metas-endpoint/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have added a ClusterCatalog of extensions, such as OperatorHub.io, to your cluster.</li> <li>You have installed the <code>jq</code> CLI tool.</li> </ul> <p>Note</p> <p>By default, Catalogd is installed with TLS enabled for the catalog webserver. The following examples will show this default behavior, but for simplicity's sake will ignore TLS verification in the curl commands using the <code>-k</code> flag.</p>"},{"location":"draft/tutorials/explore-available-content-metas-endpoint/#procedure","title":"Procedure","text":"<ol> <li> <p>Port forward the catalog server service:</p> <pre><code>kubectl -n olmv1-system port-forward svc/catalogd-service 8443:443\n</code></pre> </li> <li> <p>Return a list of all the extensions in a catalog via the v1 API endpoint:     <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.package' | jq -s '.[] | .name'\n</code></pre></p> Success Example output<pre><code>\"ack-acm-controller\"\n\"ack-acmpca-controller\"\n\"ack-apigatewayv2-controller\"\n\"ack-applicationautoscaling-controller\"\n\"ack-cloudfront-controller\"\n\"ack-cloudtrail-controller\"\n\"ack-cloudwatch-controller\"\n\"ack-cloudwatchlogs-controller\"\n\"ack-dynamodb-controller\"\n\"ack-ec2-controller\"\n\"ack-ecr-controller\"\n\"ack-ecs-controller\"\n\"ack-efs-controller\"\n\"ack-eks-controller\"\n\"ack-elasticache-controller\"\n\"ack-emrcontainers-controller\"\n\"ack-eventbridge-controller\"\n\"ack-iam-controller\"\n\"ack-kafka-controller\"\n\"ack-keyspaces-controller\"\n\"ack-kinesis-controller\"\n\"ack-kms-controller\"\n\"ack-lambda-controller\"\n\"ack-memorydb-controller\"\n\"ack-mq-controller\"\n\"ack-networkfirewall-controller\"\n\"ack-opensearchservice-controller\"\n\"ack-pipes-controller\"\n\"ack-prometheusservice-controller\"\n\"ack-rds-controller\"\n\"ack-route53-controller\"\n\"ack-route53resolver-controller\"\n\"ack-s3-controller\"\n\"ack-sagemaker-controller\"\n\"ack-secretsmanager-controller\"\n\"ack-sfn-controller\"\n\"ack-sns-controller\"\n\"ack-sqs-controller\"\n\"aerospike-kubernetes-operator\"\n\"airflow-helm-operator\"\n\"aiven-operator\"\n\"akka-cluster-operator\"\n\"alvearie-imaging-ingestion\"\n\"anchore-engine\"\n\"apch-operator\"\n\"api-operator\"\n\"api-testing-operator\"\n\"apicast-community-operator\"\n\"apicurio-registry\"\n\"apimatic-kubernetes-operator\"\n\"app-director-operator\"\n\"appdynamics-operator\"\n\"application-services-metering-operator\"\n\"appranix\"\n\"aqua\"\n\"argocd-operator\"\n...\n</code></pre> </li> <li> <p>Return list of packages which support <code>AllNamespaces</code> install mode, do not use webhooks, and where the channel head version uses <code>olm.csv.metadata</code> format:</p> <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.bundle | jq -cs '[.[] | select(.properties[] | select(.type == \"olm.csv.metadata\").value.installModes[] | select(.type == \"AllNamespaces\" and .supported == true) and .spec.webhookdefinitions == null) | .package] | unique[]'\n</code></pre> Success Example output<pre><code>\"ack-acm-controller\"\n\"ack-acmpca-controller\"\n\"ack-apigateway-controller\"\n\"ack-apigatewayv2-controller\"\n\"ack-applicationautoscaling-controller\"\n\"ack-athena-controller\"\n\"ack-cloudfront-controller\"\n\"ack-cloudtrail-controller\"\n\"ack-cloudwatch-controller\"\n\"ack-cloudwatchlogs-controller\"\n\"ack-documentdb-controller\"\n\"ack-dynamodb-controller\"\n\"ack-ec2-controller\"\n\"ack-ecr-controller\"\n\"ack-ecs-controller\"\n...\n</code></pre> </li> <li> <p>Inspect the contents of an extension's metadata:</p> <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/metas?schema=olm.package&amp;name=&lt;package_name&gt;\n</code></pre> <code>package_name</code> Specifies the name of the package you want to inspect. Success Example output<pre><code>{\n  \"defaultChannel\": \"stable-v6.x\",\n  \"icon\": {\n    \"base64data\": \"PHN2ZyB4bWxucz0ia...\n    \"mediatype\": \"image/svg+xml\"\n  },\n  \"name\": \"cockroachdb\",\n  \"schema\": \"olm.package\"\n}\n</code></pre> </li> </ol>"},{"location":"draft/tutorials/explore-available-content-metas-endpoint/#additional-resources","title":"Additional resources","text":"<ul> <li>Catalog queries</li> </ul>"},{"location":"getting-started/olmv1_getting_started/","title":"Getting Started","text":""},{"location":"getting-started/olmv1_getting_started/#installation","title":"Installation","text":"<p>The following script will install OLMv1 on a Kubernetes cluster. If you don't have one, you can deploy a Kubernetes cluster with KIND.</p> <p>Warning</p> <p>Operator-Controller depends on cert-manager. Running the following command may affect an existing installation of cert-manager and cause cluster instability.</p> <p>The latest version of Operator Controller can be installed with the following command:</p> <pre><code>curl -L -s https://github.com/operator-framework/operator-controller/releases/latest/download/install.sh | bash -s\n</code></pre>"},{"location":"getting-started/olmv1_getting_started/#getting-started-with-olm-v1","title":"Getting Started with OLM v1","text":"<p>This quickstart procedure will guide you through the following processes:</p> <ul> <li>Deploying a catalog</li> <li>Installing, upgrading, or downgrading an extension</li> <li>Deleting catalogs and extensions</li> </ul>"},{"location":"getting-started/olmv1_getting_started/#create-a-catalog","title":"Create a Catalog","text":"<p>OLM v1 is designed to source content from an on-cluster catalog in the file-based catalog (FBC) format. These catalogs are deployed and configured through the <code>ClusterCatalog</code> resource. More information on adding catalogs can be found here.</p> <p>The following example uses the official OperatorHub catalog that contains many different extensions to choose from. Note that this catalog contains packages designed to work with OLM v0, and that not all packages will work with OLM v1. More information on catalog exploration and content compatibility can be found here.</p> <p>To create the catalog, run the following command:</p> <pre><code># Create ClusterCatalog\nkubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: operatorhubio\nspec:\n  source:\n    type: Image\n    image:\n      ref: quay.io/operatorhubio/catalog:latest\n      pollIntervalMinutes: 10\nEOF\n</code></pre> <p>Once the catalog is being served, its content will be available for installation.</p> <pre><code># Wait for the ClusterCatalog to be ready\nkubectl wait --for=condition=Serving=True clustercatalog/operatorhubio --timeout=60s\n</code></pre>"},{"location":"getting-started/olmv1_getting_started/#install-a-cluster-extension","title":"Install a Cluster Extension","text":"<p>For simplicity, the following example manifest includes all necessary resources to install the ArgoCD operator. The manifest includes installation namespace, installer service account and associated minimal set of RBAC permissions needed for installation, and the ClusterExtension resource, which specifies the name and version of the extension to install. More information on installing extensions can be found here.</p> <pre><code># Apply the sample ClusterExtension. Manifest already includes\n# namespace and adequately privileged service account\nkubectl apply -f https://raw.githubusercontent.com/operator-framework/operator-controller/main/config/samples/olm_v1_clusterextension.yaml\n</code></pre>"},{"location":"getting-started/olmv1_getting_started/#upgrade-the-cluster-extension","title":"Upgrade the Cluster Extension","text":"<p>To upgrade the installed extension, update the version field in the ClusterExtension resource. Note that there must be CRD compatibility between the versions being upgraded, and the target version must be compatible with OLM v1. More information on CRD upgrade safety can be found here, and more information on the extension upgrade process can be found here.</p> <pre><code># Update to v0.11.0\nkubectl patch clusterextension argocd --type='merge' -p '{\"spec\": {\"source\": {\"catalog\": {\"version\": \"0.11.0\"}}}}'\n</code></pre> <p>For information on the downgrade process, see here.</p>"},{"location":"getting-started/olmv1_getting_started/#uninstall-the-cluster-extension","title":"Uninstall the Cluster Extension","text":"<p>To uninstall an extension, delete the ClusterExtension resource. This will trigger the uninstallation process, which will remove all resources created by the extension. More information on uninstalling extensions can be found here.</p> <pre><code># Delete cluster extension and residing namespace\nkubectl delete clusterextension/argocd\n</code></pre>"},{"location":"getting-started/olmv1_getting_started/#cleanup","title":"Cleanup","text":"<p>Extension installation requires the creation of a namespace, an installer service account, and its RBAC. Once the extension is uninstalled, these resources can be cleaned up.</p> <pre><code># Delete namespace, and by extension, the installer service account, Role, and RoleBinding\nkubectl delete namespace argocd\n</code></pre> <pre><code># Delete installer service account cluster roles\nkubectl delete clusterrole argocd-installer-clusterrole &amp;&amp; kubectl delete clusterrole argocd-installer-rbac-clusterrole\n</code></pre> <pre><code># Delete installer service account cluster role bindings\nkubectl delete clusterrolebinding argocd-installer-binding &amp;&amp; kubectl delete clusterrolebinding argocd-installer-rbac-binding\n</code></pre>"},{"location":"howto/catalog-queries/","title":"Catalog queries","text":"<p>After you add a catalog of extensions to your cluster, you must port forward your catalog as a service. Then you can query the catalog by using <code>curl</code> commands and the <code>jq</code> CLI tool to find extensions to install.</p>"},{"location":"howto/catalog-queries/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have added a ClusterCatalog of extensions, such as OperatorHub.io, to your cluster.</li> <li>You have installed the <code>jq</code> CLI tool.</li> </ul> <p>Note</p> <p>By default, Catalogd is installed with TLS enabled for the catalog webserver. The following examples will show this default behavior, but for simplicity's sake will ignore TLS verification in the curl commands using the <code>-k</code> flag.</p> <p>You also need to port forward the catalog server service:</p> <pre><code>kubectl -n olmv1-system port-forward svc/catalogd-service 8443:443\n</code></pre> <p>Now you can use the <code>curl</code> command with <code>jq</code> to query catalogs that are installed on your cluster.</p> Query syntax<pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/all | &lt;query&gt;\n</code></pre> <code>&lt;query&gt;</code> One of the <code>jq</code> queries from this document"},{"location":"howto/catalog-queries/#package-queries","title":"Package queries","text":"<ul> <li> <p>Available packages in a catalog:     <pre><code>jq -s '.[] | select( .schema == \"olm.package\")'\n</code></pre></p> </li> <li> <p>Packages that support <code>AllNamespaces</code> install mode and do not use webhooks:     <pre><code>jq -cs '[.[] | select(.schema == \"olm.bundle\" and (.properties[] | select(.type == \"olm.csv.metadata\").value.installModes[] | select(.type == \"AllNamespaces\" and .supported == true)) and .spec.webhookdefinitions == null) | .package] | unique[]'\n</code></pre></p> </li> <li> <p>Package metadata:     <pre><code>jq -s '.[] | select( .schema == \"olm.package\") | select( .name == \"&lt;package_name&gt;\")'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Catalog blobs in a package:     <pre><code>jq -s '.[] | select( .package == \"&lt;package_name&gt;\")'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> </ul>"},{"location":"howto/catalog-queries/#channel-queries","title":"Channel queries","text":"<ul> <li> <p>Channels in a package:     <pre><code>jq -s '.[] | select( .schema == \"olm.channel\" ) | select( .package == \"&lt;package_name&gt;\") | .name'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Versions in a channel:     <pre><code>jq -s '.[] | select( .package == \"&lt;package_name&gt;\" ) | select( .schema == \"olm.channel\" ) | select( .name == \"&lt;channel_name&gt;\" ) | .entries | .[] | .name'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. <code>&lt;channel_name&gt;</code> Name of the channel for a given package. </li> <li> <p>Latest version in a channel and upgrade path:     <pre><code>jq -s '.[] | select( .schema == \"olm.channel\" ) | select ( .name == \"&lt;channel_name&gt;\") | select( .package == \"&lt;package_name&gt;\")'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. <code>&lt;channel_name&gt;</code> Name of the channel for a given package. </li> </ul>"},{"location":"howto/catalog-queries/#bundle-queries","title":"Bundle queries","text":"<ul> <li> <p>Bundles in a package:     <pre><code>jq -s '.[] | select( .schema == \"olm.bundle\" ) | select( .package == \"&lt;package_name&gt;\") | .name'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. </li> <li> <p>Bundle dependencies and available APIs:     <pre><code>jq -s '.[] | select( .schema == \"olm.bundle\" ) | select ( .name == \"&lt;bundle_name&gt;\") | select( .package == \"&lt;package_name&gt;\")'\n</code></pre></p> <code>&lt;package_name&gt;</code> Name of the package from the catalog you are querying. <code>&lt;bundle_name&gt;</code> Name of the bundle for a given package. </li> </ul>"},{"location":"howto/derive-service-account/","title":"Derive minimal ServiceAccount required for ClusterExtension Installation and Management","text":"<p>OLM v1 does not have permission to install extensions on a cluster by default. In order to install a supported bundle, OLM must be provided a ServiceAccount configured with the appropriate permissions.</p> <p>This document serves as a guide for how to derive the RBAC necessary to install a bundle.</p>"},{"location":"howto/derive-service-account/#required-rbac","title":"Required RBAC","text":"<p>The required permissions for the installation and management of a cluster extension can be determined by examining the contents of its bundle image. This bundle image contains all the manifests that make up the extension (e.g. <code>CustomResourceDefinition</code>s, <code>Service</code>s, <code>Secret</code>s, <code>ConfigMap</code>s, <code>Deployment</code>s etc.) as well as a <code>ClusterServiceVersion</code> (CSV) that describes the extension and its service account's permission requirements.</p> <p>The service account must have permissions to:</p> <ul> <li>create and manage the extension's <code>CustomResourceDefinition</code>s</li> <li>create and manage the resources packaged in the bundle</li> <li>grant the extension controller's service account the permissions it requires for its operation</li> <li>create and manage the extension controller's service account</li> <li>create and manage the <code>Role</code>s, <code>RoleBinding</code>s, <code>ClusterRole</code>s, and <code>ClusterRoleBinding</code>s associated with the extension controller's service account</li> <li>create and manage the extension controller's deployment</li> </ul> <p>Additionally, for clusters that use the OwnerReferencesPermissionEnforcement admission plug-in, the service account must also have permissions to:</p> <ul> <li>update finalizers on the ClusterExtension to be able to set blockOwnerDeletion and ownerReferences</li> </ul> <p>It is good security practice to follow the principle of least privilege, and scope permissions to specific resource names, wherever possible. Keep in mind, that it is not possible to scope <code>create</code>, <code>list</code>, and <code>watch</code> permissions to specific resource names.</p> <p>Depending on the scope, each permission will need to be added to either a <code>ClusterRole</code> or a <code>Role</code> and then bound to the service account with a <code>ClusterRoleBinding</code> or a <code>RoleBinding</code>.</p>"},{"location":"howto/derive-service-account/#example","title":"Example","text":"<p>The following example illustrates the process of deriving the minimal RBAC required to install the ArgoCD Operator v0.6.0 provided by OperatorHub.io. The final permission set can be found in the ClusterExtension sample manifest in the samples directory.</p> <p>The bundle includes the following manifests, which can be found here:</p> <ul> <li><code>ClusterServiceVersion</code>:<ul> <li>argocd-operator.v0.6.0.clusterserviceversion.yaml</li> </ul> </li> <li><code>CustomResourceDefinition</code>s:<ul> <li>argoproj.io_applicationsets.yaml</li> <li>argoproj.io_applications.yaml</li> <li>argoproj.io_appprojects.yaml</li> <li>argoproj.io_argocdexports.yaml</li> <li>argoproj.io_argocds.yaml</li> </ul> </li> <li>Additional resources:<ul> <li>argocd-operator-controller-manager-metrics-service_v1_service.yaml</li> <li>argocd-operator-manager-config_v1_configmap.yaml</li> <li>argocd-operator-metrics-reader_rbac.authorization.k8s.io_v1_clusterrole.yaml</li> </ul> </li> </ul> <p>The <code>ClusterServiceVersion</code> defines a single <code>Deployment</code> in <code>spec.install.deployments</code> named <code>argocd-operator-controller-manager</code> with a <code>ServiceAccount</code> of the same name. It declares the following cluster-scoped permissions in <code>spec.install.clusterPermissions</code>, and its namespace-scoped permissions in <code>spec.install.permissions</code>.</p>"},{"location":"howto/derive-service-account/#derive-permissions-for-the-installer-service-account-clusterrole","title":"Derive permissions for the installer service account <code>ClusterRole</code>","text":""},{"location":"howto/derive-service-account/#step-1-rbac-creation-and-management-permissions","title":"Step 1. RBAC creation and management permissions","text":"<p>The installer service account must create and manage the <code>ClusterRole</code>s and <code>ClusterRoleBinding</code>s for the extension controller(s). Therefore, it must have the following permissions:</p> <pre><code>- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: [create, list, watch]\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: [get, update, patch, delete]\n  resourceNames: [&lt;controller cluster role name 1&gt;, ...]\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterrolebindings]\n  verbs: [create, list, watch]\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterrolebindings]\n  verbs: [get, update, patch, delete]\n  resourceNames: [&lt;controller cluster rolebinding name 1&gt;, ...]\n</code></pre> <p>Note</p> <p>The <code>resourceNames</code> field should be populated with the names of the <code>ClusterRole</code>s and <code>ClusterRoleBinding</code>s created by OLM v1. These names are generated with the following format: <code>&lt;packageName&gt;.&lt;hash&gt;</code>. Since it is not a trivial task to generate these names ahead of time, it is recommended to use a wildcard <code>*</code> in the <code>resourceNames</code> field for the installation. Then, update the <code>resourceNames</code> fields by inspecting the cluster for the generated resource names. For instance, for <code>ClusterRole</code>s:</p> <pre><code>kubectl get clusterroles | grep argocd\n</code></pre> <p>Example output:</p> <pre><code>argocd-installer-clusterrole                                           2024-09-30T08:02:09Z\nargocd-installer-rbac-clusterrole                                      2024-09-30T08:02:09Z\nargocd-operator-metrics-reader                                         2024-09-30T08:02:12Z\n# The following are the generated ClusterRoles\nargocd-operator.v0-1dhiybrldl1gyksid1dk2dqjsc72psdybc7iyvse5gpx        2024-09-30T08:02:12Z\nargocd-operator.v0-22gmilmgp91wu25is5i2ec598hni8owq3l71bbkl7iz3        2024-09-30T08:02:12Z\n</code></pre> <p>The same can be done for <code>ClusterRoleBindings</code>.</p>"},{"location":"howto/derive-service-account/#step-2-customresourcedefinition-permissions","title":"Step 2. <code>CustomResourceDefinition</code> permissions","text":"<p>The installer service account must be able to create and manage the <code>CustomResourceDefinition</code>s for the extension, as well as grant the extension controller's service account the permissions it needs to manage its CRDs.</p> <pre><code>- apiGroups: [apiextensions.k8s.io]\n  resources: [customresourcedefinitions]\n  verbs: [create, list, watch]\n- apiGroups: [apiextensions.k8s.io]\n  resources: [customresourcedefinitions]\n  verbs: [get, update, patch, delete]\n  # Scoped to the CRDs in the bundle\n  resourceNames: [applications.argoproj.io, appprojects.argoproj.io, argocds.argoproj.io, argocdexports.argoproj.io, applicationsets.argoproj.io]\n</code></pre>"},{"location":"howto/derive-service-account/#step-3-ownerreferencespermissionenforcement-permissions","title":"Step 3. <code>OwnerReferencesPermissionEnforcement</code> permissions","text":"<p>For clusters that use <code>OwnerReferencesPermissionEnforcement</code>, the installer service account must be able to update finalizers on the ClusterExtension to be able to set blockOwnerDeletion and ownerReferences for clusters that use <code>OwnerReferencesPermissionEnforcement</code>. This is only a requirement for clusters that use the OwnerReferencesPermissionEnforcement admission plug-in.</p> <pre><code>- apiGroups: [olm.operatorframework.io]\n  resources: [clusterextensions/finalizers]\n  verbs: [update]\n  # Scoped to the name of the ClusterExtension\n  resourceNames: [argocd-operator.v0.6.0]\n</code></pre>"},{"location":"howto/derive-service-account/#step-4-bundled-cluster-scoped-resource-permissions","title":"Step 4. Bundled cluster-scoped resource permissions","text":"<p>Permissions must be added for the creation and management of any cluster-scoped resources included in the bundle. In this example, the ArgoCD bundle contains a <code>ClusterRole</code> called <code>argocd-operator-metrics-reader</code>. Given that <code>ClusterRole</code> permissions have already been created in Step 1, it is sufficient to add the <code>argocd-operator-metrics-reader</code>resource name to the <code>resourceName</code> list of the pre-existing rule:</p> <pre><code>- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: [get, update, patch, delete]\n  resourceNames: [&lt;controller cluster role name 1&gt;, ..., argocd-operator-metrics-reader]\n</code></pre>"},{"location":"howto/derive-service-account/#step-5-operator-permissions-declared-in-the-clusterserviceversion","title":"Step 5. Operator permissions declared in the ClusterServiceVersion","text":"<p>Include all permissions defined in the <code>.spec.install.permissions</code> (reference) and <code>.spec.install.clusterPermissions</code> (reference) stanzas in the bundle's <code>ClusterServiceVersion</code>. These permissions are required by the extension controller, and therefore the installer service account must be able to grant them.</p> <p>Note</p> <p>There may be overlap between the rules defined in each stanza. Overlapping rules needn't be added twice.</p> <pre><code># from .spec.install.clusterPermissions\n- apiGroups: [\"\"]\n  resources: [\"configmaps\", \"endpoints\", \"events\", \"namespaces\", \"persistentvolumeclaims\", \"pods\", \"secrets\", \"serviceaccounts\", \"services\", \"services/finalizers\"]\n  verbs: [\"*\"]\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\"]\n  verbs: [\"get\"]\n- apiGroups: [\"apps\"]\n  resources: [\"daemonsets\", \"deployments\", \"replicasets\", \"statefulsets\"]\n  verbs: [\"*\"]\n- apiGroups: [\"apps\"]\n  resourceNames: [\"argocd-operator\"]\n  resources: [\"deployments/finalizers\"]\n  verbs: [\"update\"]\n- apiGroups: [\"apps.openshift.io\"]\n  resources: [\"deploymentconfigs\"]\n  verbs: [\"*\"]\n- apiGroups: [\"argoproj.io\"]\n  resources: [\"applications\", \"appprojects\"]\n  verbs: [\"*\"]\n- apiGroups: [\"argoproj.io\"]\n  resources: [\"argocdexports\", \"argocdexports/finalizers\", \"argocdexports/status\"]\n  verbs: [\"*\"]\n- apiGroups: [\"argoproj.io\"]\n  resources: [\"argocds\", \"argocds/finalizers\", \"argocds/status\"]\n  verbs: [\"*\"]\n- apiGroups: [\"autoscaling\"]\n  resources: [\"horizontalpodautoscalers\"]\n  verbs: [\"*\"]\n- apiGroups: [\"batch\"]\n  resources: [\"cronjobs\", \"jobs\"]\n  verbs: [\"*\"]\n- apiGroups: [\"config.openshift.io\"]\n  resources: [\"clusterversions\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"monitoring.coreos.com\"]\n  resources: [\"prometheuses\", \"servicemonitors\"]\n  verbs: [\"*\"]\n- apiGroups: [\"networking.k8s.io\"]\n  resources: [\"ingresses\"]\n  verbs: [\"*\"]\n- apiGroups: [\"oauth.openshift.io\"]\n  resources: [\"oauthclients\"]\n  verbs: [\"create\", \"delete\", \"get\", \"list\", \"patch\", \"update\", \"watch\"]\n- apiGroups: [\"rbac.authorization.k8s.io\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"rbac.authorization.k8s.io\"]\n  resources: [\"clusterrolebindings\", \"clusterroles\"]\n  verbs: [\"*\"]\n- apiGroups: [\"route.openshift.io\"]\n  resources: [\"routes\", \"routes/custom-host\"]\n  verbs: [\"*\"]\n- apiGroups: [\"template.openshift.io\"]\n  resources: [\"templateconfigs\", \"templateinstances\", \"templates\"]\n  verbs: [\"*\"]\n- apiGroups: [\"authentication.k8s.io\"]\n  resources: [\"tokenreviews\"]\n  verbs: [\"create\"]\n- apiGroups: [\"authorization.k8s.io\"]\n  resources: [\"subjectaccessreviews\"]\n  verbs: [\"create\"]\n\n# copied from .spec.install.permissions\n- apiGroups: [\"coordination.k8s.io\"]\n  resources: [\"leases\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n# overlapping permissions:\n# - apiGroups: [\"\"]\n#  resources: [\"configmaps\"]\n#  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n# - apiGroups: [\"\"]\n#  resources: [\"events\"]\n#  verbs: [\"create\", \"patch\"]\n</code></pre>"},{"location":"howto/derive-service-account/#derive-permissions-for-the-installer-service-account-role","title":"Derive permissions for the installer service account <code>Role</code>","text":"<p>The following steps detail how to define the namespace-scoped permissions needed by the installer service account's <code>Role</code>. The installer service account must create and manage the <code>RoleBinding</code>s for the extension controller(s).</p>"},{"location":"howto/derive-service-account/#step-1-deployment-permissions","title":"Step 1. <code>Deployment</code> permissions","text":"<p>The installer service account must be able to create and manage the <code>Deployment</code>s for the extension controller(s). The <code>Deployment</code> name(s) can be found in the <code>ClusterServiceVersion</code> resource packed in the bundle under <code>.spec.install.deployments</code> (reference). This example's <code>ClusterServiceVersion</code> can be found here.</p> <pre><code>- apiGroups: [apps]\n  resources: [deployments]\n  verbs: [create]\n- apiGroups: [apps]\n  resources: [deployments]\n  verbs: [get, list, watch, update, patch, delete]\n  # scoped to the extension controller deployment name\n  resourceNames: [argocd-operator-controller-manager]\n</code></pre>"},{"location":"howto/derive-service-account/#step-2-serviceaccount-permissions","title":"Step 2: <code>ServiceAccount</code> permissions","text":"<p>The installer service account must be able to create and manage the <code>ServiceAccount</code>(s) for the extension controller(s). The <code>ServiceAccount</code> name(s) can be found in deployment template in the <code>ClusterServiceVersion</code> resource packed in the bundle under <code>.spec.install.deployments</code>. This example's <code>ClusterServiceVersion</code> can be found here.</p> <pre><code>- apiGroups: [\"\"]\n  resources: [serviceaccounts]\n  verbs: [create, list, watch]\n- apiGroups: [\"\"]\n  resources: [serviceaccounts]\n  verbs: [get, update, patch, delete]\n  # scoped to the extension controller's deployment service account\n  resourceNames: [argocd-operator-controller-manager]\n</code></pre>"},{"location":"howto/derive-service-account/#step-3-bundled-namespace-scoped-resource-permissions","title":"Step 3. Bundled namespace-scoped resource permissions","text":"<p>The installer service account must also create and manage other namespace-scoped resources included in the bundle. In this example, the bundle also includes two additional namespace-scoped resources:</p> <ul> <li>the argocd-operator-controller-manager-metrics-service <code>Service</code>, and</li> <li>the argocd-operator-manager-config <code>ConfigMap</code></li> </ul> <p>Therefore, the following permissions must be given to the installer service account:</p> <pre><code>- apiGroups: [\"\"]\n  resources: [services]\n  verbs: [create]\n- apiGroups: [\"\"]\n  resources: [services]\n  verbs: [get, list, watch, update, patch, delete]\n  # scoped to the service name\n  resourceNames: [argocd-operator-controller-manager-metrics-service]\n- apiGroups: [\"\"]\n  resources: [configmaps]\n  verbs: [create]\n- apiGroups: [\"\"]\n  resources: [configmaps]\n  verbs: [get, list, watch, update, patch, delete]\n  # scoped to the configmap name\n  resourceNames: [argocd-operator-manager-config]\n</code></pre>"},{"location":"howto/derive-service-account/#putting-it-all-together","title":"Putting it all together","text":"<p>Once the installer service account required cluster-scoped and namespace-scoped permissions have been collected:</p> <ol> <li>Create the installation namespace</li> <li>Create the installer <code>ServiceAccount</code></li> <li>Create the installer <code>ClusterRole</code></li> <li>Create the <code>ClusterRoleBinding</code> between the installer service account and its cluster role</li> <li>Create the installer <code>Role</code></li> <li>Create the <code>RoleBinding</code> between the installer service account and its role</li> <li>Create the <code>ClusterExtension</code></li> </ol> <p>A manifest with the full set of resources can be found here.</p>"},{"location":"howto/derive-service-account/#alternatives","title":"Alternatives","text":"<p>We understand that manually determining the minimum RBAC required for installation/upgrade of a <code>ClusterExtension</code> quite complex and protracted. In the near future, OLM v1 will provide tools and automation in order to simplify this process while maintaining our security posture. For users wishing to test out OLM v1 in a non-production settings, we offer the following alternatives:</p>"},{"location":"howto/derive-service-account/#give-the-installer-service-account-admin-privileges","title":"Give the installer service account admin privileges","text":"<p>The <code>cluster-admin</code> <code>ClusterRole</code> can be bound to the installer service account giving it full permissions to the cluster. While this obviates the need to determine the minimal RBAC required for installation, it is also dangerous. It is highly recommended that this alternative only be used in test clusters. Never in production.</p> <p>Below is an example ClusterRoleBinding using the cluster-admin ClusterRole:</p> <pre><code># Create ClusterRole\nkubectl apply -f - &lt;&lt;EOF\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: my-cluster-extension-installer-role-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: my-cluster-extension-service-account\n  namespace: my-cluster-extension-namespace\nEOF\n</code></pre> <p>Use the below on a Kind cluster to assign cluster-admin privileges to your cluster extension</p> <pre><code>kubectl create clusterrolebinding my-cluster-extension-installer-role-binding \\\n  --clusterrole=cluster-admin \\\n  --serviceaccount=my-cluster-extension-namespace:my-cluster-installer-service-account\n</code></pre>"},{"location":"howto/derive-service-account/#hacktoolscatalog","title":"hack/tools/catalog","text":"<p>In the spirit of making this process more tenable until the proper tools are in place, the scripts in hack/tools/catalogs were created to help the user navigate and search catalogs as well as to generate the minimal RBAC requirements. These tools are offered as is, with no guarantees on their correctness, support, or maintenance. For more information, see Hack Catalog Tools.</p>"},{"location":"howto/how-to-channel-based-upgrades/","title":"Channel-Based Automatic Upgrades","text":"<p>A \"channel\" is a package author defined stream of updates for an extension. A set of channels can be set in the Catalog source to restrict automatic updates to the set of versions defined in those channels.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      # Automatically upgrade to the latest version found in the preview and dev-preview channels\n      channels: [dev-preview, preview]\n</code></pre> <p>Note that the <code>version</code> field also supports version pinning and version ranges to further restrict the set of possible upgradable operator versions.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      channels: [stable] # Automatically upgrade to the latest version found in \u2018stable\u2019\n      version: \"!=1.3.2\" # Don\u2019t allow version 1.3.2\n</code></pre> <p>For more information on SemVer version ranges see version ranges</p>"},{"location":"howto/how-to-grant-api-access/","title":"Granting Users Access to API Resources in OLM","text":"<p>When cluster extensions are managed via OLM, they often provide Custom Resource Definitions (CRDs) that expose new API resources. Typically, cluster administrators have full management access to these resources by default, whereas non-administrative users might lack sufficient permissions. Cluster administrators must create the needed permissions to create, view, or edit these Custom Resources for these users.</p> <p>OLM v1 does not automatically configure or manage role-based access control (RBAC) for users to interact with the APIs provided by installed packages. Cluster administrators must manage RBAC to grant appropriate permissions to non-administrative users. This guide outlines the steps to manually configure RBAC, with a focus on creating ClusterRoles and binding them to specific users or groups.</p>"},{"location":"howto/how-to-grant-api-access/#1-finding-api-groups-and-resources-provided-by-a-clusterextension","title":"1. Finding API Groups and Resources Provided by a ClusterExtension","text":"<p>To create appropriate RBAC policies, you need to know which API groups and resources are exposed by the installed cluster extension. You can inspect the installed CRDs and resources by running:</p> <pre><code>kubectl get crds\n</code></pre> <p>This will list all available CRDs, and you can inspect individual CRDs for their API groups:</p> <pre><code>kubectl get crd &lt;crd-name&gt; -o yaml\n</code></pre> <p>A user can use label selectors to find CRDs owned by a specific cluster extension:</p> <pre><code>kubectl get crds -l 'olm.operatorframework.io/owner-kind=ClusterExtension,olm.operatorframework.io/owner-name=&lt;clusterExtensionName&gt;'\n</code></pre>"},{"location":"howto/how-to-grant-api-access/#2-creating-default-clusterroles-for-apicrd-access","title":"2. Creating Default ClusterRoles for API/CRD Access","text":"<p>Administrators can define standard roles to control access to the API resources provided by installed cluster extensions. If the cluster extension does not provide default roles, you can create them yourself.</p>"},{"location":"howto/how-to-grant-api-access/#default-roles","title":"Default Roles","text":"<ul> <li>View ClusterRole: Grants read-only access to all custom resource objects of specified API resources across the cluster. This role is intended for users who need visibility into the resources without any permissions to modify them. It\u2019s ideal for monitoring purposes and limited access viewing.</li> <li>Edit ClusterRole: Allows users to modify all custom resource objects within the cluster. This role enables users to create, update, and delete resources, making it suitable for team members who need to manage resources but should not control RBAC or manage permissions for others.</li> <li>Admin ClusterRole: Provides full permissions (create, update, delete) over all custom resource objects for the specified API resources across the cluster.</li> </ul>"},{"location":"howto/how-to-grant-api-access/#example-defining-a-custom-view-clusterrole","title":"Example: Defining a Custom \"View\" ClusterRole","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: custom-resource-view\nrules:\n- apiGroups:\n  - &lt;your-api-group&gt;\n  resources:\n  - &lt;your-custom-resources&gt;\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre>"},{"location":"howto/how-to-grant-api-access/#example-defining-a-custom-edit-clusterrole","title":"Example: Defining a Custom \"Edit\" ClusterRole","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: custom-resource-edit\nrules:\n- apiGroups:\n  - &lt;your-api-group&gt;\n  resources:\n  - &lt;your-custom-resources&gt;\n  verbs:\n  - get\n  - list\n  - watch\n  - create\n  - update\n  - patch\n  - delete\n</code></pre>"},{"location":"howto/how-to-grant-api-access/#example-defining-a-custom-admin-clusterrole","title":"Example: Defining a Custom \"Admin\" ClusterRole","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: custom-resource-admin\nrules:\n- apiGroups:\n  - &lt;your-api-group&gt;\n  resources:\n  - &lt;your-custom-resources&gt;\n  verbs:\n  - '*'\n</code></pre> <p>Note</p> <p>The <code>'*'</code> in verbs allows all actions on the specified resources. In each case, replace <code>&lt;your-api-group&gt;</code> and <code>&lt;your-custom-resources&gt;</code> with the actual API group and resource names provided by the installed cluster extension.</p>"},{"location":"howto/how-to-grant-api-access/#3-granting-user-access-to-api-resources","title":"3. Granting User Access to API Resources","text":"<p>Once the roles are created, you can bind them to specific users or groups to grant them the necessary permissions. There are two main ways to do this:</p>"},{"location":"howto/how-to-grant-api-access/#option-1-binding-default-clusterroles-to-users","title":"Option 1: Binding Default ClusterRoles to Users","text":"<ul> <li>ClusterRoleBinding: Use this to grant access across all namespaces.</li> <li>RoleBinding: Use this to grant access within a specific namespace.</li> </ul>"},{"location":"howto/how-to-grant-api-access/#example-clusterrolebinding","title":"Example: ClusterRoleBinding","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: custom-resource-view-binding\nsubjects:\n- kind: User\n  name: &lt;username&gt; # Or use Group for group-based binding\nroleRef:\n  kind: ClusterRole\n  name: custom-resource-view\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>This binding grants <code>&lt;username&gt;</code> read-only access to the custom resource across all namespaces.</p>"},{"location":"howto/how-to-grant-api-access/#example-rolebinding","title":"Example: RoleBinding","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: custom-resource-edit-binding\n  namespace: &lt;namespace&gt;\nsubjects:\n- kind: User\n  name: &lt;username&gt;\nroleRef:\n  kind: Role\n  name: custom-resource-edit\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>This RoleBinding restricts permissions to a specific namespace.</p>"},{"location":"howto/how-to-grant-api-access/#option-2-extending-default-kubernetes-roles","title":"Option 2: Extending Default Kubernetes Roles","text":"<p>To automatically extend existing Kubernetes roles (e.g., the default <code>view</code>, <code>edit</code>, and <code>admin</code> roles), you can add aggregation labels to ClusterRoles. This allows users who already have <code>view</code>, <code>edit</code>, or <code>admin</code> roles to interact with the custom resource without needing additional RoleBindings.</p>"},{"location":"howto/how-to-grant-api-access/#example-adding-aggregation-labels-to-a-clusterrole","title":"Example: Adding Aggregation Labels to a ClusterRole","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: custom-resource-aggregated-view\n  labels:\n    rbac.authorization.k8s.io/aggregate-to-view: \"true\"\nrules:\n  - apiGroups:\n      - &lt;your-api-group&gt;\n    resources:\n      - &lt;your-custom-resource&gt;\n    verbs:\n      - get\n      - list\n      - watch\n</code></pre> <p>You can create similar ClusterRoles for <code>edit</code> and <code>admin</code> with appropriate verbs (such as <code>create</code>, <code>update</code>, <code>delete</code> for <code>edit</code> and <code>admin</code>). By using aggregation labels, the permissions for the custom resources are added to the default roles.</p> <p>Source: Kubernetes RBAC Aggregation</p>"},{"location":"howto/how-to-pin-version/","title":"Pin Version and Disable Automatic Updates","text":"<p>To disable automatic updates, and pin the version of an extension, set <code>version</code> in the Catalog source to a specific version (e.g. 1.2.3).</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n        packageName: argocd-operator\n        version: 0.6.0 # Pin argocd-operator to v0.6.0\n</code></pre> <p>For more information on SemVer version ranges see version ranges</p>"},{"location":"howto/how-to-version-range-upgrades/","title":"Version Range Automatic Updates","text":"<p>Set the version for the desired package in the Catalog source to a comparison string, like  <code>\"&gt;=3.0, &lt;3.6\"</code>, to restrict the automatic updates to the version range. Any new version of the extension released in the catalog within this range will be automatically applied.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: \"&gt;=3.0, &lt;3.6\"  # Install versions from v3.0.0 up to, but not including, v3.6.0\n</code></pre> <p>For more information on SemVer version ranges see version-ranges</p>"},{"location":"howto/how-to-z-stream-upgrades/","title":"Z-Stream Automatic Updates","text":"<p>To restrict automatic updates to only z-stream patches and avoid breaking changes, use the <code>\"~\"</code> version range operator when setting the version for the desired package in Catalog source.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: \"~2.3\" # Automatically upgrade patch releases for v2.3\n</code></pre> <p>For more information on SemVer version ranges see version ranges</p>"},{"location":"project/olmv1_architecture/","title":"Architecture","text":""},{"location":"project/olmv1_architecture/#olm-v1-architecture","title":"OLM v1 Architecture","text":"<p>This document provides an overview of the architecture of OLM v1, which consists of two primary components:</p> <ol> <li>operator-controller</li> <li>catalogD</li> </ol> <p>The diagram below visually represents the architecture of OLM v1, followed by descriptions of each component and its role within the system.</p>"},{"location":"project/olmv1_architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>flowchart TB\n    A(bundle)\n    B(registry repo)\n    C(catalog author)\n    D(bundle author)\n    E(file based catalog)\n    F(extension controller)\n    G(bundle cache)\n    H(catalog cache)\n    I(resolver)\n    J(catalog controller)\n    K(catalog content cache)\n    L(catalog http server)\n\n    subgraph Image-registry\n    B\n    end\n    subgraph Cluster\n    subgraph Operator-controller\n    F--&gt;G\n    F--&gt;I\n    I--&gt;H\n    end\n    subgraph Catalogd\n    J--&gt;K\n    L&lt;--&gt;K\n    end\n    end\n\n    F--&gt;L\n    F--&gt;B\n    J--&gt;B\n    C -- creates --&gt; E\n    E -- pushed to --&gt; B\n    D -- creates --&gt; A\n    A -- pushed to --&gt; B</code></pre> <p>Note</p> <p>The direction of the arrows represents the flow of communication. If an arrow starts from A and points to B, it indicates that A retrieves or consumes information from B, unless otherwise specified.</p>"},{"location":"project/olmv1_architecture/#operator-controller","title":"operator-controller","text":"<p>The <code>operator-controller</code> is the core component of OLM v1. Its responsibilities include:</p> <ul> <li>Managing a cache of catalog metadata provided by catalogD through its HTTP server.</li> <li>Ensuring the catalog metadata cache is kept up-to-date with the latest catalog state.</li> <li>Identifying the appropriate <code>registry+v1</code> bundle that meets the constraints defined in the <code>ClusterExtension</code> resource (e.g., package name, version, channel) based on the cluster's current state.</li> <li>Unpacking and applying bundle manifests (e.g., installing or updating the operator).</li> </ul> <p>The operator-controller has three key sub-components:</p> <ol> <li> <p>Cluster Extension Controller:</p> <ul> <li>Queries catalogD (via its HTTP server) to retrieve catalog information.</li> <li>Saves catalog information in the catalog cache and automatically updates the cache if a catalog has a new image reference.</li> <li>Downloads bundle container images from the registry, saves them to the bundle cache, unpacks them, and applies the bundle manifests to the cluster.</li> <li>Handles bundle upgrades by determining which bundle is the correct one to apply.</li> </ul> </li> <li> <p>Resolver:</p> <ul> <li>Assists the Cluster Extension Controller by filtering bundle references according to user-defined restrictions (e.g., package name, priority). It returns the filtered bundle reference to the extension controller.</li> </ul> </li> <li> <p>Bundle Cache:</p> <ul> <li>Stores previously unpacked bundles. If a bundle is not already cached, it downloads and caches it for future use.</li> </ul> </li> </ol>"},{"location":"project/olmv1_architecture/#catalogd","title":"catalogd","text":"<p>catalogd is responsible for unpacking file-based catalog (FBC) content, which is packaged and delivered as container images. It allows on-cluster clients to discover installable content by providing access to this metadata. In the future, catalogD will also support other sources like Git repositories and OCI artifacts.</p> <p>catalogd has three main sub-components:</p> <ol> <li> <p>ClusterCatalog Controller:</p> <ul> <li>Pulls FBC-based catalog images from the registry and unpacks them into the catalog content cache.</li> <li>Reconciles any changes in the catalog and ensures the latest content is reflected in the cluster.</li> </ul> </li> <li> <p>CatalogD HTTP Server:</p> <ul> <li>Serves catalog information to clients, such as the Cluster Extension Controller.</li> </ul> </li> <li> <p>CatalogD Content Cache:</p> <ul> <li>A cache maintained by the Catalog Controller that stores unpacked catalog data, which the CatalogD HTTP Server uses to respond to client queries.</li> </ul> </li> </ol>"},{"location":"project/olmv1_community/","title":"Community","text":"<p>OLM is an open-source CNCF project with a friendly and supportive community of developers, testers,  and documentation experts with a passion for Kubernetes.</p> <p>Through the effort of redesigning OLM, the community also took the opportunity to make the project more accessible,  and contributor-friendly through its weekly meetings, continuous planning, and a GitHub project  tracker that provides a convenient entry point to quickly find something interesting to work on and contribute.</p> <p>You can reach out to the OLM community for feedbacks/discussions/contributions in the following channels:</p> <ul> <li>Kubernetes Slack channel: #olm-dev</li> <li>Operator Framework on Google Groups</li> <li>Weekly in-person Working Group meeting: olm-wg</li> </ul> <p>For further information on contributing, please consult the Contribution Guide</p>"},{"location":"project/olmv1_design_decisions/","title":"Multi-Tenancy Challenges, Lessons Learned, and Design Shifts","text":"<p>This provides historical context on the design explorations and challenges that led to substantial design shifts between OLM v1 and its predecessor. It explains the technical reasons why OLM v1 cannot support major v0 features, such as, multi-tenancy, and namespace-specific controller configurations. Finally, it highlights OLM v1\u2019s shift toward more secure, predictable, and simple operations while moving away from some of the complex, error-prone features of OLM v0.</p>"},{"location":"project/olmv1_design_decisions/#what-wont-olm-v1-do-that-olm-v0-did","title":"What won't OLM v1 do that OLM v0 did?","text":"<p>TL;DR: OLM v1 cannot feasibly support multi-tenancy or any feature that assumes multi-tenancy. All multi-tenancy features end up falling over because of the global API system of Kubernetes. While this short conclusion may be unsatisfying, the reasons are complex and intertwined.</p>"},{"location":"project/olmv1_design_decisions/#historical-context","title":"Historical Context","text":"<p>Nearly every active contributor in the Operator Framework project contributed to design explorations and prototypes over an entire year. For each of these design explorations, there are complex webs of features and assumptions that are necessary to understand the context that ultimately led to a conclusion of infeasibility.</p> <p>Here is a sampling of some of the ideas we explored:</p> <ul> <li>OLM v1's approach to multi-tenancy</li> <li>OLM v1 Multi-tenancy Brainstorming</li> </ul>"},{"location":"project/olmv1_design_decisions/#watched-namespaces-cannot-be-configured-in-a-first-class-api","title":"Watched namespaces cannot be configured in a first-class API","text":"<p>OLM v1 will not have a first-class API for configuring the namespaces that a controller will watch.</p> <p>Kubernetes APIs are global. Kubernetes is designed with the assumption that a controller WILL reconcile an object no matter where it is in the cluster.</p> <p>However, Kubernetes does not assume that a controller will be successful when it reconciles an object.</p> <p>The Kubernetes design assumptions are:</p> <ul> <li>CRDs and their controllers are trusted cluster extensions.</li> <li>If an object for an API exists a controller WILL reconcile it, no matter where it is in the cluster.</li> </ul> <p>OLM v1 will make the same assumption that Kubernetes does and that users of Kubernetes APIs do. That is: If a user has RBAC to create an object in the cluster, they can expect that exactly one controller exists that will reconcile that object. If this assumption does not hold, it will be considered a configuration issue, not an OLM v1 bug.</p> <p>This means that it is a best practice to implement and configure controllers to have cluster-wide permission to read and update the status of their primary APIs. It does not mean that a controller needs cluster-wide access to read/write secondary APIs. If a controller can update the status of its primary APIs, it can tell users when it lacks permission to act on secondary APIs.</p>"},{"location":"project/olmv1_design_decisions/#dependencies-based-on-watched-namespaces","title":"Dependencies based on watched namespaces","text":"<p>Since there will be no first-class support for configuration of watched namespaces, OLM v1 cannot resolve dependencies among bundles based on where controllers are watching.</p> <p>However, not all bundle constraints are based on dependencies among bundles from different packages. OLM v1 will be able to support constraints against cluster state. For example, OLM v1 could support a \u201ckubernetesVersionRange\u201d constraint that blocks installation of a bundle if the current kubernetes cluster version does not fall into the specified range.</p>"},{"location":"project/olmv1_design_decisions/#background","title":"Background","text":"<p>For packages that specify API-based dependencies, OLMv0\u2019s dependency checker knows which controllers are watching which namespaces. While OLM v1 will have awareness of which APIs are present on a cluster (via the discovery API), it will not know which namespaces are being watched for reconciliation of those APIs. Therefore dependency resolution based solely on API availability would only work in cases where controllers are configured to watch all namespaces.</p> <p>For packages that specify package-based dependencies, OLMv0\u2019s dependency checker again knows which controllers are watching which namespaces. This case is challenging for a variety of reasons:</p> <ol> <li>How would a dependency resolver know which extensions were installed (let alone which extensions were watching which namespaces)? If a user is running the resolver, they would be blind to an installed extension that is watching their namespace if they don\u2019t have permission to list extensions in the installation namespace. If a controller is running the resolver, then it might leak information to a user about installed extensions that the user is not otherwise entitled to know.</li> <li>Even if (1) could be overcome, the lack of awareness of watched namespaces means that the resolver would have to make assumptions. If only one controller is installed, is it watching the right set of namespaces to meet the constraint? If multiple controllers are installed, are any of them watching the right set of namespaces? Without knowing the watched namespaces of the parent and child controllers, a correct dependency resolver implementation is not possible to implement.</li> </ol> <p>Note that regardless of the ability of OLM v1 to perform dependency resolution (now or in the future), OLM v1 will not automatically install a missing dependency when a user requests an operator. The primary reasoning is that OLM v1 will err on the side of predictability and cluster-administrator awareness.</p>"},{"location":"project/olmv1_design_decisions/#watch-namespace-aware-operator-discoverability","title":"\"Watch namespace\"-aware operator discoverability","text":"<p>When operators add APIs to a cluster, these APIs are globally visible. As stated before, there is an assumption in this design that a controller will reconcile an object of that API anywhere it exists in the cluster.</p> <p>Therefore, the API discoverability story boils down to answering this question for the user: \u201cWhat APIs do I have access to in a given namespace?\u201d Fortunately, built-in APIs exist to answer this question: Kubernetes Discovery, SelfSubjectRulesReview (SSRR), and SelfSubjectAccessReview (SSAR).</p> <p>However, helping users discover which actual controllers will reconcile those APIs is not possible unless OLM v1 knows which namespaces those controllers are watching.</p> <p>Any solution here would be unaware of where a controller is actually watching and could only know \u201cis there a controller installed that provides an implementation of this API?\u201d. However even knowledge of a controller installation is not certain. Any user can use the discovery, SSRR, and SSAR. Not all users can list all Extensions (see User discovery of \u201cavailable\u201d APIs).</p>"},{"location":"project/olmv1_design_decisions/#what-does-this-mean-for-multi-tenancy","title":"What does this mean for multi-tenancy?","text":"<p>The multi-tenancy promises that OLMv0 made were false promises. Kubernetes is not multi-tenant with respect to management of APIs (because APIs are global). Any promise that OLMv0 has around multi-tenancy evaporates when true tenant isolation attempts are made, and any attempt to fix a broken promise is actually just a bandaid on an already broken assumption.</p> <p>So where do we go from here? There are multiple solutions that do not involve OLM implementing full multi-tenancy support, some or all of which can be explored.</p> <ol> <li>Customers transition to a control plane per tenant</li> <li>Extension authors update their operators to support customers\u2019 multi-tenancy use cases</li> <li>Extension authors with \u201csimple\u201d lifecycling concerns transition to other packaging and deployment strategies (e.g. helm charts)</li> </ol>"},{"location":"project/olmv1_design_decisions/#single-tenant-control-planes","title":"Single-tenant control planes","text":"<p>One choice for customers would be to adopt low-overhead single-tenant control planes in which every tenant can have full control over their APIs and controllers and be truly isolated (at the control plane layer at least) from other tenants. With this option, the things OLM v1 cannot do (listed above) are irrelevant, because the purpose of all of those features is to support multi-tenant control planes in OLM.</p> <p>The Kubernetes multi-tenancy docs contain a good overview of the options in this space. Kubernetes vendors may also have their own virtual control plane implementations.</p>"},{"location":"project/olmv1_design_decisions/#shift-multi-tenant-responsibility-to-operators","title":"Shift multi-tenant responsibility to operators","text":"<p>There is a set of operators that both (a) provide fully namespace-scoped workload-style operands and that (b) provide a large amount of value to their users for advanced features like backup and migration. For these operators, the Operator Framework program would suggest that they shift toward supporting multi-tenancy directly. That would involve:</p> <ol> <li>Taking extreme care to avoid API breaking changes.</li> <li>Supporting multiple versions of their operands in a single version of the operator (if required by users in multi-tenant clusters).</li> <li>Maintaining support for versioned operands for the same period of time that the operator is supported for a given cluster version.</li> <li>Completely avoiding global configuration. Each tenant should be able to provide their configuration separately.</li> </ol>"},{"location":"project/olmv1_design_decisions/#operator-authors-ship-controllers-outside-of-olm","title":"Operator authors ship controllers outside of OLM","text":"<p>Some projects have been successful delivering and supporting their operator on Kubernetes, but outside of OLM, for example with helm-packaged operators. On this path, individual layered project teams have more flexibility in solving lifecycling problems for their users because they are unencumbered by OLM\u2019s opinions. However the tradeoff is that those project teams and their users take on responsibility and accountability for safe upgrades, automation, and multi-tenant architectures. With OLM v1 no longer attempting to support multi-tenancy in a first-class way, these tradeoffs change and project teams may decide that a different approach is necessary.</p> <p>This path does not necessarily mean a scattering of content in various places. It would still be possible to provide customers with a marketplace of content (e.g. see artifacthub.io).</p>"},{"location":"project/olmv1_design_decisions/#authors-of-simple-operators-ship-their-workload-without-an-operator","title":"Authors of \"simple\" operators ship their workload without an operator","text":"<p>Another direction is to just stop shipping content via an operator. The operator pattern is particularly well-suited for applications that require complex upgrade logic, that need to convert declarative intent to imperative action, or that require sophisticated health monitoring logic and feedback. But a sizable portion of the OperatorHub catalog contain operators that are not actually taking advantage of the benefits of the operator pattern and are instead a simple wrapper around the workload, which is where the real value is.</p> <p>Using the Operator Capability Levels as a rubric, operators that fall into Level 1 and some that fall into Level 2 are not making full use of the operator pattern. If content authors had the choice to ship their content without also shipping an operator that performs simple installation and upgrades, many supporting these Level 1 and Level 2 operators might make that choice to decrease their overall maintenance and support burden while losing very little in terms of value to their customers.</p>"},{"location":"project/olmv1_design_decisions/#what-will-olm-do-that-a-generic-package-manager-doesnt","title":"What will OLM do that a generic package manager doesn't?","text":"<p>OLM will provide multiple features that are absent in generic package managers. Some items listed below are already implemented, while others may be planned for the future.</p>"},{"location":"project/olmv1_design_decisions/#upgrade-controls","title":"Upgrade controls","text":"<p>An operator author can control the upgrade flow by specifying supported upgrade paths from one version to another. Or, they could use semantic versioning (semver) - this is fully supported by OLM too.</p> <p>A user can see the author\u2019s supplied upgrade information.</p> <p>While these features might seem standard in package managers, they are fairly unique in the Kubernetes ecosystem. Helm, for example, doesn\u2019t have any features that help users stay on supported upgrade paths.</p>"},{"location":"project/olmv1_design_decisions/#on-cluster-component-for-automated-upgrades-health-monitoring","title":"On-cluster component for automated upgrades, health monitoring","text":"<p>OLM automatically upgrades an operator to the latest acceptable matching version whenever a new matching version appears in a catalog, assuming the user has enabled this for their operator.</p> <p>OLM constantly monitors the state of all on-cluster resources for all the operators it manages, reporting the health in aggregate on each operator.</p>"},{"location":"project/olmv1_design_decisions/#crd-upgrade-safety-checks","title":"CRD Upgrade Safety Checks","text":"<p>Before OLM upgrades a CRD, OLM performs a set of safety checks to identify any changes that potentially would have negative impacts, such as:</p> <ul> <li>data loss</li> <li>incompatible schema changes</li> </ul> <p>These checks may not be a guarantee that an upgrade is safe; instead, they are intended to provide an early warning sign for identifiable incompatibilities. False positives (OLM v1 claims a breaking change when there is none) and false negatives (a breaking change makes it through the check without being caught) are possible, at least while the OLM v1 team iterates on this feature.</p>"},{"location":"project/olmv1_design_decisions/#user-permissions-management","title":"User permissions management","text":"<p>Operators typically provide at least one new API, and often multiple. While operator authors know the APIs they\u2019re providing, users installing operators won\u2019t necessarily have this same knowledge. OLM will make it easy to grant permissions to operator-provided APIs to users/groups in various namespaces, but any automation (which would be client-side only) or UX provided by OLM related to user permissions management will be unable to automatically account for watch namespace configurations. See Watched namespaces cannot be configured in a first class API</p> <p>Also note that user permission management does not unlock operator discoverability (only API discoverability). See \u201cWatch namespace\u201d-aware operator discoverability for more details.</p>"},{"location":"project/olmv1_design_decisions/#user-discovery-of-available-apis","title":"User discovery of \u201cavailable\u201d APIs","text":"<p>In the future, the Operator Framework team could explore building an API similar to SelfSubjectAccessReview and SelfSubjectRulesReview that answers the question: \u201cWhat is the public metadata of all extensions that are installed on the cluster that provide APIs that I have permission for in namespace X?\u201d</p> <p>One solution would be to join \u201cinstalled extensions with user permissions\u201d. If an installed extension provides an API that a user has RBAC permission for, that extension would be considered available to that user in that scope. This solution would not be foolproof: it makes the (reasonable) assumption that an administrator only configures RBAC for a user in a namespace where a controller is reconciling that object. If an administrator gives a user RBAC access to an API without also configuring that controller to watch the namespace that they have access to, the discovery solution would report an available extension, but then nothing would actually reconcile the object they create.</p> <p>This solution would tell users about API-only and API+controller bundles that are installed. It would not tell users about controller-only bundles, because they do not include APIs.</p> <p>Other similar API-centric solutions could be explored as well. For example, pursuing enhancements to OLM v1 or core Kubernetes related to API metadata and/or grouping.</p> <p>A key insight here is that controller-specific metadata like the version of the controller that will reconcile the object in a certain namespace is not necessary for discovery. Discovery is primarily about driving user flows around presenting information and example usage of a group of APIs such that CLIs and UIs can provide rich experiences around interactions with available APIs.</p>"},{"location":"project/olmv1_design_decisions/#approach","title":"Approach","text":"<p>We will adhere to the following tenets in our approach for the design and implementation of OLM v1</p>"},{"location":"project/olmv1_design_decisions/#do-not-fight-kubernetes","title":"Do not fight Kubernetes","text":"<p>One of the key features of cloud-native applications/extensions/operators is that they typically come with a Kubernetes-based API (e.g. CRD) and a controller that reconciles instances of that API. In Kubernetes, API registration is cluster-scoped. It is not possible to register different APIs in different namespaces. Instances of an API can be cluster- or namespace-scoped. All APIs are global (they can be invoked/accessed regardless of namespace). For cluster-scoped APIs, the names of their instances must be unique. For example, it\u2019s possible to have Nodes named \u201cone\u201d and \u201ctwo\u201d, but it\u2019s not possible to have multiple Nodes named \u201ctwo\u201d. For namespace-scoped APIs, the names of their instances must be unique per namespace. The following illustrates this for ConfigMaps, a namespace-scoped API:</p> <p>Allowed</p> <ul> <li>Namespace: test, name: my-configmap</li> <li>Namespace: other, name: my-configmap</li> </ul> <p>Disallowed</p> <ul> <li>Namespace: test, name: my-configmap</li> <li>Namespace: test, name: my-configmap</li> </ul> <p>In cases where OLMv0 decides that joint ownership of CRDs will not impact different tenants, OLMv0 allows multiple installations of bundles that include the same named CRD, and OLMv0 itself manages the CRD lifecycle. This has security implications because it requires OLMv0 to act as a deputy, but it also pits OLM against the limitations of the Kubernetes API. OLMv0 promises that different versions of an operator can be installed in the cluster for use by different tenants without tenants being affected by each other. This is not a promise OLM can make because it is not possible to have multiple versions of the same CRD present on a cluster for different tenants.</p> <p>In OLM v1, we will not design the core APIs and controllers around this promise. Instead, we will build an API where ownership of installed objects is not shared. Managed objects are owned by exactly one extension.</p> <p>This pattern is generic, aligns with the Kubernetes API, and makes multi-tenancy a possibility, but not a guarantee or core concept. We will explore the implications of this design on existing OLMv0 registry+v1 bundles as part of the larger v0 to v1 migration design. For net new content, operator authors that intend multiple installations of operator on the same cluster would need to package their components to account for this ownership rule. Generally, this would entail separation along these lines:</p> <ul> <li>CRDs, conversion webhook workloads, and admission webhook configurations and workloads, APIServices and workloads.</li> <li>Controller workloads, service accounts, RBAC, etc.</li> </ul> <p>OLM v1 will include primitives (e.g. templating) to make it possible to have multiple non-conflicting installations of bundles.</p> <p>However, it should be noted that the purpose of these primitives is not to enable multi-tenancy. It is to enable administrators to provide configuration for the installation of an extension. The fact that operators can be packaged as separate bundles and parameterized in a way that permits multiple controller installations is incidental, and not something that OLM v1 will encourage or promote.</p>"},{"location":"project/olmv1_design_decisions/#make-olm-secure-by-default","title":"Make OLM secure by default","text":"<p>OLMv0 runs as cluster-admin, which is a security concern. OLMv0 has optional security controls for operator installations via the OperatorGroup, which allows a user with permission to create or update them to also set a ServiceAccount that will be used for authorization purposes on operator installations and upgrades in that namespace. If a ServiceAccount is not explicitly specified, OLM\u2019s cluster-admin credentials are used. Another avenue that cluster administrators have is to lock down permissions and usage of the CatalogSource API, disable default catalogs, and provide tenants with custom vetted catalogs. However if a cluster admin is not aware of these options, the default configuration of a cluster results in users with permission to create a Subscription in namespaces that contain an OperatorGroup effectively have cluster-admin, because OLMv0 has unlimited permissions to install any bundle available in the default catalogs and the default community catalog is not vetted for limited RBAC. Because OLMv0 is used to install more RBAC and run arbitrary workloads, there are numerous potential vectors that attackers could exploit. While there are no known exploits and there has not been any specific concern reported from customers, we believe CNCF\u2019s reputation rest on secure cloud-native software and that this is a non-negotiable area to improve.</p> <p>To make OLM secure by default:</p> <ul> <li>OLM v1 will not be granted cluster admin permissions. Instead, it will require service accounts provided by users to actually install, upgrade, and delete content. In addition to the security this provides, it also fulfills one of OLM\u2019s long-standing requirements: halt when bundle upgrades require additional permissions and wait until those permissions are granted.</li> <li>OLM v1 will use secure communication protocols between all internal components and between itself and its clients.</li> </ul>"},{"location":"project/olmv1_design_decisions/#simple-and-predictable-semantics-for-install-upgrade-and-delete","title":"Simple and predictable semantics for install, upgrade, and delete","text":"<p>OLMv0 has grown into a complex web of functionality that is difficult to understand, even for seasoned Kubernetes veterans.</p> <p>In OLM v1 we will move to GitOps-friendly APIs that allow administrators to rely on their experience with conventional Kubernetes API behavior (declarative, eventually consistent) to manage operator lifecycles.</p> <p>OLM v1 will reduce its API surface down to two primary APIs that represent catalogs of content, and intent for that content to be installed on the cluster.</p> <p>OLM v1 will:</p> <ul> <li>Permit administrators to pin to specific versions, channels, version ranges, or combinations of both.</li> <li>Permit administrators to pause management of an installation for maintenance or troubleshooting purposes.</li> <li>Put opinionated guardrails up by default (e.g. follow operator developer-defined upgrade edges).</li> <li>Give administrators escape hatches to disable any or all of OLMs guardrails.</li> <li>Delete managed content when a user deletes the OLM object that represents it.</li> </ul>"},{"location":"project/olmv1_design_decisions/#apis-and-behaviors-to-handle-common-controller-patterns","title":"APIs and behaviors to handle common controller patterns","text":"<p>OLMv0 takes an extremely opinionated stance on the contents of the bundles it installs and in the way that operators can be lifecycled. The original designers believed these opinions would keep OLM\u2019s scope limited and that they encompassed best practices for operator lifecycling. Some of these opinions are:</p> <ul> <li>All bundles must include a ClusterServiceVersion, which ostensibly gives operator authors an API that they can use to fully describe how to run the operator, what permissions it requires, what APIs it provides, and what metadata to show to users.</li> <li>Bundles cannot contain arbitrary objects. OLMv0 needs to have specific handling for each resource that it supports.</li> <li>Cluster administrators cannot override OLM safety checks around CRD changes or upgrades.</li> </ul> <p>OLM v1 will take a slightly different approach:</p> <ul> <li>It will not require bundles to have very specific controller-centric shapes. OLM v1 will happily install a bundle that contains a deployment, service, and ingress or a bundle that contains a single configmap.</li> <li>However for bundles that do include CRDs, controllers, RBAC, webhooks, and other objects that relate to the behavior of the apiserver, OLM will continue to have opinions and special handling:<ul> <li>CRD upgrade checks (best effort)</li> <li>Specific knowledge and handling of webhooks.</li> </ul> </li> <li>To the extent necessary OLM v1 will include optional controller-centric concepts in its APIs and or CLIs in order to facilitate the most common controller patterns. Examples could include:<ul> <li>Permission management</li> <li>CRD upgrade check policies</li> </ul> </li> <li>OLM v1 will continue to have opinions about upgrade traversals and CRD changes that help users prevent accidental breakage, but it will also allow administrators to disable safeguards and proceed anyway.</li> </ul> <p>OLMv0 has some support for automatic upgrades. However, administrators cannot control the maximum version for automatic upgrades, and the upgrade policy (manual vs automatic) applies to all operators in a namespace. If any operator\u2019s upgrade policy is manual, all upgrades of all operators in the namespace must be approved manually.</p> <p>OLM v1 will have fine-grained control for version ranges (and pins) and for controlling automatic upgrades for individual operators regardless of the policy of other operators installed in the same namespace.</p>"},{"location":"project/olmv1_design_decisions/#constraint-checking-but-not-automated-on-cluster-management","title":"Constraint checking (but not automated on-cluster management)","text":"<p>OLMv0 includes support for dependency and constraint checking for many common use cases (e.g. required and provided APIs, required cluster version, required package versions). It also has other constraint APIs that have not gained traction (e.g. CEL expressions and compound constraints). In addition to its somewhat hap-hazard constraint expression support, OLMv0 also automatically installs dependency trees, which has proven problematic in several respects:</p> <ol> <li>OLMv0 can resolve existing dependencies from outside the current namespace, but it can only install new dependencies in the current namespace. One scenario where this is problematic is if A depends on B, where A supports only OwnNamespace mode and B supports only AllNamespace mode. In that case, OLMv0\u2019s auto dependency management fails because B cannot be installed in the same namespace as A (assuming the OperatorGroup in that namespace is configured for OwnNamespace operators to work).</li> <li>OLMv0\u2019s logic for choosing a dependency among multiple contenders is confusing and error-prone, and an administrator\u2019s ability to have fine-grained control of upgrades is essentially limited to building and deploying tailor-made catalogs.</li> <li>OLMv0 automatically installs dependencies. The only way for an administrator to avoid this OLMv0 functionality is to fully understand the dependency tree in advance and to then install dependencies from the leaves to the root so that OLMv0 always detects that dependencies are already met. If OLMv0 installs a dependency for you, it does not uninstall it when it is no longer depended upon.</li> </ol> <p>OLM v1 will not provide dependency resolution among packages in the catalog (see Dependencies based on watched namespaces)</p> <p>OLM v1 will provide constraint checking based on available cluster state. Constraint checking will be limited to checking whether the existing constraints are met. If so, install proceeds. If not, unmet constraints will be reported and the install/upgrade waits until constraints are met.</p> <p>The Operator Framework team will perform a survey of registry+v1 packages that currently rely on OLMv0\u2019s dependency features and will suggest a solution as part of the overall OLMv0 to OLM v1 migration effort.</p>"},{"location":"project/olmv1_design_decisions/#client-libraries-and-clis-contribute-to-the-overall-ux","title":"Client libraries and CLIs contribute to the overall UX","text":"<p>OLMv0 has no official client libraries or CLIs that can be used to augment its functionality or provide a more streamlined user experience. The kubectl \"operator\" plugin was developed several years ago, but has never been a focus of the core Operator Framework development team, and has never factored into the overall architecture.</p> <p>OLM v1 will deliver an official CLI (likely by overhauling the kubectl operator plugin) and will use it to meet requirements that are difficult or impossible to implement in a controller, or where an architectural assessment dictates that a client is the better choice. This CLI would automate standard workflows over cluster APIs to facilitate simple administrative actions (e.g. automatically create RBAC and ServiceAccounts necessary for an extension installation as an optional step in the CLI\u2019s extension install experience).</p> <p>The official CLI will provide administrators and users with a UX that covers the most common scenarios users will encounter.</p> <p>The official CLI will explicitly NOT attempt to cover complex scenarios. Maintainers will reject requests to over-complicate the CLI. Users with advanced use cases will be able to directly interact with OLM v1\u2019s on-cluster APIs.</p> <p>The idea is:</p> <ul> <li>On-cluster APIs can be used to manage operators in 100% of cases (assuming bundle content is structured in a compatible way)</li> <li>The official CLI will cover standard user flows, covering ~80% of use cases.</li> <li>Third-party or unofficial CLIs will cover the remaining ~20% of use cases.</li> </ul> <p>Areas where the official CLI could provide value include:</p> <ul> <li>Catalog interactions (search, list, inspect, etc.)</li> <li>Standard install/upgrade/delete commands</li> <li>Upgrade previews</li> <li>RBAC management</li> <li>Discovery of available APIs</li> </ul>"},{"location":"project/olmv1_limitations/","title":"Limitations","text":""},{"location":"project/olmv1_limitations/#content-support","title":"Content Support","text":"<p>Currently, OLM v1 only supports installing operators packaged in OLM v0 bundles , also known as <code>registry+v1</code> bundles. Additionally, the bundled operator, or cluster extension:</p> <ul> <li>must support installation via the <code>AllNamespaces</code> install mode.<ul> <li>Note that <code>AllNamespaces</code> is the recommended install mode. OLM v1 supports <code>SingleNamespace</code> and <code>OwnNamespace</code> modes for <code>registry+v1</code> bundles for backwards compatibility with OLM v0, but these are not recommended install modes as there is a hard limitation of only one instance of a given CRD in the cluster.</li> </ul> </li> <li>must not declare dependencies using any of the following file-based catalog properties:<ul> <li><code>olm.gvk.required</code></li> <li><code>olm.package.required</code></li> <li><code>olm.constraint</code></li> </ul> </li> </ul> <p>OLM v1 verifies these criteria at install time and will surface violations in the <code>ClusterExtensions</code>'s <code>.status.conditions</code>.</p> <p>Important</p> <p>OLM v1 does not support the <code>OperatorConditions</code> API introduced in legacy OLM.</p> <p>Currently, there is no testing to validate against this constraint. If an extension uses the <code>OperatorConditions</code> API, the extension does not install correctly. Most extensions that rely on this API fail at start time, but some might fail during reconcilation.</p>"},{"location":"project/olmv1_roadmap/","title":"OLM v1 roadmap (Deprecated)","text":"<p>Note: The current roadmap is deprecated and it is not up-to-date. Refer to project dashboard to get latest information.</p>"},{"location":"project/olmv1_roadmap/#functional-requirements","title":"Functional Requirements","text":"<p>Priority Rating: 1 highest, 2 medium, 3 lower (e.g. P2 = Medium Priority)</p>"},{"location":"project/olmv1_roadmap/#f1-extension-catalogs-p1","title":"F1 - Extension catalogs (P1)","text":"<p>The existing OLM concepts around catalogs, packages and channels is to be used as a basis for below functional requirements.</p>"},{"location":"project/olmv1_roadmap/#f2-extension-catalog-discovery-p2","title":"F2 - Extension catalog discovery (P2)","text":"<p>Unprivileged tenants need to have the ability to discover extensions that are available to install. In particular users need to be able to discover all versions in all channels that an extension package defines in a catalog. The privilege should be given at the discretion of the cluster administrator.</p>"},{"location":"project/olmv1_roadmap/#f3-dependency-preview-p3","title":"F3 - Dependency preview (P3)","text":"<p>Before extension installation, OLM needs to introspect the dependencies of an extension and present a preview of the resolution result to the user to let the user confirm they are ok with this.</p>"},{"location":"project/olmv1_roadmap/#f4-dependency-review-p3","title":"F4 - Dependency review (P3)","text":"<p>For installed extensions OLM needs to surface the dependency relationship to other installed extensions and also highlight which other extensions depend on a particular extension so users are informed about the relationships at runtime.</p>"},{"location":"project/olmv1_roadmap/#f5-permission-preview-p2","title":"F5 - Permission preview (P2)","text":"<p>Before extension installation and updates, OLM needs to allow introspection of the permissions the extension requires on cluster and dependencies APIs. This is especially important during updates when the permission scope increases in which case updates should be blocked until approved (F14).</p>"},{"location":"project/olmv1_roadmap/#f6-installupdate-preflight-checks-p1","title":"F6 - Install/Update preflight checks (P1)","text":"<p>When installing and updating extensions OLM should carry out a set of preflight checks to prevent installations from going into a failed state as a result of attempting an upgrade or install. Preflight checks should include availability and (if applicable) health of (running) dependencies and any cluster runtime constraints (F19).</p>"},{"location":"project/olmv1_roadmap/#f7-extension-installation-p1","title":"F7 - Extension installation (P1)","text":"<p>OLM needs a declarative way to install extensions either from a catalog of extensions or directly from an OCI image. Should the installation attempt fail due to unfilled requirements, constraints, preflight checks or dependencies there needs to be an option to force the install. Extensions are cluster-wide singletons, thus they can only be installed once in the cluster and are managed at cluster-scope.</p>"},{"location":"project/olmv1_roadmap/#f8-semver-based-update-policy-p2","title":"F8 - Semver-based update policy (P2)","text":"<p>OLM should allow users to specify if and when extensions are updated. Manual update policy should include the user explicitly approving an update to be installed. An automatic update policy should allow updates to automatically be applied as soon as they are available and should provide further conditions upon which an update is to be applied. Conditions concern version changes of the extension, specifically: automatic updates on z-streams only, automatic updates on y-streams only, always automatic update. Updates across channels are outside of the update policy.</p>"},{"location":"project/olmv1_roadmap/#f9-update-notification-p3","title":"F9 - Update notification (P3)","text":"<p>As updates can be made available at any time using OLMs existing over-the-air catalog update capabilities, OLM should provide events / notifications on the platform to notify users about available but not yet approved updates of existing installed extensions, specifically so that graphical consoles can pick them up and visualize them. Automatically applied updates as per F8 should also create notifications.</p>"},{"location":"project/olmv1_roadmap/#f10-extension-updates-p2","title":"F10 - Extension updates (P2)","text":"<p>As extensions get updated, either automatically or manually, OLM replaces the older version of the extensions with a newer version atomically. Up until any custom code or conversion logic runs, an update should be able to be rolled back (F23). When multiple extensions are updated to satisfy an update request, the update policy of each extension needs to be respected to allow users to pin certain extensions to installed versions or certain types of updates (e.g. z-stream only). It should also be possible to force an update to a certain version, even if there is no direct path as per the graph metadata. Otherwise all versions along the update path should be allowed for selecting by the user as the desired target version.Otherwise all versions on</p>"},{"location":"project/olmv1_roadmap/#f11-request-approval-flow-for-installs-updates-p2","title":"F11 - Request / Approval Flow for Installs / Updates (P2)","text":"<p>To support multi-tenant environments a request / approval flow is desirable for generally available content within default catalogs. In this model any tenant with enough privilege can discover installable content and can trigger an install request, which can in turn be approved or denied by a more privileged administrative role. Such requests should also have timeouts. Administrators should have the ability to define a list of extensions that are automatically approved at the scope of a namespace. Administrators should be able to get aware of unapproved requested via alerts triggered by the platform.</p>"},{"location":"project/olmv1_roadmap/#f12-installed-extension-discovery-p1","title":"F12 - Installed extension discovery (P1)","text":"<p>Unprivileged tenants need to be able to discover installed extensions if they are offering services for them to use in their namespace. OLM needs to provide distinct controls for installed extensions which administrators can use to regulate in which namespaces extensions are discoverable by tenants, irrespective of the namespaces in which the extension has permissions on cluster APIs (see F13)</p>"},{"location":"project/olmv1_roadmap/#f13-extension-permissions-management-p1","title":"F13 - Extension permissions management (P1)","text":"<p>Administrative personas need to be able to configure in which namespaces in the cluster the extension can get the requested permissions the extension author deems required. The control needs to be independent of the controls in F12. Extensions should always be given permissions to update their own APIs (if they define any) to inform users about potential lack of permissions in their namespace.</p>"},{"location":"project/olmv1_roadmap/#f14-extension-permissions-escalation-checks-p2","title":"F14 - Extension permissions escalation checks (P2)","text":"<p>If, in the course of an update, an extension requests more permissions than the currently installed version, an automatic update is blocked and an administrative persona needs to specifically approve the update by default. The user who installed the extension can opt out of these permission increase checks for the purpose of automation.</p>"},{"location":"project/olmv1_roadmap/#f15-selective-extension-permissions-grants-p3","title":"F15 - Selective extension permissions grants (P3)","text":"<p>Administrative personas can choose to give extensions only a subset of the permissions it requests. This should be manageable at a per namespace level.</p>"},{"location":"project/olmv1_roadmap/#f16-extension-removal-p1","title":"F16 - Extension removal (P1)","text":"<p>Administrative personas need to be able to remove an extension including all the content that was part of the original installation bundle. Special handling should be implemented for CRDs, which when not removed, are left behind in a functioning state (i.e.any dependencies on running controllers like conversion webhooks need to be removed). When they are to be removed this can only happen if the user opts into F17. Special care also needs to be taken to allow the extension to perform any clean upon getting a signal to be removed. Components need to be removed in an order that allows the extension to handle a graceful shutdown.</p>"},{"location":"project/olmv1_roadmap/#f17-extension-cascading-removal-p2","title":"F17 - Extension cascading removal (P2)","text":"<p>OLM needs to be able to cleanly remove an extension entirely, which means deleting CRDs and other resources on the cluster. In particular this means the removal of all custom resource instances of the CRDs to be deleted and all extensions with a hard dependency. A user needs to actively opt-in to this behavior and OLM has to sequence the successful removal of all affected components and the extension itself.</p>"},{"location":"project/olmv1_roadmap/#f18-standalone-extension-bundle-installation-p2","title":"F18 - Standalone extension bundle installation (P2)","text":"<p>For local development OLM should allow the installation of an extension by directly referring to the bundle / OCI image in a container registry rather than a package name of an extension in a catalog containing the image in order to simplify testing and delivering hotfixes.</p>"},{"location":"project/olmv1_roadmap/#f19-extension-constraints-p1","title":"F19 - Extension constraints (P1)","text":"<p>OLM needs to allow extensions to specify constraints towards aspects of the running cluster and other currently installed or future extensions. Aspects of the running cluster should include software version, resource utilization, overall resource availability and state of configuration settings. These constraints need to be evaluated when extensions are attempted to be installed or updated.</p>"},{"location":"project/olmv1_roadmap/#f20-extension-health-p1","title":"F20 - Extension health (P1)","text":"<p>OLM needs to be able to report the overall health state of the extension on a cluster along the following set of aspects: presence of all required objects from the extension bundle, health of all components that have a liveness / readiness endpoint, presence and health of all other extensions the extension in question has a dependency on as well as evaluation of all additional constraints from F19. An extension that was forced to install despite missing / unhealthy dependencies and violated constraints has a reduced health scope down to the liveness / readiness endpoint.</p>"},{"location":"project/olmv1_roadmap/#f21-custom-extension-health-p3","title":"F21 - Custom extension health (P3)","text":"<p>OLM should provide a way for extensions to report an aggregate health state with custom logic. This should align with other communications channels that are also used for extensions to declare update readiness (F25). This way extensions can report health more accurately than what OLM reports today based on simple readiness of the extension controller pod. Clients like graphical consoles should be able to make use of this to supply additional overall health states of extensions that provide some form of control plane by the user of other extensions.</p>"},{"location":"project/olmv1_roadmap/#f22-best-effort-resolution-p2","title":"F22 - Best effort resolution (P2)","text":"<p>OLM should always try its best to resolve installation and update requests with the currently available and healthy set catalogs to resolve against. Intermittently or permanently failed catalogs should not block resolution for installation and updates. Fulfilling user requests is valued higher than determinism of results.</p>"},{"location":"project/olmv1_roadmap/#f23-opt-in-to-fallback-rollback-p2","title":"F23 - Opt-in to fallback / rollback (P2)","text":"<p>OLM should allow extension developers to specify whether or not it is safe to rollback from a particular current version of the extension to an author-specified previous version, once an extension update has passed pre-flights checks in F10 but subsequently failed to become available or carry out a migration. In these cases OLM should allow the administrator to downgrade the extension to the specific previous version. OLM should also respect this downgrade path when conducting updates that fail and use it to fail back to the previous version of the extension indicating that the downgrade path is supported. Extension uptime is an important goal of OLM.</p>"},{"location":"project/olmv1_roadmap/#f24-extension-overrides-p2","title":"F24 - Extension Overrides (P2)","text":"<p>Components deployed as part of extensions will require user-provided modifications at runtime in order to aid features like placement, networking configuration, proxy configuration etc. that require customization of volume mounts, annotations, labels, environment variables, taints, tolerations, node selectors, affinity, and resources. OLM should support accepting these customizations to the extension as input from the user prior or after the installation of an extension and apply them to applicable objects such as Deployments, StatefulSets, ReplicatSets.</p>"},{"location":"project/olmv1_roadmap/#f25-extension-controlled-update-readiness-p2","title":"F25 - Extension-controlled Update Readiness (P2)","text":"<p>Extensions should be able to control their readiness for updates. An extension could be on a critical path or in a state where updates would lead to disruption or worst-case: outages. OLM should respect these update readiness signals and allow the extension to signal readiness differentiated to what nature the update is based on semantic versioning rules, i.e. patch updates vs. minor or major updates. Once the signal is encountered, OLM should block the update until the signal disappears.</p>"},{"location":"project/olmv1_roadmap/#f26-canary-style-rollouts-p3","title":"F26 - Canary Style Rollouts (P3)","text":"<p>OLM should have an opinion about how administrators can carry out roll outs of new extension versions that coexist with already installed versions of the extension, in particular if the extension only ships a controller. While conflicting CRDs cannot co-exist, controllers that only selectively reconcile objects (Ingress controller pattern) can. OLM should support these deployment styles while ensuring integrity of cluster-level extensions like CRDs.</p>"},{"location":"project/olmv1_roadmap/#f27-pluggable-certificate-management-p2","title":"F27 - Pluggable certificate management (P2)","text":"<p>OLM should rely on other controllers to create and lifecycle TLS certificates required to drive the functionality of certain extensions, like webhooks that need to trust /  need to be trusted by the cluster's API server. OLM should not implement any certificate handling itself. In a first implementation support should be established for cert-manager.</p>"},{"location":"project/olmv1_roadmap/#f28-provided-service-versions-p2","title":"F28 - Provided service versions (P2)","text":"<p>Workload-based extensions can offer multiple services (a.k.a. operands) and their respective versions. Extension admins need to see which operand versions each extension supports by the extension version. Extension admins are guaranteed to install or upgrade an extension that supports their desired operand version(s). Extension authors can list supported operand versions and have guarantees that they can list dependencies that support the necessary operand version(s). When mirroring a catalog, mirroring users can select a subset of the related images to mirror, based on desired operand version(s).</p>"},{"location":"project/olmv1_roadmap/#behavioral-requirements","title":"Behavioral Requirements","text":"<p>Priority Rating: 1 highest, 2 medium, 3 lower (ex. P2 = Medium Priority)</p>"},{"location":"project/olmv1_roadmap/#b1-single-api-control-surface-p1","title":"B1 - Single API control surface (P1)","text":"<p>While the underlying implementation of the functional requirements can be carried out by different controllers with different APIs, to the administrative and non-administrative users there should be a single, cluster-level API that represents an installed extension with all high level controls described in / required by F4, F7, F8, F10, F13, F14, F15, F16, F17, F18, F21, F22, F23 and F24.</p>"},{"location":"project/olmv1_roadmap/#b2-gitops-friendly-api-surface-p1","title":"B2 - GitOps-friendly API surface (P1)","text":"<p>In many cases OLM APIs will not be used by a human via a CLI or GUI interactively but declaratively through a GitOps pipeline. This means the primary OLM API to lifecycle an extension cannot leak abstractions to other APIs for initial deployment or reconfiguration. Modifications must not require conditional lookup or modifications of other objects on the cluster that are created as part of the declarative intent stored in git in the form of YAML manifest files.</p>"},{"location":"project/olmv1_roadmap/#b3-declarative-api-p1","title":"B3 - Declarative API (P1)","text":"<p>As an extension itself, OLMs API controls have to allow for operations to be carried out solely declaratively. This mandates continuous reconciliation and eventual consistency of desired state. OLM should not conduct one-off operations. OLM should not require either clean up of failed operations or restating intent to retry a failed operation (with the exception of F11).</p>"},{"location":"project/olmv1_roadmap/#b4-event-trail-p2","title":"B4 - Event trail (P2)","text":"<p>OLM should make heavy use of Kubernetes events to leave an audit trail of tasks and actions carried out on the cluster. For expected failure scenarios administrators should not need to consult the OLM controller logs for debugging but solely rely on events and status conditions (see also B6).</p>"},{"location":"project/olmv1_roadmap/#b5-force-overrides-p1","title":"B5 - Force overrides (P1)","text":"<p>While OLM has a lot of opinions about safe operations with cluster extensions they do not apply all the time since OLM cannot possibly foresee how extensions behave at runtime. It needs to yield to the user in cases where they have more certainty about what's going to happen based on their background knowledge of the cluster or the extension. It should offer ways to force-override decisions that OLM made that block the user from proceeding in a certain direction, especially in the areas of extension installation, removal and updates.</p>"},{"location":"project/olmv1_roadmap/#b6-human-readable-status-extensions-information-p2","title":"B6 - Human-readable status extensions information (P2)","text":"<p>Whenever OLM is in the process of or having reached or failed to reach a desired state it needs to update the user about what is happening / what has happened without assuming knowledge about OLM internal or implementation details.</p>"},{"location":"project/olmv1_roadmap/#b7-scalability-resource-consumption-p1","title":"B7 - Scalability &amp; Resource consumption (P1)","text":"<p>OLM is used on clusters with hundreds to thousands of namespaces and tenants. Its API controls, specifically for F2 and F12 need to be built in such a way that resource consumption scales linearly with usage and cluster size and the overall resource usage envelope stays within manageable bounds that does not put the cluster stability, especially that of the API server at risk. System memory especially is a scarce resource.</p>"},{"location":"project/olmv1_roadmap/#compatibility-requirements","title":"Compatibility Requirements:","text":""},{"location":"project/olmv1_roadmap/#c1-compatibility-with-existing-extensions-p1","title":"C1 - Compatibility with existing extensions  (P1)","text":"<p>OLM should be able to manage extensions packaged with the current bundle format in the way described by the functional and behavior requirements when the bundle supports AllNamespace installation mode.</p>"},{"location":"project/olmv1_roadmap/#c2-compatibility-with-existing-catalogs-p1","title":"C2 - Compatibility with existing catalogs (P1)","text":"<p>OLM should be able to retrieve and update extensions that adhere to C1 from the currently supported catalog formats (File-based catalogs).</p>"},{"location":"project/olmv1_roadmap/#c3-incompatibility-with-existing-extensions-p1","title":"C3 - Incompatibility with existing extensions (P1)","text":"<p>OLM 1.0 does not support managing bundles or extension versions that do not support AllNamespace installation mode with the new set of APIs or flows</p>"},{"location":"project/olmv1_roadmap/#assumptions","title":"Assumptions","text":"<ul> <li> <p>No additional tenancy model will be introduced at the control plane / API layer of Kubernetes upstream</p> </li> <li> <p>kcp doesn\u2019t fundamentally change OLMs role and responsibilities around managing extensions (at least initially)</p> </li> <li> <p>OLM will move to a descoped, cluster-wide singleton model for cluster extensions, extension management isn\u2019t namespaced</p> </li> </ul>"},{"location":"project/olmv1_roadmap/#constraints","title":"Constraints","text":"<ul> <li>Only extension bundles with \u201cAllNamespace\u201d mode installation support can be lifecycled with the new APIs / flows in OLM 1.0</li> </ul>"},{"location":"project/olmv1_roadmap/#dependencies","title":"Dependencies","text":"<ul> <li>\"F13 - Extension permissions management (P1)\" and \"F12 - Installed extension discovery (P1)\" will land prior to the GA of OLM 1.0 to unblock most extensions that do not support AllNamespace installation mode today.</li> </ul>"},{"location":"project/olmv1_roadmap/#migration","title":"Migration","text":"<ul> <li> <p>A new set of APIs is introduced in parallel to the existing set of APIs</p> </li> <li> <p>Users opt-in to the new set of APIs, potentially resulting in a reinstall of their extension if required</p> </li> <li> <p>Extensions that are shipped with the current bundle format with AllNamespace mode can simply be reused with the new set of APIs and controls</p> </li> <li> <p>Extensions that do not support AllNamespace mode cannot be managed with the new APIs</p> </li> <li> <p>Migration scripting is provided to mass-convert existing installed extensions (\u201cSubscription\u201d / \u201cOperatorGroup\u201d objects) on existing clusters to the new OLM 1.0 model assuming they are compatible</p> </li> <li> <p>Extension authors that are also SRE/Managed PaaS administrators are incentivized to make their extension compatible with the requirements of OLM 1.0 to reap the operational benefits</p> </li> </ul>"},{"location":"project/public-api/","title":"Public API","text":"<p>The public API of OLM v1 is as follows:</p> <ul> <li>Kubernetes APIs. For more information on these APIs, see:<ul> <li>OLMv1 API reference</li> </ul> </li> <li><code>Catalogd</code> web server. For more information on what this includes, see the catalogd web server documentation</li> </ul> <p>Warning</p> <p>Only what is mentioned in the above documentation references is considered part of the public API and follows SemVer. Anything not mentioned in the above references is prone to breaking changes.</p>"},{"location":"tutorials/add-catalog/","title":"Add a Catalog of Extensions to a Cluster","text":"<p>Extension authors can publish their products in catalogs. ClusterCatalogs are curated collections of Kubernetes extensions, such as Operators. Cluster administrators can add these ClusterCatalogs to their cluster. Cluster administrators can enable polling to get over-the-air updates to ClusterCatalogs when extension authors publish changes such as bug fixes and new features.</p> <p>For example, the Kubernetes community Operators catalog is a catalog of curated extensions that is developed by the Kubernetes community. You can see the available extensions at Operatorhub.io. This catalog is distributed as an image quay.io/operatorhubio/catalog that can be installed on clusters.</p>"},{"location":"tutorials/add-catalog/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to a Kubernetes cluster, for example <code>kind</code>, using an account with <code>cluster-admin</code> permissions</li> <li>Operator Controller and Catalogd installed on the cluster</li> <li>Kubernetes CLI (<code>kubectl</code>) installed on your workstation</li> </ul>"},{"location":"tutorials/add-catalog/#procedure","title":"Procedure","text":"<ol> <li> <p>Create a catalog custom resource (CR):</p> clustercatalog_cr.yaml<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: &lt;catalog_name&gt;\nspec:\n  source:\n    type: Image\n    image:\n      ref: &lt;catalog_image&gt;\n      pollIntervalMinutes: &lt;poll_interval_duration&gt;\n</code></pre> <code>catalog_image</code> Specifies the image reference for the catalog you want to install, such as <code>quay.io/operatorhubio/catalog:latest</code>. <code>poll_interval_duration</code> Specifies the number of minutes for polling the remote registry for newer image digests. This field is optional. To disable polling, unset the field. Example `operatorhubio.yaml` CR<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterCatalog\nmetadata:\n  name: operatorhubio\nspec:\n  source:\n    type: Image\n    image:\n      ref: quay.io/operatorhubio/catalog:latest\n      pollIntervalMinutes: 10\n</code></pre> </li> <li> <p>Apply the ClusterCatalog CR:</p> <pre><code>kubectl apply -f operatorhubio.yaml\n</code></pre> Example output<pre><code>clustercatalog.olm.operatorframework.io/operatorhubio created\n</code></pre> </li> </ol>"},{"location":"tutorials/add-catalog/#verification","title":"Verification","text":"<ul> <li> <p>Run the following commands to verify the status of your catalog:</p> <ul> <li> <p>Check if your catalog is available on the cluster:</p> <pre><code>kubectl get clustercatalog\n</code></pre> Example output<pre><code>NAME            LASTUNPACKED   SERVING   AGE\noperatorhubio   18s            True      27s\n</code></pre> </li> <li> <p>Check the status of your catalog:</p> <pre><code>kubectl describe clustercatalog\n</code></pre> Example output<pre><code>Name:         operatorhubio\nNamespace:\nLabels:       olm.operatorframework.io/metadata.name=operatorhubio\nAnnotations:  &lt;none&gt;\nAPI Version:  olm.operatorframework.io/v1\nKind:         ClusterCatalog\nMetadata:\n  Creation Timestamp:  2024-11-13T15:11:08Z\n  Finalizers:\n    olm.operatorframework.io/delete-server-cache\n  Generation:        1\n  Resource Version:  3069\n  UID:               2c94ebf8-32ea-4a62-811a-c7098cd2d4db\nSpec:\n  Availability Mode:  Available\n  Priority:           0\n  Source:\n    Image:\n      Poll Interval Minutes:  10\n      Ref:                    quay.io/operatorhubio/catalog:latest\n    Type:                     Image\nStatus:\n  Conditions:\n    Last Transition Time:  2024-11-13T15:11:19Z\n    Message:               Successfully unpacked and stored content from resolved source\n    Observed Generation:   1\n    Reason:                Succeeded\n    Status:                True\n    Type:                  Progressing\n    Last Transition Time:  2024-11-13T15:11:19Z\n    Message:               Serving desired content from resolved source\n    Observed Generation:   1\n    Reason:                Available\n    Status:                True\n    Type:                  Serving\n  Last Unpacked:           2024-11-13T15:11:18Z\n  Resolved Source:\n    Image:\n      Ref:  quay.io/operatorhubio/catalog@sha256:3cd8fde1dfd4269467451c4b2c77d4196b427004f2eb82686376f28265655c1c\n    Type:   Image\n  Urls:\n    Base:  https://catalogd-service.olmv1-system.svc/catalogs/operatorhubio\nEvents:    &lt;none&gt;\n</code></pre> </li> </ul> </li> </ul>"},{"location":"tutorials/downgrade-extension/","title":"Downgrade a ClusterExtension","text":""},{"location":"tutorials/downgrade-extension/#introduction","title":"Introduction","text":"<p>Downgrading a <code>ClusterExtension</code> involves reverting the extension to a previously available version. This process may be necessary due to compatibility issues, unexpected behavior in the newer version, or specific feature requirements only available in an earlier release. However, downgrading carries inherent risks, such as potential data loss, issues with new CRD versions, and possible breakage of clients that rely on the newer version. Users should carefully consider these risks and be confident in their decision to proceed with the downgrade. This guide provides step-by-step instructions for performing a downgrade, including overrides to bypass default constraints and disable CRD safety checks.</p>"},{"location":"tutorials/downgrade-extension/#prerequisites","title":"Prerequisites","text":"<p>Before initiating the downgrade process, ensure the following prerequisites are met:</p> <ul> <li>Backup Configurations: Always back up your current configurations and data to prevent potential loss during the downgrade.</li> <li>Access Rights: Ensure you have the necessary permissions to modify <code>ClusterExtension</code> resources and perform administrative tasks.</li> <li>Version Availability: Verify that the target downgrade version is available in your catalogs.</li> <li>Compatibility Check: Ensure that the target version is compatible with your current system and other dependencies.</li> </ul>"},{"location":"tutorials/downgrade-extension/#steps-to-downgrade","title":"Steps to Downgrade","text":""},{"location":"tutorials/downgrade-extension/#1-disabling-the-crd-upgrade-safety-check","title":"1. Disabling the CRD Upgrade Safety Check","text":"<p>Custom Resource Definitions (CRDs) ensure that the resources used by the <code>ClusterExtension</code> are valid and consistent. During a downgrade, the CRD Upgrade Safety check might prevent reverting to an incompatible version. Disabling the CRD Upgrade Safety check allows the downgrade to proceed without these validations.</p> <p>Disable CRD Safety Check Configuration:</p> <p>Add the <code>crdUpgradeSafety</code> field and set its <code>enforcement</code> to <code>None</code> in the <code>ClusterExtension</code> resource. This configuration disables CRD safety checks during the downgrade process.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: example-extension\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  install:\n    preflight:\n      crdUpgradeSafety:\n        enforcement: None\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.6.0\n</code></pre> <p>Command Example:</p> <p>If you prefer using the command line, you can use <code>kubectl</code> to modify the upgrade CRD safety check configuration.</p> <pre><code>kubectl patch clusterextension example-extension --patch '{\"spec\":{\"install\":{\"preflight\":{\"crdUpgradeSafety\":{\"enforcement\":\"None\"}}}}}' --type=merge\n</code></pre>"},{"location":"tutorials/downgrade-extension/#2-ignoring-catalog-provided-upgrade-constraints","title":"2. Ignoring Catalog Provided Upgrade Constraints","text":"<p>By default, Operator Lifecycle Manager (OLM) enforces upgrade constraints based on semantic versioning and catalog definitions. To allow downgrades, you need to override these constraints.</p> <p>Override Configuration:</p> <p>Set the <code>upgradeConstraintPolicy</code> to <code>SelfCertified</code> in the <code>ClusterExtension</code> resource. This configuration permits downgrades, sidegrades, and any version changes without adhering to the predefined upgrade paths.</p> <p>Example:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: example-extension\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  install:\n    preflight:\n      crdUpgradeSafety:\n        enforcement: None\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.6.0\n      upgradeConstraintPolicy: SelfCertified\n</code></pre> <p>Command Example:</p> <p>If you prefer using the command line, you can use <code>kubectl</code> to modify the upgrade constraint policy.</p> <pre><code>kubectl patch clusterextension example-extension --patch '{\"spec\":{\"source\": {\"catalog\":{\"upgradeConstraintPolicy\":\"SelfCertified\"}}}}' --type=merge\n</code></pre>"},{"location":"tutorials/downgrade-extension/#3-executing-the-downgrade","title":"3. Executing the Downgrade","text":"<p>Once the CRD safety checks are disabled and upgrade constraints are set, you can proceed with the actual downgrade.</p> <ol> <li> <p>Edit the ClusterExtension Resource:</p> <p>Modify the <code>ClusterExtension</code> custom resource to specify the target version and adjust the upgrade constraints.</p> <pre><code>kubectl edit clusterextension example-extension\n</code></pre> </li> <li> <p>Update the Version:</p> <p>Within the YAML editor, update the <code>spec</code> section as follows:</p> <pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: example-extension\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  install:\n    preflight:\n      crdUpgradeSafety:\n        enforcement: None\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: &lt;target_version&gt;\n      upgradeConstraintPolicy: SelfCertified\n</code></pre> <code>target_version</code> Specify the target version you wish to downgrade to. </li> <li> <p>Apply the Changes:</p> <p>Save and exit the editor. Kubernetes will apply the changes and initiate the downgrade process.</p> </li> </ol>"},{"location":"tutorials/downgrade-extension/#4-post-downgrade-verification","title":"4. Post-Downgrade Verification","text":"<p>After completing the downgrade, verify that the <code>ClusterExtension</code> is functioning as expected.</p> <p>Verification Steps:</p> <ol> <li> <p>Check the Status of the ClusterExtension:</p> <pre><code>kubectl get clusterextension example-extension -o yaml\n</code></pre> <p>Ensure that the <code>status</code> reflects the target version and that there are no error messages.</p> </li> <li> <p>Validate CRD Integrity:</p> <p>Confirm that all CRDs associated with the <code>ClusterExtension</code> are correctly installed and compatible with the downgraded version.</p> <pre><code>kubectl get crd | grep &lt;extension_crd&gt;\n</code></pre> </li> <li> <p>Test Extension Functionality:</p> <p>Perform functional tests to ensure that the extension operates correctly in its downgraded state.</p> </li> <li> <p>Monitor Logs:</p> <p>Check the logs of the operator managing the <code>ClusterExtension</code> for any warnings or errors.</p> <pre><code>kubectl logs deployment/&lt;operator_deployment&gt; -n &lt;operator_namespace&gt;\n</code></pre> </li> </ol>"},{"location":"tutorials/downgrade-extension/#troubleshooting","title":"Troubleshooting","text":"<p>During the downgrade process, you might encounter issues. Below are common problems and their solutions:</p>"},{"location":"tutorials/downgrade-extension/#downgrade-fails-due-to-version-constraints","title":"Downgrade Fails Due to Version Constraints","text":"<p>Solution:</p> <ul> <li>Ensure that the <code>upgradeConstraintPolicy</code> is set to <code>SelfCertified</code>.</li> <li>Verify that the target version exists in the catalog.</li> <li>Check for typos or incorrect version numbers in the configuration.</li> </ul>"},{"location":"tutorials/downgrade-extension/#crd-compatibility-issues","title":"CRD Compatibility Issues","text":"<p>Solution:</p> <ul> <li>Review the changes in CRDs between versions to ensure compatibility.</li> <li>If disabling the CRD safety check, ensure that the downgraded version can handle the existing CRDs without conflicts.</li> <li>Consider manually reverting CRDs if necessary, but proceed with caution to avoid data loss.</li> </ul>"},{"location":"tutorials/downgrade-extension/#extension-becomes-unresponsive-after-downgrade","title":"Extension Becomes Unresponsive After Downgrade","text":"<p>Solution:</p> <ul> <li>Restore from the backup taken before the downgrade.</li> <li>Investigate logs for errors related to the downgraded version.</li> <li>Verify that all dependencies required by the downgraded version are satisfied.</li> </ul>"},{"location":"tutorials/downgrade-extension/#additional-resources","title":"Additional Resources","text":"<ul> <li>Semantic Versioning Specification</li> <li>Manually Verified Upgrades and Downgrades</li> </ul>"},{"location":"tutorials/explore-available-content/","title":"Explore Available Content","text":"<p>After you add a catalog of extensions to your cluster, you must port forward your catalog as a service. Then you can query the catalog by using <code>curl</code> commands and the <code>jq</code> CLI tool to find extensions to install.</p>"},{"location":"tutorials/explore-available-content/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have added a ClusterCatalog of extensions, such as OperatorHub.io, to your cluster.</li> <li>You have installed the <code>jq</code> CLI tool.</li> </ul> <p>Note</p> <p>By default, Catalogd is installed with TLS enabled for the catalog webserver. The following examples will show this default behavior, but for simplicity's sake will ignore TLS verification in the curl commands using the <code>-k</code> flag.</p>"},{"location":"tutorials/explore-available-content/#procedure","title":"Procedure","text":"<ol> <li> <p>Port forward the catalog server service:</p> <pre><code>kubectl -n olmv1-system port-forward svc/catalogd-service 8443:443\n</code></pre> </li> <li> <p>Return a list of all the extensions in a catalog via the v1 API endpoint:     <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/all | jq -s '.[] | select(.schema == \"olm.package\") | .name'\n</code></pre></p> Success Example output<pre><code>\"ack-acm-controller\"\n\"ack-acmpca-controller\"\n\"ack-apigatewayv2-controller\"\n\"ack-applicationautoscaling-controller\"\n\"ack-cloudfront-controller\"\n\"ack-cloudtrail-controller\"\n\"ack-cloudwatch-controller\"\n\"ack-cloudwatchlogs-controller\"\n\"ack-dynamodb-controller\"\n\"ack-ec2-controller\"\n\"ack-ecr-controller\"\n\"ack-ecs-controller\"\n\"ack-efs-controller\"\n\"ack-eks-controller\"\n\"ack-elasticache-controller\"\n\"ack-emrcontainers-controller\"\n\"ack-eventbridge-controller\"\n\"ack-iam-controller\"\n\"ack-kafka-controller\"\n\"ack-keyspaces-controller\"\n\"ack-kinesis-controller\"\n\"ack-kms-controller\"\n\"ack-lambda-controller\"\n\"ack-memorydb-controller\"\n\"ack-mq-controller\"\n\"ack-networkfirewall-controller\"\n\"ack-opensearchservice-controller\"\n\"ack-pipes-controller\"\n\"ack-prometheusservice-controller\"\n\"ack-rds-controller\"\n\"ack-route53-controller\"\n\"ack-route53resolver-controller\"\n\"ack-s3-controller\"\n\"ack-sagemaker-controller\"\n\"ack-secretsmanager-controller\"\n\"ack-sfn-controller\"\n\"ack-sns-controller\"\n\"ack-sqs-controller\"\n\"aerospike-kubernetes-operator\"\n\"airflow-helm-operator\"\n\"aiven-operator\"\n\"akka-cluster-operator\"\n\"alvearie-imaging-ingestion\"\n\"anchore-engine\"\n\"apch-operator\"\n\"api-operator\"\n\"api-testing-operator\"\n\"apicast-community-operator\"\n\"apicurio-registry\"\n\"apimatic-kubernetes-operator\"\n\"app-director-operator\"\n\"appdynamics-operator\"\n\"application-services-metering-operator\"\n\"appranix\"\n\"aqua\"\n\"argocd-operator\"\n...\n</code></pre> </li> <li> <p>Return list of packages that support <code>AllNamespaces</code> install mode and do not use webhooks:</p> <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/all | jq -cs '[.[] | select(.schema == \"olm.bundle\" and (.properties[] | select(.type == \"olm.csv.metadata\").value.installModes[] | select(.type == \"AllNamespaces\" and .supported == true)) and .spec.webhookdefinitions == null) | .package] | unique[]'\n</code></pre> Success Example output<pre><code>{\"package\":\"ack-acm-controller\",\"version\":\"0.0.12\"}\n{\"package\":\"ack-acmpca-controller\",\"version\":\"0.0.5\"}\n{\"package\":\"ack-apigatewayv2-controller\",\"version\":\"1.0.7\"}\n{\"package\":\"ack-applicationautoscaling-controller\",\"version\":\"1.0.11\"}\n{\"package\":\"ack-cloudfront-controller\",\"version\":\"0.0.9\"}\n{\"package\":\"ack-cloudtrail-controller\",\"version\":\"1.0.8\"}\n{\"package\":\"ack-cloudwatch-controller\",\"version\":\"0.0.3\"}\n{\"package\":\"ack-cloudwatchlogs-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-dynamodb-controller\",\"version\":\"1.2.9\"}\n{\"package\":\"ack-ec2-controller\",\"version\":\"1.2.4\"}\n{\"package\":\"ack-ecr-controller\",\"version\":\"1.0.12\"}\n{\"package\":\"ack-ecs-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-efs-controller\",\"version\":\"0.0.5\"}\n{\"package\":\"ack-eks-controller\",\"version\":\"1.3.3\"}\n{\"package\":\"ack-elasticache-controller\",\"version\":\"0.0.29\"}\n{\"package\":\"ack-emrcontainers-controller\",\"version\":\"1.0.8\"}\n{\"package\":\"ack-eventbridge-controller\",\"version\":\"1.0.6\"}\n{\"package\":\"ack-iam-controller\",\"version\":\"1.3.6\"}\n{\"package\":\"ack-kafka-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-keyspaces-controller\",\"version\":\"0.0.11\"}\n...\n</code></pre> </li> <li> <p>Inspect the contents of an extension's metadata:</p> <pre><code>curl -k https://localhost:8443/catalogs/operatorhubio/api/v1/all | jq -s '.[] | select( .schema == \"olm.package\") | select( .name == \"&lt;package_name&gt;\")'\n</code></pre> <code>package_name</code> Specifies the name of the package you want to inspect. Success Example output<pre><code>{\n  \"defaultChannel\": \"stable-v6.x\",\n  \"icon\": {\n    \"base64data\": \"PHN2ZyB4bWxucz0ia...\n    \"mediatype\": \"image/svg+xml\"\n  },\n  \"name\": \"cockroachdb\",\n  \"schema\": \"olm.package\"\n}\n</code></pre> </li> </ol>"},{"location":"tutorials/explore-available-content/#additional-resources","title":"Additional resources","text":"<ul> <li>Catalog queries</li> </ul>"},{"location":"tutorials/install-extension/","title":"Install an Extension from a Catalog","text":"<p>In Operator Lifecycle Manager (OLM) 1.0, Kubernetes extensions are scoped to the cluster. After you add a catalog to your cluster, you can install an extension by creating a custom resource (CR) and applying it.</p>"},{"location":"tutorials/install-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>A catalog that is being served</li> <li>The name, and optionally version, or channel, of the supported extension to be installed</li> <li>An existing namespace in which to install the extension</li> </ul>"},{"location":"tutorials/install-extension/#serviceaccount-for-clusterextension-installation-and-management","title":"ServiceAccount for ClusterExtension Installation and Management","text":"<p>Adhering to OLM v1's \"Secure by Default\" tenet, OLM v1 does not have the permissions necessary to install content. This follows the least privilege principle and reduces the chance of a confused deputy attack. Instead, users must explicitly specify a ServiceAccount that will be used to perform the installation and management of a specific ClusterExtension.</p> <p>The ServiceAccount must be configured with the RBAC permissions required by the ClusterExtension. If the permissions do not meet the minimum requirements, installation will fail. If no ServiceAccount is provided in the ClusterExtension manifest, then the manifest will be rejected.</p> <p>For information on determining the ServiceAccount's permission, please see Derive minimal ServiceAccount required for ClusterExtension Installation and Management.</p>"},{"location":"tutorials/install-extension/#procedure","title":"Procedure","text":"<ol> <li> <p>Create a CR for the Kubernetes extension you want to install:</p> Example CR<pre><code>apiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: &lt;extension_name&gt;\nspec:\n  namespace: &lt;namespace_name&gt;\n  serviceAccount:\n    name: &lt;serviceAccount_name&gt;\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: &lt;package_name&gt;\n      channels: [&lt;channel1&gt;,&lt;channel2]\n      version: \"&lt;version&gt;\"\n</code></pre> <code>extension_name</code> Specifies a custom name for the Kubernetes extension you want to install, such as <code>my-camel-k</code>. <code>package_name</code> Specifies the name of the package you want to install, such as <code>camel-k</code>. <code>channels</code> Optional: Specifies a set of the extension's channels from which to select, such as <code>stable</code> or <code>fast</code>. <code>version</code> Optional: Specifies the version or version range you want installed, such as <code>1.3.1</code> or <code>\"&lt;2\"</code>.  If you use a comparison string to define a version range, the string must be surrounded by double quotes (<code>\"</code>). <code>namespace_name</code> Specifies a name for the namespace in which the bundle of content for the package referenced in the packageName field will be applied. <code>serviceAccount_name</code> serviceAccount name is a required reference to a ServiceAccount that exists in the <code>namespace_name</code>. The provided ServiceAccount is used to install and manage the content for the package specified in the packageName field. <p>Warning</p> <p>Currently, the following limitations affect the installation of extensions:</p> <ul> <li>If multiple catalogs are added to a cluster, you cannot specify a catalog when you install an extension.</li> <li>OLM 1.0 requires that all of the extensions have unique bundle and package names for dependency resolution.</li> </ul> <p>As a result, if two catalogs have an extension with the same name, the installation might fail or lead to an unintended outcome. For example, the first extension that matches might install successfully and finish without searching for a match in the second catalog.</p> </li> <li> <p>Apply the CR to the cluster:</p> <pre><code>kubectl apply -f &lt;cr_name&gt;.yaml\n</code></pre> <p>Success</p> Example output<pre><code>clusterextension.olm.operatorframework.io/argocd created\n</code></pre> </li> </ol>"},{"location":"tutorials/install-extension/#verification","title":"Verification","text":"<ul> <li> <p>Describe the installed extension:</p> <pre><code>kubectl describe clusterextensions\n</code></pre> Success Example output<pre><code>Name:         argocd\nNamespace:\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nAPI Version:  olm.operatorframework.io/v1\nKind:         ClusterExtension\nMetadata:\n  Creation Timestamp:  2024-11-11T13:41:23Z\n  Finalizers:\n    olm.operatorframework.io/cleanup-unpack-cache\n    olm.operatorframework.io/cleanup-contentmanager-cache\n  Generation:        1\n  Resource Version:  5426\n  UID:               bde55f03-abe2-48af-8c09-28d32df878ad\nSpec:\n  Namespace:  argocd\n  Service Account:\n    Name:  argocd-installer\n  Source:\n    Catalog:\n      Package Name:               argocd-operator\n      Upgrade Constraint Policy:  CatalogProvided\n      Version:                    0.6.0\n    Source Type:                  Catalog\nStatus:\n  Conditions:\n    Last Transition Time:  2024-11-11T13:41:23Z\n    Message:\n    Observed Generation:   1\n    Reason:                Deprecated\n    Status:                False\n    Type:                  Deprecated\n    Last Transition Time:  2024-11-11T13:41:23Z\n    Message:\n    Observed Generation:   1\n    Reason:                Deprecated\n    Status:                False\n    Type:                  PackageDeprecated\n    Last Transition Time:  2024-11-11T13:41:23Z\n    Message:\n    Observed Generation:   1\n    Reason:                Deprecated\n    Status:                False\n    Type:                  ChannelDeprecated\n    Last Transition Time:  2024-11-11T13:41:23Z\n    Message:\n    Observed Generation:   1\n    Reason:                Deprecated\n    Status:                False\n    Type:                  BundleDeprecated\n    Last Transition Time:  2024-11-11T13:41:31Z\n    Message:               Installed bundle quay.io/operatorhubio/argocd-operator@sha256:d538c45a813b38ef0e44f40d279dc2653f97ca901fb660da5d7fe499d51ad3b3 successfully\n    Observed Generation:   1\n    Reason:                Succeeded\n    Status:                True\n    Type:                  Installed\n    Last Transition Time:  2024-11-11T13:41:32Z\n    Message:               desired state reached\n    Observed Generation:   1\n    Reason:                Succeeded\n    Status:                True\n    Type:                  Progressing\n  Install:\n    Bundle:\n      Name:     argocd-operator.v0.6.0\n      Version:  0.6.0\nEvents:         &lt;none&gt;\n</code></pre> </li> </ul>"},{"location":"tutorials/uninstall-extension/","title":"Uninstall an extension","text":"<p>You can uninstall a Kubernetes extension and its associated custom resource definitions (CRD) by deleting the extension's custom resource (CR).</p>"},{"location":"tutorials/uninstall-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have an extension installed.</li> </ul>"},{"location":"tutorials/uninstall-extension/#procedure","title":"Procedure","text":"<ul> <li> <p>Delete the extension's CR:</p> <pre><code>kubectl delete clusterextensions &lt;extension_name&gt;\n</code></pre> <code>extension_name</code> Specifies the name defined in the <code>metadata.name</code> field of the extension's CR. Example output<pre><code>clusterextension.olm.operatorframework.io \"argocd\" deleted\n</code></pre> </li> </ul>"},{"location":"tutorials/uninstall-extension/#verification","title":"Verification","text":"<ul> <li> <p>Verify that the Kubernetes extension is deleted:</p> <pre><code>kubectl get clusterextension.olm.operatorframework.io\n</code></pre> Example output<pre><code>No resources found\n</code></pre> </li> </ul>"},{"location":"tutorials/uninstall-extension/#cleanup","title":"Cleanup","text":"<ul> <li>Remove the extension namespace, and installer service account cluster-scoped RBAC resources (if applicable).</li> </ul>"},{"location":"tutorials/upgrade-extension/","title":"Upgrade an Extension","text":"<p>Existing extensions can be upgraded by updating the version field in the ClusterExtension resource.</p> <p>For information on downgrading an extension, see Downgrade an Extension.</p>"},{"location":"tutorials/upgrade-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have a ClusterExtension installed</li> <li>The target version is compatible with OLM v1 (see OLM v1 limitations)</li> <li>Any changes to the CustomResourceDefinition in the new version meet compatibility requirements (see CRD upgrade safety)</li> <li>The installer ServiceAccount's RBAC permissions are adequate for the target version (see Minimal RBAC for Installer Service Account)</li> <li>You are not attempting to upgrade between minor versions with a major version of zero (see Upgrades within the major version zero)</li> </ul> <p>For more detailed information see Upgrade Support.</p>"},{"location":"tutorials/upgrade-extension/#procedure","title":"Procedure","text":"<p>For this example, we will be using v0.2.0 of the ArgoCD operator. If you would like to follow along with this tutorial, you can apply the following manifest to your cluster by, for example, saving it to a local file and then running <code>kubectl apply -f FILENAME</code>:</p> ArgoCD v0.2.0 manifests <pre><code>---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: argocd\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: argocd-installer\n  namespace: argocd\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: argocd-installer-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: argocd-installer-clusterrole\nsubjects:\n- kind: ServiceAccount\n  name: argocd-installer\n  namespace: argocd\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: argocd-installer-clusterrole\nrules:\n# Allow ClusterExtension to set blockOwnerDeletion ownerReferences\n- apiGroups: [olm.operatorframework.io]\n  resources: [clusterextensions/finalizers]\n  verbs: [update]\n  resourceNames: [argocd]\n# Manage ArgoCD CRDs\n- apiGroups: [apiextensions.k8s.io]\n  resources: [customresourcedefinitions]\n  verbs: [create, list, watch]\n- apiGroups: [apiextensions.k8s.io]\n  resources: [customresourcedefinitions]\n  verbs: [get, update, patch, delete]\n  resourceNames:\n  - appprojects.argoproj.io\n  - argocds.argoproj.io\n  - applications.argoproj.io\n  - argocdexports.argoproj.io\n  - applicationsets.argoproj.io\n# Manage ArgoCD ClusterRoles and ClusterRoleBindings\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: [create, list, watch]\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: [get, update, patch, delete]\n  resourceNames:\n  - argocd-operator.v0-1dhiybrldl1gyksid1dk2dqjsc72psdybc7iyvse5gpx\n  - argocd-operator-metrics-reader\n  - argocd-operator.v0-22gmilmgp91wu25is5i2ec598hni8owq3l71bbkl7iz3\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterrolebindings]\n  verbs: [create, list, watch]\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterrolebindings]\n  verbs: [get, update, patch, delete]\n  resourceNames:\n  - argocd-operator.v0-1dhiybrldl1gyksid1dk2dqjsc72psdybc7iyvse5gpx\n  - argocd-operator.v0-22gmilmgp91wu25is5i2ec598hni8owq3l71bbkl7iz3\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: argocd-installer-rbac-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: argocd-installer-rbac-clusterrole\nsubjects:\n- kind: ServiceAccount\n  name: argocd-installer\n  namespace: argocd\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: argocd-installer-rbac-clusterrole\nrules:\n- apiGroups: [\"\"]\n  resources: [configmaps]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [endpoints]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [events]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [namespaces]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [persistentvolumeclaims]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [pods]\n  verbs: ['*', get]\n- apiGroups: [\"\"]\n  resources: [pods/log]\n  verbs: [get]\n- apiGroups: [\"\"]\n  resources: [secrets]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [serviceaccounts]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [services]\n  verbs: ['*']\n- apiGroups: [\"\"]\n  resources: [services/finalizers]\n  verbs: ['*']\n- apiGroups: [apps]\n  resources: [daemonsets]\n  verbs: ['*']\n- apiGroups: [apps]\n  resources: [deployments]\n  verbs: ['*']\n- apiGroups: [apps]\n  resources: [deployments/finalizers]\n  resourceNames: [argocd-operator]\n  verbs: [update]\n- apiGroups: [apps]\n  resources: [replicasets]\n  verbs: ['*']\n- apiGroups: [apps]\n  resources: [statefulsets]\n  verbs: ['*']\n- apiGroups: [apps.openshift.io]\n  resources: [deploymentconfigs]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [applications]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [appprojects]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocdexports]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocdexports/finalizers]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocdexports/status]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocds]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocds/finalizers]\n  verbs: ['*']\n- apiGroups: [argoproj.io]\n  resources: [argocds/status]\n  verbs: ['*']\n- apiGroups: [authentication.k8s.io]\n  resources: [tokenreviews]\n  verbs: [create]\n- apiGroups: [authorization.k8s.io]\n  resources: [subjectaccessreviews]\n  verbs: [create]\n- apiGroups: [autoscaling]\n  resources: [horizontalpodautoscalers]\n  verbs: ['*']\n- apiGroups: [batch]\n  resources: [cronjobs]\n  verbs: ['*']\n- apiGroups: [batch]\n  resources: [jobs]\n  verbs: ['*']\n- apiGroups: [config.openshift.io]\n  resources: [clusterversions]\n  verbs: [get, list, watch]\n- apiGroups: [monitoring.coreos.com]\n  resources: [prometheuses]\n  verbs: ['*']\n- apiGroups: [monitoring.coreos.com]\n  resources: [servicemonitors]\n  verbs: ['*']\n- apiGroups: [networking.k8s.io]\n  resources: [ingresses]\n  verbs: ['*']\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: ['*']\n  verbs: ['*']\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterrolebindings]\n  verbs: ['*']\n- apiGroups: [rbac.authorization.k8s.io]\n  resources: [clusterroles]\n  verbs: ['*']\n- apiGroups: [route.openshift.io]\n  resources: [routes]\n  verbs: ['*']\n- apiGroups: [route.openshift.io]\n  resources: [routes/custom-host]\n  verbs: ['*']\n- apiGroups: [\"coordination.k8s.io\"]\n  resources: [\"leases\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: argocd-installer-role\n  namespace: argocd\nrules:\n- apiGroups: [\"\"]\n  resources: [serviceaccounts]\n  verbs: [create, list, watch]\n- apiGroups: [\"\"]\n  resources: [serviceaccounts]\n  verbs: [get, update, patch, delete]\n  resourceNames: [argocd-operator-controller-manager]\n- apiGroups: [\"\"]\n  resources: [configmaps]\n  verbs: [create, list, watch]\n- apiGroups: [\"\"]\n  resources: [configmaps]\n  verbs: [get, update, patch, delete]\n  resourceNames: [argocd-operator-manager-config]\n- apiGroups: [\"\"]\n  resources: [services]\n  verbs: [create, list, watch]\n- apiGroups: [\"\"]\n  resources: [services]\n  verbs: [get, update, patch, delete]\n  resourceNames: [argocd-operator-controller-manager-metrics-service]\n- apiGroups: [apps]\n  resources: [deployments]\n  verbs: [create, list, watch]\n- apiGroups: [apps]\n  resources: [deployments]\n  verbs: [get, update, patch, delete]\n  resourceNames: [argocd-operator-controller-manager]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: argocd-installer-binding\n  namespace: argocd\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: argocd-installer-role\nsubjects:\n- kind: ServiceAccount\n  name: argocd-installer\n  namespace: argocd\n---\napiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.2.0\n</code></pre> <p>If we view the current state of our ClusterExtension we should see that we have installed version 0.2.0:</p> <pre><code>kubectl get clusterextension argocd -o jsonpath-as-json=\"{.status.install}\"\n</code></pre> <p>Command output</p> <pre><code>[\n    {\n        \"bundle\": {\n            \"name\": \"argocd-operator.v0.2.0\",\n            \"version\": \"0.2.0\"\n        }\n    }\n]\n</code></pre> <ul> <li> <p>To initiate our upgrade, let's update the version field in the ClusterExtension resource:</p> Method 1: apply a new ClusterExtension manifest<pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1\nkind: ClusterExtension\nmetadata:\n  name: argocd\nspec:\n  namespace: argocd\n  serviceAccount:\n    name: argocd-installer\n  source:\n    sourceType: Catalog\n    catalog:\n      packageName: argocd-operator\n      version: 0.2.1 # Update to version 0.2.1\nEOF\n</code></pre> <p>Method 1 output</p> <pre><code>clusterextension.olm.operatorframework.io/argocd configured\n</code></pre> <p>Alternatively, you can use <code>kubectl patch</code> to update the version field:</p> Method 2: run patch command<pre><code>kubectl patch clusterextension argocd --type='merge' -p '{\"spec\": {\"source\": {\"catalog\": {\"version\": \"0.2.1\"}}}}'\n</code></pre> <p>Method 2 output</p> <pre><code>clusterextension.olm.operatorframework.io/argocd patched\n</code></pre> </li> <li> <p>We can now verify that the ClusterExtension is updated to the new version:</p> Get the current ClusterExtension version<pre><code>kubectl get clusterextension argocd -o jsonpath-as-json=\"{.status.install}\"\n</code></pre> <p>Updated ClusterExtension version</p> <pre><code>[\n    {\n        \"bundle\": {\n            \"name\": \"argocd-operator.v0.2.1\",\n            \"version\": \"0.2.1\"\n        }\n    }\n]\n</code></pre> </li> </ul> <p>Note on the <code>kubectl.kubernetes.io/last-applied-configuration</code> annotation</p> <p>After your upgrade, the contents of the <code>kubectl.kubernetes.io/last-applied-configuration</code> annotation field will differ depending on your method of upgrade. If you apply a new ClusterExtension manifest as in the first method shown, the last applied configuration will show the new version since we replaced the existing manifest. If you use the patch method or <code>kubectl edit clusterextension</code>, then the last applied configuration will show the old version.</p>"}]}